{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import progressbar\n",
    "import torch\n",
    "import pickle\n",
    "from mytree import *\n",
    "from utils import *\n",
    "from treeUtil import *\n",
    "import tqdm\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import functools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import string\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import nltk.tree\n",
    "from ast import literal_eval\n",
    "import pptree\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from spacy.pipeline import merge_entities\n",
    "nlp = en_core_web_sm.load()\n",
    "nlp.add_pipe(merge_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False if in-domain; True if general\n",
    "proanti = True\n",
    "w2vec = False\n",
    "ner = True\n",
    "blackout = False\n",
    "balanced = True\n",
    "undersample = False\n",
    "non_trainable = True\n",
    "economic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three_economic_w2v_aadhar_test_1ProAnti_0General_1NER_0Blackout_1Balance_0Undersample_1Fixed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {0:'ProAnti', 1:'General', 2:'NER', 3:'Blackout', 4:'Balance', 5:'Undersample', 6:'Fixed'}\n",
    "bool_list = [proanti, w2vec, ner, blackout, balanced, undersample, non_trainable]\n",
    "corpus_path = '../data/new/economic'\n",
    "namecode = 'three_economic_w2v_aadhar_test'\n",
    "for index, bb in enumerate(bool_list):\n",
    "    namecode += '_'\n",
    "    if bb:\n",
    "        namecode += '1'\n",
    "    else:\n",
    "        namecode += '0'\n",
    "    namecode += dic[index]\n",
    "namecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For logging\n",
    "import logging\n",
    "\n",
    "#Remove all the previous handlers\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "#Create the file for logging purposes -> CHANGE THE LEVEL TYPE TO logging.DEBUG when debugging or finding faults\n",
    "logging.basicConfig(filename='log_'+namecode+'.log',\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "                            level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger('./logs_'+namecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveNN(nn.Module):\n",
    "    def __init__(self, word_embeddings, vocab, embedSize=300, numClasses=2, beta = 0.3, use_weight = True, non_trainable = non_trainable):\n",
    "        super(RecursiveNN, self).__init__()\n",
    "#             if (w2vec):\n",
    "#                 self.embedding = nn.Embedding(len(vocab), embedSize)\n",
    "#                 self.embedding.load_state_dict({'weight': w2vec_weights})\n",
    "        self.embedding = nn.Embedding.from_pretrained(word_embeddings)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        if non_trainable:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(len(vocab), embedSize)\n",
    "        self.embedding = nn.Embedding(len(vocab), embedSize)\n",
    "        self.W = nn.Linear(2*embedSize, embedSize, bias=True)\n",
    "        self.nonLinear = torch.tanh\n",
    "        self.projection = nn.Linear(embedSize, numClasses, bias=True)\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.loss = Var(torch.FloatTensor([0]))\n",
    "        self.V = vocab\n",
    "        self.beta = beta\n",
    "        self.use_weight = use_weight\n",
    "        self.total_rep = None #\n",
    "        self.count_rep = 0 #\n",
    "        self.numClasses = numClasses\n",
    "\n",
    "    def traverse(self, node):\n",
    "        if node.isLeaf:\n",
    "            if node.getLeafWord() in self.V:  # check if right word is in vocabulary\n",
    "                word = node.getLeafWord()\n",
    "            else:  # otherwise use the unknown token\n",
    "                word = 'UNK'\n",
    "            # print(self.V[word],len(self.V),word,(torch.LongTensor([int(self.V[word])])))\n",
    "            currentNode = (self.embedding(Var(torch.LongTensor([int(self.V[word])]))))\n",
    "        else: currentNode = self.nonLinear(self.W(torch.cat((self.traverse(node.left),self.traverse(node.right)),1)))\n",
    "        currentNode = currentNode/(torch.norm(currentNode))\n",
    "\n",
    "        assert node.label!=None\n",
    "        self.nodeProbList.append(self.projection(currentNode))\n",
    "        # print (node.label)\n",
    "        self.labelList.append(torch.LongTensor([node.label]))\n",
    "        loss_weight = 1-self.beta if node.annotated else self.beta\n",
    "        self.loss += (loss_weight*F.cross_entropy(input=torch.cat([self.projection(currentNode)]),target=Var(torch.cat([torch.LongTensor([node.label])]))))\n",
    "\n",
    "        #\n",
    "        if not node.isRoot():\n",
    "            if self.total_rep is None:\n",
    "                self.total_rep = currentNode.data.clone()\n",
    "            else:\n",
    "                self.total_rep += currentNode.data.clone()\n",
    "            self.count_rep += 1\n",
    "        #\n",
    "\n",
    "        return currentNode        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.loss = Var(torch.FloatTensor([0]))\n",
    "        self.traverse(x)\n",
    "        self.labelList = Var(torch.cat(self.labelList))\n",
    "        return torch.cat(self.nodeProbList)\n",
    "\n",
    "    def getLoss(self, tree):\n",
    "        nodes = self.forward(tree)\n",
    "        predictions = nodes.max(dim=1)[1]\n",
    "        loss = self.loss\n",
    "        return predictions,loss\n",
    "\n",
    "    def getRep(self, tree):\n",
    "        self.count_rep = 0\n",
    "        self.total_rep = None\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.loss = Var(torch.FloatTensor([0]))\n",
    "\n",
    "        root_rep = self.traverse(tree)\n",
    "\n",
    "        return (torch.cat((root_rep,self.total_rep/self.count_rep),1)).data.numpy().T.flatten()\n",
    "\n",
    "\n",
    "    def evaluate(self, trees):\n",
    "            pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "            n = nAll = correctRoot = correctAll = 0.0\n",
    "            tp = [1e-2]*self.numClasses\n",
    "            fp = [1e-2]*self.numClasses\n",
    "            fn = [1e-2]*self.numClasses\n",
    "            f1 = [0.]*self.numClasses\n",
    "            for j, tree in enumerate(trees):\n",
    "                predictions,_ = self.getLoss(tree.root)\n",
    "#                     print((predictions.cpu().data).numpy(),(predictions.cpu().data).numpy().shape)\n",
    "#                     print((self.labelList.cpu().data).numpy(), (self.labelList.cpu().data).numpy().shape)\n",
    "                correct = ((predictions.cpu().data).numpy()==(self.labelList.cpu().data).numpy())\n",
    "#                     print(correct)\n",
    "                correctAll += correct.sum()\n",
    "                nAll += np.shape(correct.squeeze())[0] if np.size(correct)!=1 else 1 \n",
    "                correctRoot += correct.squeeze()[-1] if np.size(correct)!=1 else correct[-1]\n",
    "#                     print(correct.squeeze()[-1] if np.size(correct)!=1 else correct[-1])\n",
    "#                     print('actual: {}'.format(tree.root.label))\n",
    "                for i in range(self.numClasses):\n",
    "                    size = np.size((predictions.cpu().data).numpy())\n",
    "                    if size!=1:\n",
    "                        pred = (predictions.cpu().data).numpy().squeeze()[-1]\n",
    "                        actual = (self.labelList.cpu().data).numpy().squeeze()[-1]\n",
    "                    else:\n",
    "                        pred = (predictions.cpu().data).numpy()[-1]\n",
    "                        actual = (self.labelList.cpu().data).numpy()[-1]\n",
    "                    if pred==i and actual==i:\n",
    "                        tp[i]+=1\n",
    "                    elif pred==i and actual!=i:\n",
    "                        fn[i]+=1\n",
    "                    elif pred==i and actual!=i:\n",
    "                        fp[i]+=1\n",
    "                n += 1\n",
    "                pbar.update(j)\n",
    "#             print(tp,fp,fn)\n",
    "            for i in range(self.numClasses):\n",
    "                p =(1.0*tp[i]/(tp[i]+fp[i]))\n",
    "                r =(1.0*tp[i]/(tp[i]+fn[i]))\n",
    "                f1[i] = (2*p*r)/(p+r)\n",
    "            pbar.finish()\n",
    "            return correctRoot / n, correctAll/nAll, f1\n",
    "\n",
    "    def eval_sent_lvl(self,trees,clf):\n",
    "        pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "        n = nAll = correctRoot = correctAll = 0.0\n",
    "        X_predict = []\n",
    "        Y_gold = []\n",
    "        for j, tree in enumerate(trees):\n",
    "            tree_rep = model.getRep(tree.root)\n",
    "            X_predict.append(tree_rep)\n",
    "            Y_gold.append(tree.root.label)\n",
    "        acc = clf.score(np.array(X_predict),np.array(Y_gold))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_trees = 'aadhar_test_trees.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(\"./trees/df_\"+file_trees, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = set(sum(df_train['tokens'],[]))\n",
    "\n",
    "word2idx = {}\n",
    "word2idx['UNK']=0\n",
    "i = 1\n",
    "for token in list(all_tokens):\n",
    "    word2idx[token] = i\n",
    "    i+=1\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: 'above',\n",
       " 2: 'accepts',\n",
       " 3: 'Palwal',\n",
       " 4: 'probably',\n",
       " 5: 'newspaper',\n",
       " 6: 'seamless',\n",
       " 7: 'schools',\n",
       " 8: 'training',\n",
       " 9: 'D',\n",
       " 10: 'diagnostic',\n",
       " 11: 'investment',\n",
       " 12: 'Prestige',\n",
       " 13: 'been',\n",
       " 14: 'pocket',\n",
       " 15: 'Belt',\n",
       " 16: 'maintain',\n",
       " 17: 'Neel',\n",
       " 18: 'say',\n",
       " 19: 'Drabu',\n",
       " 20: 'misplaced',\n",
       " 21: 'Called',\n",
       " 22: 'refund',\n",
       " 23: 'chairperson',\n",
       " 24: 'All',\n",
       " 25: 'aftereffects',\n",
       " 26: 'factories',\n",
       " 27: 'crippled',\n",
       " 28: 'tracks',\n",
       " 29: 'Kumaraswamy',\n",
       " 30: 'mood',\n",
       " 31: 'Bharatmala',\n",
       " 32: 'scenario',\n",
       " 33: 'scars',\n",
       " 34: 'rights',\n",
       " 35: 'blog',\n",
       " 36: 'schedule',\n",
       " 37: 'cattle',\n",
       " 38: 'accept',\n",
       " 39: 'havens',\n",
       " 40: 'Water',\n",
       " 41: 'cyber',\n",
       " 42: 'comprised',\n",
       " 43: 'Karzmaafi',\n",
       " 44: 'Telugu',\n",
       " 45: 'converting',\n",
       " 46: 'unaffected',\n",
       " 47: 'chants',\n",
       " 48: 'review',\n",
       " 49: 'free',\n",
       " 50: 'Kankarbagh',\n",
       " 51: 'liability',\n",
       " 52: 'tankers',\n",
       " 53: 'suspected',\n",
       " 54: 'normalcy',\n",
       " 55: 'survey',\n",
       " 56: 'capability',\n",
       " 57: 'mission',\n",
       " 58: 'formalising',\n",
       " 59: 'mind',\n",
       " 60: 'waives',\n",
       " 61: 'specifically',\n",
       " 62: 'Astodia',\n",
       " 63: 'devout',\n",
       " 64: 'Shivar',\n",
       " 65: 'protocols',\n",
       " 66: 'Mayawati',\n",
       " 67: 'contains',\n",
       " 68: 'corrupt',\n",
       " 69: 'focussed',\n",
       " 70: 'Pusa',\n",
       " 71: 'judiciously',\n",
       " 72: 'clients',\n",
       " 73: 'rationalised',\n",
       " 74: 'national',\n",
       " 75: 'Dcc',\n",
       " 76: 'senior',\n",
       " 77: 'challenging',\n",
       " 78: 'readiness',\n",
       " 79: 'committee',\n",
       " 80: 'crackdown',\n",
       " 81: 'riverfront',\n",
       " 82: 'Shakti',\n",
       " 83: 'projections',\n",
       " 84: 'clean',\n",
       " 85: 'northern',\n",
       " 86: 'Commonwealth',\n",
       " 87: 'residential',\n",
       " 88: 'Action',\n",
       " 89: 'offenders',\n",
       " 90: 'pipelines',\n",
       " 91: 'hoarded',\n",
       " 92: 'Stern',\n",
       " 93: 'Rolloutthe',\n",
       " 94: 'acting',\n",
       " 95: 'weighed',\n",
       " 96: 'fodder',\n",
       " 97: 'reality',\n",
       " 98: 'Often',\n",
       " 99: 'whenever',\n",
       " 100: 'cancellation',\n",
       " 101: 'equally',\n",
       " 102: 'grown',\n",
       " 103: 'assault',\n",
       " 104: 'Poll',\n",
       " 105: 'continue',\n",
       " 106: 'fault',\n",
       " 107: 'Flood',\n",
       " 108: 'folk',\n",
       " 109: 'relaxed',\n",
       " 110: 'kids',\n",
       " 111: 'Acre',\n",
       " 112: 'Lashing',\n",
       " 113: 'topic',\n",
       " 114: 'Allowing',\n",
       " 115: 'sic',\n",
       " 116: 'Photopointing',\n",
       " 117: 'mammoth',\n",
       " 118: 'weaker',\n",
       " 119: 'Spelling',\n",
       " 120: 'ponds',\n",
       " 121: 'thanks',\n",
       " 122: 'distributed',\n",
       " 123: 'Compensation',\n",
       " 124: 'Aadhaar',\n",
       " 125: 'improved',\n",
       " 126: 'corporate',\n",
       " 127: 'depend',\n",
       " 128: 'Uddhav',\n",
       " 129: 'cross',\n",
       " 130: 'giants',\n",
       " 131: 'Yadavthe',\n",
       " 132: 'scale',\n",
       " 133: 'moneylenders',\n",
       " 134: 'trove',\n",
       " 135: 'Lima',\n",
       " 136: 'pump',\n",
       " 137: 'degraded',\n",
       " 138: 'migrate',\n",
       " 139: 'vast',\n",
       " 140: 'expressed',\n",
       " 141: 'edition',\n",
       " 142: 'reported',\n",
       " 143: 'VIPs',\n",
       " 144: 'pull',\n",
       " 145: 'clarifications',\n",
       " 146: 'closely',\n",
       " 147: 'interlinking',\n",
       " 148: 'morning',\n",
       " 149: 'significant',\n",
       " 150: 'ordinance',\n",
       " 151: 'disturbed',\n",
       " 152: 'Pibprime',\n",
       " 153: 'Servicenew',\n",
       " 154: 'Former',\n",
       " 155: 'performing',\n",
       " 156: 'games',\n",
       " 157: 'platinum',\n",
       " 158: 'shifting',\n",
       " 159: 'IMF',\n",
       " 160: 'low',\n",
       " 161: 'drove',\n",
       " 162: 'parched',\n",
       " 163: 'pursuit',\n",
       " 164: 'Noteban',\n",
       " 165: 'mature',\n",
       " 166: 'Reddy',\n",
       " 167: 'technical',\n",
       " 168: 'requirements',\n",
       " 169: 'opposing',\n",
       " 170: 'conducting',\n",
       " 171: 'states',\n",
       " 172: 'Igps',\n",
       " 173: 'cheated',\n",
       " 174: 'nine',\n",
       " 175: 'gums',\n",
       " 176: 'wait',\n",
       " 177: 'conducted',\n",
       " 178: 'administering',\n",
       " 179: 'misery',\n",
       " 180: 'dams',\n",
       " 181: 'Businesses',\n",
       " 182: 'unlikely',\n",
       " 183: 'whereas',\n",
       " 184: 'drought',\n",
       " 185: 'forcible',\n",
       " 186: 'online',\n",
       " 187: 'output',\n",
       " 188: 'Ghaziapur',\n",
       " 189: 'pollution',\n",
       " 190: 'seminar',\n",
       " 191: 'cops',\n",
       " 192: 'groundwater',\n",
       " 193: 'pretending',\n",
       " 194: 'retired',\n",
       " 195: 'file',\n",
       " 196: 'Baghpat',\n",
       " 197: 'complaints',\n",
       " 198: 'Mitra',\n",
       " 199: 'accountants',\n",
       " 200: 'reports',\n",
       " 201: 'realise',\n",
       " 202: 'fell',\n",
       " 203: 'general',\n",
       " 204: 'state',\n",
       " 205: 'promising',\n",
       " 206: 'animals',\n",
       " 207: 'cereals',\n",
       " 208: 'payment',\n",
       " 209: 'habit',\n",
       " 210: 'deceived',\n",
       " 211: 'spending',\n",
       " 212: 'Tribals',\n",
       " 213: 'undertaking',\n",
       " 214: 'sideline',\n",
       " 215: 'samples',\n",
       " 216: 'talk',\n",
       " 217: 'submissions',\n",
       " 218: 'detected',\n",
       " 219: 'bottlenecks',\n",
       " 220: 'Pticongress',\n",
       " 221: 'operations',\n",
       " 222: 'disgruntled',\n",
       " 223: 'Agri',\n",
       " 224: 'Day',\n",
       " 225: 'Month',\n",
       " 226: 'institutional',\n",
       " 227: 'Levy',\n",
       " 228: 'Institutionalising',\n",
       " 229: 'points',\n",
       " 230: 'revolt',\n",
       " 231: 'connect',\n",
       " 232: 'depended',\n",
       " 233: 'Gadag',\n",
       " 234: 'Supreme',\n",
       " 235: 'announcements',\n",
       " 236: 'cabinet',\n",
       " 237: 'sow',\n",
       " 238: 'tariff',\n",
       " 239: 'city',\n",
       " 240: 'Shekhars',\n",
       " 241: 'up',\n",
       " 242: 'Hours',\n",
       " 243: 'succeeded',\n",
       " 244: 'regretted',\n",
       " 245: 'insurance',\n",
       " 246: 'while',\n",
       " 247: 'innocents',\n",
       " 248: 'ties',\n",
       " 249: 'input',\n",
       " 250: 'priority',\n",
       " 251: 'handling',\n",
       " 252: 'roses',\n",
       " 253: 'What',\n",
       " 254: 'hopefully',\n",
       " 255: 'policies',\n",
       " 256: 'Chikkaballapur',\n",
       " 257: 'transfers',\n",
       " 258: 'game',\n",
       " 259: 'expedition',\n",
       " 260: 'Stone',\n",
       " 261: 'Roughly',\n",
       " 262: 'rendered',\n",
       " 263: 'National',\n",
       " 264: 'Kau',\n",
       " 265: 'beneficiaries',\n",
       " 266: 'refinery',\n",
       " 267: 'Iststate',\n",
       " 268: 'pioneering',\n",
       " 269: 'Christmas',\n",
       " 270: 'disappointed',\n",
       " 271: 'vested',\n",
       " 272: 'celebration',\n",
       " 273: 'e',\n",
       " 274: 'seven',\n",
       " 275: 'sought',\n",
       " 276: 'arbitrary',\n",
       " 277: 'Brickbats',\n",
       " 278: 'officers',\n",
       " 279: 'dying',\n",
       " 280: 'indications',\n",
       " 281: 'Chairing',\n",
       " 282: 'queries',\n",
       " 283: 'Amritsar',\n",
       " 284: 'possible',\n",
       " 285: 'Mandsaur',\n",
       " 286: 'water',\n",
       " 287: 'develop',\n",
       " 288: 'urging',\n",
       " 289: 'sides',\n",
       " 290: 'willingly',\n",
       " 291: 'samba',\n",
       " 292: 'ONGC',\n",
       " 293: 'measure',\n",
       " 294: 'plunged',\n",
       " 295: 'loud',\n",
       " 296: 'akin',\n",
       " 297: 'personal',\n",
       " 298: 'chilly',\n",
       " 299: 'such',\n",
       " 300: 'respect',\n",
       " 301: 'entry',\n",
       " 302: 'facilities',\n",
       " 303: 'Istcm',\n",
       " 304: 'live',\n",
       " 305: 'Kalasa',\n",
       " 306: 'employ',\n",
       " 307: 'both',\n",
       " 308: 'hit',\n",
       " 309: 'Ruing',\n",
       " 310: 'adding',\n",
       " 311: 'Feb',\n",
       " 312: 'Naveenpatnaik',\n",
       " 313: 'Platform',\n",
       " 314: 'roost',\n",
       " 315: 'initiate',\n",
       " 316: 'representational',\n",
       " 317: 'apply',\n",
       " 318: 'Explaining',\n",
       " 319: 'tune',\n",
       " 320: 'businessmen',\n",
       " 321: 'Lucknow',\n",
       " 322: 'fun',\n",
       " 323: 'proud',\n",
       " 324: 'overview',\n",
       " 325: 'habitats',\n",
       " 326: 'information',\n",
       " 327: 'trap',\n",
       " 328: 'smuggling',\n",
       " 329: 'Gandhinagar',\n",
       " 330: 'Govenrment',\n",
       " 331: 'misused',\n",
       " 332: 'certified',\n",
       " 333: 'polling',\n",
       " 334: 'impinging',\n",
       " 335: 'wonders',\n",
       " 336: 'derail',\n",
       " 337: 'conceived',\n",
       " 338: 'calm',\n",
       " 339: 'difficulties',\n",
       " 340: 'received',\n",
       " 341: 'uses',\n",
       " 342: 'waivers',\n",
       " 343: 'recalibrated',\n",
       " 344: 'notice',\n",
       " 345: 'old',\n",
       " 346: 'control',\n",
       " 347: 'curry',\n",
       " 348: 'apprised',\n",
       " 349: 'honesty',\n",
       " 350: 'one',\n",
       " 351: 'recovered',\n",
       " 352: 'protect',\n",
       " 353: 'supplementary',\n",
       " 354: 'pitching',\n",
       " 355: 'readjust',\n",
       " 356: 'wasnt',\n",
       " 357: 'limited',\n",
       " 358: 'upsets',\n",
       " 359: 'factions',\n",
       " 360: 'Samaj',\n",
       " 361: 'similar',\n",
       " 362: 'properties',\n",
       " 363: 'nations',\n",
       " 364: 'runs',\n",
       " 365: 'scrapping',\n",
       " 366: 'terrorists',\n",
       " 367: 'throw',\n",
       " 368: 'curb',\n",
       " 369: 'bankrupt',\n",
       " 370: 'find',\n",
       " 371: 'rupee',\n",
       " 372: 'snatch',\n",
       " 373: 'address',\n",
       " 374: 'misusing',\n",
       " 375: 'Aninew',\n",
       " 376: 'merge',\n",
       " 377: 'air',\n",
       " 378: 'or',\n",
       " 379: 'owners',\n",
       " 380: 'despite',\n",
       " 381: 'Europe',\n",
       " 382: 'RAM',\n",
       " 383: 'finalised',\n",
       " 384: 'Santra',\n",
       " 385: 'rivals',\n",
       " 386: 'tide',\n",
       " 387: 'Ugrahan',\n",
       " 388: 'inaugurating',\n",
       " 389: 'homes',\n",
       " 390: 'accusing',\n",
       " 391: 'led',\n",
       " 392: 'comments',\n",
       " 393: 'purchasing',\n",
       " 394: 'rise',\n",
       " 395: 'principal',\n",
       " 396: 'triggering',\n",
       " 397: 'construction',\n",
       " 398: 'Gowda',\n",
       " 399: 'charging',\n",
       " 400: 'mandates',\n",
       " 401: 'operative',\n",
       " 402: 'constituency',\n",
       " 403: 'Tiruchy',\n",
       " 404: 'Sammelan',\n",
       " 405: 'integration',\n",
       " 406: 'instalments',\n",
       " 407: 'Apple',\n",
       " 408: 'agrarian',\n",
       " 409: 'expand',\n",
       " 410: 'wanted',\n",
       " 411: 'releasing',\n",
       " 412: 'plantation',\n",
       " 413: 'You',\n",
       " 414: 'ruling',\n",
       " 415: 'screen',\n",
       " 416: 'commercial',\n",
       " 417: 'looted',\n",
       " 418: 'arrived',\n",
       " 419: 'grievances',\n",
       " 420: 'subsuming',\n",
       " 421: 'Venkaiahnaidu',\n",
       " 422: 'choked',\n",
       " 423: 'trader',\n",
       " 424: 'East',\n",
       " 425: 'outskirts',\n",
       " 426: 'sixth',\n",
       " 427: 'guide',\n",
       " 428: 'unearthed',\n",
       " 429: 'Bharat',\n",
       " 430: 'sacrificing',\n",
       " 431: 'counterpart',\n",
       " 432: 'slowdown',\n",
       " 433: 'outreach',\n",
       " 434: 'divert',\n",
       " 435: 'economics',\n",
       " 436: 'let',\n",
       " 437: 'Cgst',\n",
       " 438: 'developed',\n",
       " 439: 'Clarifying',\n",
       " 440: 'Insurancepatna',\n",
       " 441: 'shook',\n",
       " 442: 'HDFC',\n",
       " 443: 'wants',\n",
       " 444: 'backfire',\n",
       " 445: 'article',\n",
       " 446: 'quell',\n",
       " 447: 'Ko',\n",
       " 448: 'off',\n",
       " 449: 'In',\n",
       " 450: 'system',\n",
       " 451: 'iron',\n",
       " 452: 'wore',\n",
       " 453: 'works',\n",
       " 454: 'easy',\n",
       " 455: 'Summitnew',\n",
       " 456: 'popularise',\n",
       " 457: 'dialogue',\n",
       " 458: 'highlights',\n",
       " 459: 'circumstance',\n",
       " 460: 'Rupaiyya',\n",
       " 461: 'utilise',\n",
       " 462: 'Bureaucracys',\n",
       " 463: 'realised',\n",
       " 464: 'joined',\n",
       " 465: 'efficiencies',\n",
       " 466: 'Pmsix',\n",
       " 467: 'unanimous',\n",
       " 468: 'issues',\n",
       " 469: 'supply',\n",
       " 470: 'RoC',\n",
       " 471: 'telling',\n",
       " 472: 'entails',\n",
       " 473: 'developing',\n",
       " 474: 'asserting',\n",
       " 475: 'angry',\n",
       " 476: 'market',\n",
       " 477: 'date',\n",
       " 478: 'directed',\n",
       " 479: 'MA',\n",
       " 480: 'Raizada',\n",
       " 481: 'entrepreneurship',\n",
       " 482: 'farms',\n",
       " 483: 'slammed',\n",
       " 484: 'partnering',\n",
       " 485: 'accurate',\n",
       " 486: 'goods',\n",
       " 487: 'Hit',\n",
       " 488: 'inflation',\n",
       " 489: 'Desh',\n",
       " 490: 'severe',\n",
       " 491: 'goals',\n",
       " 492: 'customer',\n",
       " 493: 'seeking',\n",
       " 494: 'transparent',\n",
       " 495: 'hysteria',\n",
       " 496: 'Kolkata',\n",
       " 497: 'malaise',\n",
       " 498: 'option',\n",
       " 499: 'very',\n",
       " 500: 'Afghan',\n",
       " 501: 'angered',\n",
       " 502: 'Amitshah',\n",
       " 503: 'rapturous',\n",
       " 504: 'holder',\n",
       " 505: 'histrionics',\n",
       " 506: 'background',\n",
       " 507: 'offerings',\n",
       " 508: 'aspirations',\n",
       " 509: 'draft',\n",
       " 510: 'Shrikant',\n",
       " 511: 'deaths',\n",
       " 512: 'chit',\n",
       " 513: 'twin',\n",
       " 514: 'leave',\n",
       " 515: 'ran',\n",
       " 516: 'complicated',\n",
       " 517: 'MLA',\n",
       " 518: 'Emphasising',\n",
       " 519: 'secretary',\n",
       " 520: 'months',\n",
       " 521: 'disappointment',\n",
       " 522: 'employee',\n",
       " 523: 'Countering',\n",
       " 524: 'held',\n",
       " 525: 'advancements',\n",
       " 526: 'notifications',\n",
       " 527: 'initiating',\n",
       " 528: 'shadow',\n",
       " 529: 'bullets',\n",
       " 530: 'integrate',\n",
       " 531: 'there',\n",
       " 532: 'inclusion',\n",
       " 533: 'increasing',\n",
       " 534: 'unit',\n",
       " 535: 'North',\n",
       " 536: 'govt',\n",
       " 537: 'controversial',\n",
       " 538: 'reforms',\n",
       " 539: 'surpasses',\n",
       " 540: 'fitment',\n",
       " 541: 'consistent',\n",
       " 542: 'lighter',\n",
       " 543: 'buy',\n",
       " 544: 'bankers',\n",
       " 545: 'unfit',\n",
       " 546: 'amenities',\n",
       " 547: 'managed',\n",
       " 548: 'economical',\n",
       " 549: 'investor',\n",
       " 550: 'homeless',\n",
       " 551: 'heads',\n",
       " 552: 'worried',\n",
       " 553: 'arose',\n",
       " 554: 'Ista',\n",
       " 555: 'amounting',\n",
       " 556: 'bilateral',\n",
       " 557: 'volatility',\n",
       " 558: 'clearance',\n",
       " 559: 'tool',\n",
       " 560: 'Aiib',\n",
       " 561: 'BI',\n",
       " 562: 'buyer',\n",
       " 563: 'valley',\n",
       " 564: 'unconcerned',\n",
       " 565: 'invent',\n",
       " 566: 'pilfered',\n",
       " 567: 'isolated',\n",
       " 568: 'several',\n",
       " 569: 'formality',\n",
       " 570: 'blamed',\n",
       " 571: 'We',\n",
       " 572: 'subsidised',\n",
       " 573: 'lakh',\n",
       " 574: 'pesticides',\n",
       " 575: 'hours',\n",
       " 576: 'prepared',\n",
       " 577: 'terrorist',\n",
       " 578: 'linking',\n",
       " 579: 'toto',\n",
       " 580: 'F',\n",
       " 581: 'more',\n",
       " 582: 'philosophy',\n",
       " 583: 'addressed',\n",
       " 584: 'repayment',\n",
       " 585: 'Special',\n",
       " 586: 'countrymen',\n",
       " 587: 'Inclusionmumbai',\n",
       " 588: 'Ballari',\n",
       " 589: 'Dodhia',\n",
       " 590: 'track',\n",
       " 591: 'transplantation',\n",
       " 592: 'Gfpc',\n",
       " 593: 'Wednesday',\n",
       " 594: 'Jharkhands',\n",
       " 595: 'princely',\n",
       " 596: 'Jalyukt',\n",
       " 597: 'activate',\n",
       " 598: 'never',\n",
       " 599: 'compelling',\n",
       " 600: 'houses',\n",
       " 601: 'spells',\n",
       " 602: 'solar',\n",
       " 603: 'commission',\n",
       " 604: 'Bmr',\n",
       " 605: 'significantly',\n",
       " 606: 'wo',\n",
       " 607: 'count',\n",
       " 608: 'remembered',\n",
       " 609: 'sales',\n",
       " 610: 'infiltrators',\n",
       " 611: 'align',\n",
       " 612: 'setback',\n",
       " 613: 'robbery',\n",
       " 614: 'alternatives',\n",
       " 615: 'Faridkot',\n",
       " 616: 'catchment',\n",
       " 617: 'Politicise',\n",
       " 618: 'identify',\n",
       " 619: 'chance',\n",
       " 620: 'agitation',\n",
       " 621: 'historic',\n",
       " 622: 'LR',\n",
       " 623: 'result',\n",
       " 624: 'pummelling',\n",
       " 625: 'ready',\n",
       " 626: 'deepen',\n",
       " 627: 'Farmersbelagavi',\n",
       " 628: 'pharmaceuticals',\n",
       " 629: 'Sericulture',\n",
       " 630: 'severly',\n",
       " 631: 'hour',\n",
       " 632: 'counselling',\n",
       " 633: 'easily',\n",
       " 634: 'window',\n",
       " 635: 'associates',\n",
       " 636: 'span',\n",
       " 637: 'Punjabi',\n",
       " 638: 'Formalisation',\n",
       " 639: 'support',\n",
       " 640: 'bus',\n",
       " 641: 'recovery',\n",
       " 642: 'rendering',\n",
       " 643: 'listening',\n",
       " 644: 'Similarly',\n",
       " 645: 'narrated',\n",
       " 646: 'independent',\n",
       " 647: 'printing',\n",
       " 648: 'merger',\n",
       " 649: 'Komul',\n",
       " 650: 'camps',\n",
       " 651: 'rectifying',\n",
       " 652: 'pragmatic',\n",
       " 653: 'receipt',\n",
       " 654: 'waging',\n",
       " 655: 'railway',\n",
       " 656: 'heavily',\n",
       " 657: 'Bundelkhand',\n",
       " 658: 'requires',\n",
       " 659: 'empower',\n",
       " 660: 'photo',\n",
       " 661: 'cruelty',\n",
       " 662: 'Speaking',\n",
       " 663: 'formed',\n",
       " 664: 'crores',\n",
       " 665: 'Chhattisgarh',\n",
       " 666: 'grains',\n",
       " 667: 'enhanced',\n",
       " 668: 'early',\n",
       " 669: 'stage',\n",
       " 670: 'republic',\n",
       " 671: 'committed',\n",
       " 672: 'kicking',\n",
       " 673: 'positives',\n",
       " 674: 'Empowerment',\n",
       " 675: 'Ravi',\n",
       " 676: 'adviser',\n",
       " 677: 'flustered',\n",
       " 678: 'Pathankot',\n",
       " 679: 'booths',\n",
       " 680: 'train',\n",
       " 681: 'Bharataiya',\n",
       " 682: 'own',\n",
       " 683: 'roadshow',\n",
       " 684: 'formal',\n",
       " 685: 'wages',\n",
       " 686: 'Loans',\n",
       " 687: 'custodian',\n",
       " 688: 'midnight',\n",
       " 689: 'Economic',\n",
       " 690: 'CSIR',\n",
       " 691: 'Dmks',\n",
       " 692: 'temporary',\n",
       " 693: 'genuine',\n",
       " 694: 'PepsiCo',\n",
       " 695: 'saw',\n",
       " 696: 'swoop',\n",
       " 697: 'manure',\n",
       " 698: 'Unfazed',\n",
       " 699: 'contesting',\n",
       " 700: 'came',\n",
       " 701: 'rollout',\n",
       " 702: 'soil',\n",
       " 703: 'ended',\n",
       " 704: 'norms',\n",
       " 705: 'northeastern',\n",
       " 706: 'Istseeking',\n",
       " 707: 'Apeda',\n",
       " 708: 'cleanliness',\n",
       " 709: 'compared',\n",
       " 710: 'par',\n",
       " 711: 'laws',\n",
       " 712: 'indelible',\n",
       " 713: 'run',\n",
       " 714: 'improper',\n",
       " 715: 'unlimited',\n",
       " 716: 'dipped',\n",
       " 717: 'rescue',\n",
       " 718: 'capable',\n",
       " 719: 'BIMA',\n",
       " 720: 'fate',\n",
       " 721: 'multinational',\n",
       " 722: 'exemption',\n",
       " 723: 'compel',\n",
       " 724: 'Utsav',\n",
       " 725: 'Newsemphasizing',\n",
       " 726: 'Currency',\n",
       " 727: 'Jaitley',\n",
       " 728: 'renovated',\n",
       " 729: 'Muslim',\n",
       " 730: 'households',\n",
       " 731: 'ration',\n",
       " 732: 'Districtssinking',\n",
       " 733: 'swearing',\n",
       " 734: 'media',\n",
       " 735: 'conspiring',\n",
       " 736: 'sent',\n",
       " 737: 'participation',\n",
       " 738: 'oath',\n",
       " 739: 'colluding',\n",
       " 740: 'But',\n",
       " 741: 'hardware',\n",
       " 742: 'occupied',\n",
       " 743: 'doles',\n",
       " 744: 'resilient',\n",
       " 745: 'trickle',\n",
       " 746: 'victory',\n",
       " 747: 'storage',\n",
       " 748: 'firmly',\n",
       " 749: 'offs',\n",
       " 750: 'realized',\n",
       " 751: 'fly',\n",
       " 752: 'confiscation',\n",
       " 753: 'feasibility',\n",
       " 754: 'rapport',\n",
       " 755: 'sentiment',\n",
       " 756: 'asked',\n",
       " 757: 'Defence',\n",
       " 758: 'miniscule',\n",
       " 759: 'return',\n",
       " 760: 'domestically',\n",
       " 761: 'gearing',\n",
       " 762: 'forming',\n",
       " 763: 'Western',\n",
       " 764: 'applause',\n",
       " 765: 'Repeating',\n",
       " 766: 'S',\n",
       " 767: 'going',\n",
       " 768: 'Issue',\n",
       " 769: 'delegation',\n",
       " 770: 'prodded',\n",
       " 771: 'selective',\n",
       " 772: 'Pms',\n",
       " 773: 'Despite',\n",
       " 774: 'quarters',\n",
       " 775: 'stated',\n",
       " 776: 'slide',\n",
       " 777: 'along',\n",
       " 778: 'Northeast',\n",
       " 779: 'extradite',\n",
       " 780: 'Limiting',\n",
       " 781: 'fill',\n",
       " 782: 'narrowed',\n",
       " 783: 'vis',\n",
       " 784: 'diamond',\n",
       " 785: 'Constitution',\n",
       " 786: 'grip',\n",
       " 787: 'classes',\n",
       " 788: 'stopped',\n",
       " 789: 'BCS',\n",
       " 790: 'driven',\n",
       " 791: 'stabilise',\n",
       " 792: 'Court',\n",
       " 793: 'relaxation',\n",
       " 794: 'fiery',\n",
       " 795: 'assume',\n",
       " 796: 'views',\n",
       " 797: 'businessman',\n",
       " 798: 'launch',\n",
       " 799: 'marketplace',\n",
       " 800: 'sensitivity',\n",
       " 801: 'Nair',\n",
       " 802: 'corporates',\n",
       " 803: 'consultants',\n",
       " 804: 'Sunil',\n",
       " 805: 'watch',\n",
       " 806: 'testimony',\n",
       " 807: 'multi',\n",
       " 808: 'direction',\n",
       " 809: 'Expressing',\n",
       " 810: 'trains',\n",
       " 811: 'MMF',\n",
       " 812: 'bumper',\n",
       " 813: 'runaway',\n",
       " 814: 'veterinary',\n",
       " 815: 'not',\n",
       " 816: 'tariffs',\n",
       " 817: 'intermittent',\n",
       " 818: 'Hindu',\n",
       " 819: 'assistance',\n",
       " 820: 'audience',\n",
       " 821: 'inauguration',\n",
       " 822: 'uproot',\n",
       " 823: 'pertaining',\n",
       " 824: 'Council',\n",
       " 825: 'implementations',\n",
       " 826: 'hydrocarbon',\n",
       " 827: 'Apmc',\n",
       " 828: 'Meghwal',\n",
       " 829: 'effective',\n",
       " 830: 'greater',\n",
       " 831: 'brining',\n",
       " 832: 'ministers',\n",
       " 833: 'decades',\n",
       " 834: 'industrial',\n",
       " 835: 'voters',\n",
       " 836: 'political',\n",
       " 837: 'stabilisation',\n",
       " 838: 'Amrg',\n",
       " 839: 'isolation',\n",
       " 840: 'ruining',\n",
       " 841: 'negative',\n",
       " 842: 'potatoes',\n",
       " 843: 'T',\n",
       " 844: 'flexibility',\n",
       " 845: 'Flanked',\n",
       " 846: 'Ncp',\n",
       " 847: 'students',\n",
       " 848: 'festivities',\n",
       " 849: 'bit',\n",
       " 850: 'sale',\n",
       " 851: 'Sgst',\n",
       " 852: 'scope',\n",
       " 853: 'contract',\n",
       " 854: 'wilted',\n",
       " 855: 'preservation',\n",
       " 856: 'owing',\n",
       " 857: 'Upgradation',\n",
       " 858: 'agenda',\n",
       " 859: 'Noting',\n",
       " 860: 'Urgently',\n",
       " 861: 'stiff',\n",
       " 862: 'deeper',\n",
       " 863: 'organised',\n",
       " 864: 'cooperation',\n",
       " 865: 'extent',\n",
       " 866: 'waged',\n",
       " 867: 'CR',\n",
       " 868: 'Mandakalli',\n",
       " 869: 'bills',\n",
       " 870: 'Befool',\n",
       " 871: 'pledged',\n",
       " 872: 'invoice',\n",
       " 873: 'reversal',\n",
       " 874: 'behead',\n",
       " 875: 'vain',\n",
       " 876: 'Istbenefiting',\n",
       " 877: 'mea',\n",
       " 878: 'Midnapore',\n",
       " 879: 'aimed',\n",
       " 880: 'treated',\n",
       " 881: 'Teaotia',\n",
       " 882: 'range',\n",
       " 883: 'strongly',\n",
       " 884: 'composite',\n",
       " 885: 'database',\n",
       " 886: 'clubs',\n",
       " 887: 'humbly',\n",
       " 888: 'availability',\n",
       " 889: 'attentions',\n",
       " 890: 'assess',\n",
       " 891: 'exports',\n",
       " 892: 'sake',\n",
       " 893: 'framed',\n",
       " 894: 'corresponding',\n",
       " 895: 'slew',\n",
       " 896: 'Adhia',\n",
       " 897: 'didnt',\n",
       " 898: 'disarray',\n",
       " 899: 'misinterpreted',\n",
       " 900: 'fraud',\n",
       " 901: 'got',\n",
       " 902: 'Tent',\n",
       " 903: 'sentiments',\n",
       " 904: 'Saidon',\n",
       " 905: 'wipe',\n",
       " 906: 'goal',\n",
       " 907: 'Kisan',\n",
       " 908: 'Saharanpur',\n",
       " 909: 'Prashant',\n",
       " 910: 'victim',\n",
       " 911: 'possibility',\n",
       " 912: 'vendors',\n",
       " 913: 'used',\n",
       " 914: 'fighting',\n",
       " 915: 'hoarders',\n",
       " 916: 'engineering',\n",
       " 917: 'POS',\n",
       " 918: 'ripples',\n",
       " 919: 'countrys',\n",
       " 920: 'compromised',\n",
       " 921: 'Thursday',\n",
       " 922: 'highest',\n",
       " 923: 'trucks',\n",
       " 924: 'terminate',\n",
       " 925: 'feedback',\n",
       " 926: 'Nationalist',\n",
       " 927: 'n',\n",
       " 928: 'heres',\n",
       " 929: 'Commending',\n",
       " 930: 'Istcongress',\n",
       " 931: 'stations',\n",
       " 932: 'taken',\n",
       " 933: 'Govt',\n",
       " 934: 'occasion',\n",
       " 935: 'grabbing',\n",
       " 936: 'wiped',\n",
       " 937: 'dual',\n",
       " 938: 'buying',\n",
       " 939: 'sums',\n",
       " 940: 'onion',\n",
       " 941: 'described',\n",
       " 942: 'However',\n",
       " 943: 'disposal',\n",
       " 944: 'turn',\n",
       " 945: 'employees',\n",
       " 946: 'approve',\n",
       " 947: 'serve',\n",
       " 948: 'methods',\n",
       " 949: 'IPC',\n",
       " 950: 'days',\n",
       " 951: 'explain',\n",
       " 952: 'producing',\n",
       " 953: 'fight',\n",
       " 954: 'point',\n",
       " 955: 'Nagpur',\n",
       " 956: 'refunding',\n",
       " 957: 'Gstin',\n",
       " 958: 'Palnar',\n",
       " 959: 'happening',\n",
       " 960: 'room',\n",
       " 961: 'measuring',\n",
       " 962: 'reservation',\n",
       " 963: 'Initiativehyderabad',\n",
       " 964: 'MSP',\n",
       " 965: 'loss',\n",
       " 966: 'start',\n",
       " 967: 'identified',\n",
       " 968: 'happen',\n",
       " 969: 'resignation',\n",
       " 970: 'Iims',\n",
       " 971: 'assets',\n",
       " 972: 'joint',\n",
       " 973: 'involve',\n",
       " 974: 'eventually',\n",
       " 975: 'Agriculture',\n",
       " 976: 'last',\n",
       " 977: 'injustice',\n",
       " 978: 'Cm',\n",
       " 979: 'Aidguwahati',\n",
       " 980: 'desired',\n",
       " 981: 'textiles',\n",
       " 982: 'Doing',\n",
       " 983: 'Lauding',\n",
       " 984: 'eligible',\n",
       " 985: 'defeat',\n",
       " 986: 'Arunjaitley',\n",
       " 987: 'quality',\n",
       " 988: 'developmental',\n",
       " 989: 'solving',\n",
       " 990: 'six',\n",
       " 991: 'growers',\n",
       " 992: 'Das',\n",
       " 993: 'cancelled',\n",
       " 994: 'surgical',\n",
       " 995: 'incidents',\n",
       " 996: 'was',\n",
       " 997: 'Biodiversity',\n",
       " 998: 'consultancy',\n",
       " 999: 'sports',\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fine tuned embeddings . .\n",
      "Loading economic-word2vec-ner\n"
     ]
    }
   ],
   "source": [
    "if not w2vec:\n",
    "    print(\"Using fine tuned embeddings . .\")\n",
    "    if economic:\n",
    "        if ner:\n",
    "            print(\"Loading economic-word2vec-ner\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/economic-word2vec-ner')\n",
    "        elif blackout:\n",
    "            print(\"Loading economic-word2vec-blackout\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/economic-word2vec-blackout')\n",
    "        else:\n",
    "            print(\"Loading economic-word2vec\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/economic-word2vec')\n",
    "    else:\n",
    "        if ner:\n",
    "            print(\"Loading tech-word2vec-ner\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/tech-word2vec-ner')\n",
    "        elif blackout:\n",
    "            print(\"Loading tech-word2vec-blackout\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/tech-word2vec-blackout')\n",
    "        else:\n",
    "            print(\"Loading tech-word2vec\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('Users/navreetkaur/MTP/finetune-word2vec/w2v-models/tech-word2vec')\n",
    "    \n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[This, apathy, is, hitting, farmers, hard, sai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Rajender, said, that, while, supporting, the,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[On, charges, of, AP, copying, Telangana, sche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Crediting, the, small, and, medium, farmers, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[file, photo, at, a, public, meeting, on, Mond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  target\n",
       "0  [This, apathy, is, hitting, farmers, hard, sai...       0\n",
       "1  [Rajender, said, that, while, supporting, the,...       0\n",
       "2  [On, charges, of, AP, copying, Telangana, sche...       1\n",
       "3  [Crediting, the, small, and, medium, farmers, ...       1\n",
       "4  [file, photo, at, a, public, meeting, on, Mond...       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = np.zeros((len(idx2word), word2vec_model.vector_size))\n",
    "\n",
    "for idx, word in idx2word.items():\n",
    "    if not w2vec:\n",
    "        try: \n",
    "            embed[idx] = unbiased_in_domain_model[word]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                embed[idx] = word2vec_model[word]\n",
    "            except:\n",
    "                embed[idx] = np.random.normal(size=(word2vec_model.vector_size, ))\n",
    "    else:\n",
    "        try:\n",
    "            embed[idx] = word2vec_model[word]\n",
    "        except:\n",
    "            embed[idx] = np.random.normal(size=(word2vec_model.vector_size, ))\n",
    "        \n",
    "embed = torch.from_numpy(embed)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[This, apathy, is, hitting, farmers, hard, sai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Rajender, said, that, while, supporting, the,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[On, charges, of, AP, copying, Telangana, sche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Crediting, the, small, and, medium, farmers, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[file, photo, at, a, public, meeting, on, Mond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  target\n",
       "0  [This, apathy, is, hitting, farmers, hard, sai...       0\n",
       "1  [Rajender, said, that, while, supporting, the,...       0\n",
       "2  [On, charges, of, AP, copying, Telangana, sche...       1\n",
       "3  [Crediting, the, small, and, medium, farmers, ...       1\n",
       "4  [file, photo, at, a, public, meeting, on, Mond...       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    1759\n",
       "1    1759\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6901, 300]), 6901)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape, len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(text):\n",
    "#     print(text)\n",
    "    output = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,depparse,parse',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    output = literal_eval(output)\n",
    "    try:\n",
    "        tree = str(output['sentences'][0]['parse'])\n",
    "    except:\n",
    "        print(output,text)\n",
    "        return\n",
    "    # print (tree)\n",
    "    parse_string = ' '.join(str(tree).split())\n",
    "    # print(parse_string)\n",
    "    # print (\"\\n\\n\")\n",
    "    tree = nltk.tree.Tree.fromstring(parse_string)\n",
    "    tree.chomsky_normal_form()\n",
    "    tree.collapse_unary(collapseRoot=True,collapsePOS=True)\n",
    "    nt = convertNLTK_tree(tree)\n",
    "    return nt\n",
    "\n",
    "def printLabelTree(tree):\n",
    "    def inorder(node,nnode):\n",
    "        if node.isLeaf:\n",
    "            newnode = pptree.Node('H',nnode)\n",
    "            wnode = pptree.Node(node.word,newnode)\n",
    "        elif nnode is not None:\n",
    "            newnode = pptree.Node('H',nnode)\n",
    "            inorder(node.left,newnode)\n",
    "            inorder(node.right,newnode)\n",
    "        elif node.isRoot():\n",
    "            newnode = pptree.Node('H')\n",
    "            inorder(node.left,newnode)\n",
    "            inorder(node.right,newnode)\n",
    "            return newnode\n",
    "        return None\n",
    "    pptree.print_tree(inorder(tree.root,None))\n",
    "\n",
    "def create_trees_using_df(df):\n",
    "    tree = []\n",
    "    for tokens in list(df['tokens']):\n",
    "        if len(tokens)==0:\n",
    "            continue\n",
    "        line = ' '.join(tokens)\n",
    "        line += '\\n'\n",
    "        tree.append(make_tree(line))\n",
    "    return tree\n",
    "\n",
    "def printlabel(root,l):\n",
    "    if root:\n",
    "        l.append(root.label)\n",
    "#         print(root.label)\n",
    "        if root.left:\n",
    "            l+=printlabel(root.left,[])\n",
    "#             print(printlabel(root.left))\n",
    "        if root.right:\n",
    "            l+=printlabel(root.right,[])\n",
    "#             print(printlabel(root.right))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = StanfordCoreNLP('http://localhost', port=9000,timeout=90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral = create_trees_using_df(df_train[df_train.target == 0])\n",
    "# anti = create_trees_using_df(df_train[df_train.target == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_neutral = create_trees_using_df(df_train[df_train.target == 1])\n",
    "# pro = create_trees_using_df(df_train[df_train.target == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral_test = create_trees_using_df(df_test[df_test.target == 0])\n",
    "# non_neutral_test = create_trees_using_df(df_test[df_test.target == 1])\n",
    "# anti_test = create_trees_using_df(df_test[df_test.target == 0])\n",
    "# pro_test = create_trees_using_df(df_test[df_test.target == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout = open(file_trees,'wb')\n",
    "# pickle.dump([pro, anti],fout)\n",
    "# fout.close()\n",
    "# fout = open(file_trees+\"_test\",'wb')\n",
    "# pickle.dump([pro_test, anti_test],fout)\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pro,anti] = pickle.load(open(os.path.join('./trees',file_trees),'rb'))\n",
    "[pro_test,anti_test] = pickle.load(open(os.path.join('./trees',file_trees+\"_test\"),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout = open(file_trees,'wb')\n",
    "# pickle.dump([neutral, non_neutral],fout)\n",
    "# fout.close()\n",
    "# fout = open(file_trees+'_test','wb')\n",
    "# pickle.dump([neutral_test, non_neutral_test],fout)\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1759, 1759, 168, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pro), len(anti), len(pro_test), len(anti_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA=False\n",
    "def Var(v):\n",
    "    if CUDA: return Variable(v.cuda())\n",
    "    else: return Variable(v)\n",
    "    \n",
    "trees = []\n",
    "raw_words = []\n",
    "vocab = []\n",
    "\n",
    "# print(\"Loading trees...\")\n",
    "# [neutral, non_neutral] = pickle.load(open(file_trees,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for neutral_tree in neutral:\n",
    "#     neutral_tree.root.set_label('neutral')\n",
    "# for non_neutral_tree in non_neutral:\n",
    "#     non_neutral_tree.root.set_label('non_neutral')\n",
    "    \n",
    "for pro_tree in pro:\n",
    "    pro_tree.root.set_label('pro')\n",
    "for anti_tree in anti:\n",
    "    anti_tree.root.set_label('anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for neutral_tree in neutral_test:\n",
    "#     neutral_tree.root.set_label('neutral')\n",
    "# for non_neutral_tree in non_neutral_test:\n",
    "#     non_neutral_tree.root.set_label('non_neutral')\n",
    "    \n",
    "for pro_tree in pro_test:\n",
    "    pro_tree.root.set_label('pro')\n",
    "for anti_tree in anti_test:\n",
    "    anti_tree.root.set_label('anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(neutral,non_neutral):\n",
    "    trees = []\n",
    "    trees.extend(neutral)\n",
    "    trees.extend(non_neutral)\n",
    "    random.shuffle(trees)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytree import *\n",
    "from treeUtil import *\n",
    "# from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "val = {'pro':0,'anti':1,'default':-1}\n",
    "\n",
    "# pro:1, anti:0, neutral:2\n",
    "val_all = {'pro':1,'anti':0,'default':-1,'neutral':2}\n",
    "# neutral:0, non-neutral:1\n",
    "val_neutral = {'neutral':0, 'non_neutral':1, 'default':-1}\n",
    "\n",
    "\n",
    "def convert(T):\n",
    "    label = val[T.label] if (hasattr(T,'label')) else None\n",
    "    print(label)\n",
    "    newTree = convert_primary_new(T,label)\n",
    "    annotate_all(newTree)\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convert_neutral(T):\n",
    "    label = val_neutral[T.label] if (hasattr(T,'label')) else None\n",
    "    print(label)\n",
    "    newTree = convert_primary_new(T,label)\n",
    "    annotate_all(newTree)\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convert_all(T):\n",
    "    label = val_all[T.label] if (hasattr(T,'label')) else None\n",
    "    print(label)\n",
    "    newTree = convert_primary_new(T,label)\n",
    "    annotate_all(newTree)\n",
    "\n",
    "    return newTree\n",
    "\n",
    "\n",
    "def convert_primary(T):\n",
    "    if (hasattr(T,'label')):\n",
    "        print(T.label) \n",
    "    label = val[T.label] if (hasattr(T,'label')) else None\n",
    "    # label = val[T.label] if (hasattr(T,'label') ) else None # changed for ignoring neutral\n",
    "\n",
    "    if isinstance(T,leafObj):\n",
    "        newTree = Node(label,T.word,T.pos)\n",
    "        newTree.isLeaf = True\n",
    "        return newTree\n",
    "    else:\n",
    "        newTree = Node(label)\n",
    "    \n",
    "    leftChild = convert_primary(T.c1)\n",
    "    rightChild = convert_primary(T.c2)\n",
    "    leftChild.parent = newTree\n",
    "    rightChild.parent = newTree\n",
    "\n",
    "    newTree.left = leftChild\n",
    "    newTree.right = rightChild\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convert_primary_new(T,label):\n",
    "    # from IPython import embed; embed()\n",
    "    if T is None:\n",
    "        return None\n",
    "    # label = val[T.label] if (hasattr(T,'label') ) else None # changed for ignoring neutral\n",
    "    T.set_label(label)\n",
    "    # if (T.isLeaf) : print (T.word)\n",
    "\n",
    "    T.left = convert_primary_new(T.left,label)\n",
    "    T.right = convert_primary_new(T.right,label)\n",
    "\n",
    "    return T\n",
    "\n",
    "    # if T.isLeaf:\n",
    "    #     newTree = Node(label,T.word,T.pos)\n",
    "    #     newTree.isLeaf = True\n",
    "    #     return newTree\n",
    "    # else:\n",
    "    #     newTree = Node(label)\n",
    "    \n",
    "    # leftChild = convert_primary_new(T.left)\n",
    "    # rightChild = convert_primary_new(T.right)\n",
    "    # leftChild.parent = newTree\n",
    "    # rightChild.parent = newTree\n",
    "\n",
    "    # newTree.left = leftChild\n",
    "    # newTree.right = rightChild\n",
    "\n",
    "    # return newTree\n",
    "\n",
    "def convertNLTK_tree_primary(tree):\n",
    "    if tree.height()==2:\n",
    "        newTree = Node('default',tree[0],None)\n",
    "        newTree.isLeaf = True\n",
    "        return newTree\n",
    "    newTree = Node('default')\n",
    "    leftChild = convertNLTK_tree_primary(tree[0])\n",
    "    rightChild = convertNLTK_tree_primary(tree[1])\n",
    "    \n",
    "    leftChild.parent = newTree\n",
    "    rightChild.parent = newTree\n",
    "\n",
    "    newTree.left = leftChild\n",
    "    newTree.right = rightChild\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convertNLTK_tree(tree):\n",
    "    return Tree(convertNLTK_tree_primary(tree))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def annotate_all(T):\n",
    "    if T == None: return\n",
    "    if T.label != None : \n",
    "        T.annotated = True\n",
    "    else:\n",
    "        T.annotated = False\n",
    "        T.set_label(T.parent.label)\n",
    "    annotate_all(T.left)\n",
    "    annotate_all(T.right)\n",
    "\n",
    "def buildBalTree(sent):\n",
    "    words = sent.split(' ')\n",
    "\n",
    "    nodes = words\n",
    "\n",
    "    while len(nodes)>1:\n",
    "        temp = []\n",
    "        for i in range(0,len(nodes),2):\n",
    "            lChild = Node(None,nodes[i],None) if isinstance(nodes[i],str) else nodes[i]\n",
    "            if i+1<len(nodes):\n",
    "                rChild = Node(None,nodes[i+1],None) if isinstance(nodes[i+1],str) else nodes[i+1]\n",
    "            else:\n",
    "                rChild = None\n",
    "            if isinstance(nodes[i],str):\n",
    "                lChild.isLeaf = True\n",
    "                if rChild is not None:\n",
    "                    rChild.isLeaf = True\n",
    "            newNode = Node(None)\n",
    "            lChild.parent = newNode\n",
    "            newNode.left = lChild\n",
    "            newNode.right = rChild\n",
    "            if rChild is not None:\n",
    "                rChild.parent = newNode\n",
    "            temp.append(newNode)\n",
    "        nodes=temp\n",
    "    return Tree(nodes[0])\n",
    "\n",
    "def readFile2Trees(filename):\n",
    "    trees = []\n",
    "    with open(filename,'r') as file:\n",
    "        for line in file:\n",
    "            if line=='\\n':\n",
    "                continue\n",
    "            else:\n",
    "                [labelname,sent] = line.split(': ',1)\n",
    "                tree = buildBalTree(sent)\n",
    "                tree.root.set_label(val[labelname])\n",
    "                if val[labelname]!=2:\n",
    "                    trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# trees = combine(neutral, non_neutral)\n",
    "trees = combine(pro,anti)\n",
    "data = []\n",
    "for i in range(len(trees)):\n",
    "    data.append(Tree(convert(trees[i].root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# trees_test = combine(neutral_test, non_neutral_test)\n",
    "trees_test = combine(pro_test,anti_test)\n",
    "data_test = []\n",
    "for i in range(len(trees_test)):\n",
    "    data_test.append(Tree(convert(trees_test[i].root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA: model = RecursiveNN(embed,word2idx).cuda()\n",
    "else: model = RecursiveNN(embed,word2idx)\n",
    "max_epochs = 100\n",
    "widgets = [progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]\n",
    "l2_reg = {  'embedding.weight' : 1e-6,'W.weight' : 1e-4,'W.bias' : 1e-4,'projection.weight' : 1e-3,'projection.bias' : 1e-3}\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn,dev = data[:int((len(data)+1)*.85)],data[int(len(data)*.85+1):]\n",
    "# len(data), len(trn), len(dev)\n",
    "trn = data\n",
    "dev = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3518, 202)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Start logging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, dampening=0.0)\n",
    "# bestAll=bestRoot=0.0\n",
    "global count\n",
    "count=0\n",
    "BATCH_SIZE = 128\n",
    "# optimizer = torch.optim.LBFGS(model.parameters(), lr=0.5, max_iter=10, history_size = 10)\n",
    "bestAll=bestRoot=0.0\n",
    "bestF1_0=bestF1_1=best_trn_F1_0=best_trn_F1_1=0.0\n",
    "best_trn_All = best_trn_Root = 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0\n",
      "Loss =  tensor([30.9657])\n",
      "Loss =  tensor([33.2879])\n",
      "Loss =  tensor([32.7264])\n",
      "Loss =  tensor([31.4560])\n",
      "Loss =  tensor([31.4834])\n",
      "Loss =  tensor([32.0511])\n",
      "Loss =  tensor([32.9013])\n",
      "Loss =  tensor([30.8452])\n",
      "Loss =  tensor([31.4783])\n",
      "Loss =  tensor([31.7555])\n",
      "Loss =  tensor([31.0003])\n",
      "Loss =  tensor([32.7524])\n",
      "Loss =  tensor([32.0597])\n",
      "Loss =  tensor([34.1536])\n",
      "Loss =  tensor([31.1885])\n",
      "Loss =  tensor([32.6059])\n",
      "Loss =  tensor([31.8438])\n",
      "Loss =  tensor([33.2202])\n",
      "Loss =  tensor([32.1188])\n",
      "Loss =  tensor([31.0252])\n",
      "Loss =  tensor([33.0678])\n",
      "Loss =  tensor([31.9935])\n",
      "Loss =  tensor([31.8638])\n",
      "Loss =  tensor([31.4006])\n",
      "Loss =  tensor([32.7812])\n",
      "Loss =  tensor([32.3434])\n",
      "Loss =  tensor([31.7190])\n",
      "Loss =  tensor([32.8099])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.32(best:0.32)\n",
      "Validation Root accuracy:0.29(best:0.29)\n",
      "F1:[0.96, 0.31](best:0.96 , 0.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.51(best:0.51)\n",
      "Training Root// accuracy:0.52(best:0.52)\n",
      "Training F1:[0.73, 0.67](best:0.73 , 0.67)\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Loss =  tensor([31.2850])\n",
      "Loss =  tensor([33.3428])\n",
      "Loss =  tensor([32.6973])\n",
      "Loss =  tensor([33.1169])\n",
      "Loss =  tensor([32.1739])\n",
      "Loss =  tensor([33.8153])\n",
      "Loss =  tensor([32.7615])\n",
      "Loss =  tensor([31.8144])\n",
      "Loss =  tensor([32.6486])\n",
      "Loss =  tensor([31.1896])\n",
      "Loss =  tensor([31.4799])\n",
      "Loss =  tensor([29.8457])\n",
      "Loss =  tensor([31.5595])\n",
      "Loss =  tensor([31.8117])\n",
      "Loss =  tensor([32.4671])\n",
      "Loss =  tensor([32.1050])\n",
      "Loss =  tensor([31.4524])\n",
      "Loss =  tensor([31.0372])\n",
      "Loss =  tensor([32.2922])\n",
      "Loss =  tensor([34.6393])\n",
      "Loss =  tensor([32.1798])\n",
      "Loss =  tensor([31.2444])\n",
      "Loss =  tensor([30.8219])\n",
      "Loss =  tensor([31.4483])\n",
      "Loss =  tensor([32.4103])\n",
      "Loss =  tensor([32.4265])\n",
      "Loss =  tensor([31.7915])\n",
      "Loss =  tensor([30.9059])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.27(best:0.32)\n",
      "Validation Root accuracy:0.3(best:0.3)\n",
      "F1:[0.97, 0.31](best:0.97 , 0.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.52(best:0.52)\n",
      "Training Root// accuracy:0.53(best:0.53)\n",
      "Training F1:[0.8, 0.68](best:0.8 , 0.68)\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Loss =  tensor([30.5512])\n",
      "Loss =  tensor([31.6215])\n",
      "Loss =  tensor([31.9980])\n",
      "Loss =  tensor([32.2382])\n",
      "Loss =  tensor([32.1874])\n",
      "Loss =  tensor([30.0741])\n",
      "Loss =  tensor([30.9887])\n",
      "Loss =  tensor([34.2168])\n",
      "Loss =  tensor([30.5997])\n",
      "Loss =  tensor([32.1219])\n",
      "Loss =  tensor([32.6961])\n",
      "Loss =  tensor([31.7110])\n",
      "Loss =  tensor([34.5247])\n",
      "Loss =  tensor([32.5395])\n",
      "Loss =  tensor([32.8371])\n",
      "Loss =  tensor([31.5214])\n",
      "Loss =  tensor([30.4393])\n",
      "Loss =  tensor([31.4431])\n",
      "Loss =  tensor([32.2909])\n",
      "Loss =  tensor([32.2870])\n",
      "Loss =  tensor([29.6210])\n",
      "Loss =  tensor([33.0090])\n",
      "Loss =  tensor([32.9021])\n",
      "Loss =  tensor([32.0982])\n",
      "Loss =  tensor([30.7809])\n",
      "Loss =  tensor([32.0333])\n",
      "Loss =  tensor([32.1242])\n",
      "Loss =  tensor([32.4098])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.41(best:0.41)\n",
      "Validation Root accuracy:0.36(best:0.36)\n",
      "F1:[0.95, 0.32](best:0.97 , 0.32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.53(best:0.53)\n",
      "Training Root// accuracy:0.54(best:0.54)\n",
      "Training F1:[0.74, 0.69](best:0.8 , 0.69)\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Loss =  tensor([31.5884])\n",
      "Loss =  tensor([32.1361])\n",
      "Loss =  tensor([31.3583])\n",
      "Loss =  tensor([32.3799])\n",
      "Loss =  tensor([33.4133])\n",
      "Loss =  tensor([32.3568])\n",
      "Loss =  tensor([32.8251])\n",
      "Loss =  tensor([32.1994])\n",
      "Loss =  tensor([30.9269])\n",
      "Loss =  tensor([33.8712])\n",
      "Loss =  tensor([32.6407])\n",
      "Loss =  tensor([31.1905])\n",
      "Loss =  tensor([32.6606])\n",
      "Loss =  tensor([30.8964])\n",
      "Loss =  tensor([34.0340])\n",
      "Loss =  tensor([31.2895])\n",
      "Loss =  tensor([32.9327])\n",
      "Loss =  tensor([31.3341])\n",
      "Loss =  tensor([31.0718])\n",
      "Loss =  tensor([32.0956])\n",
      "Loss =  tensor([31.2390])\n",
      "Loss =  tensor([31.9554])\n",
      "Loss =  tensor([32.1509])\n",
      "Loss =  tensor([33.8649])\n",
      "Loss =  tensor([31.3250])\n",
      "Loss =  tensor([31.7673])\n",
      "Loss =  tensor([32.0162])\n",
      "Loss =  tensor([30.2981])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.47(best:0.47)\n",
      "Validation Root accuracy:0.46(best:0.46)\n",
      "F1:[0.96, 0.35](best:0.97 , 0.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.54(best:0.54)\n",
      "Training Root// accuracy:0.57(best:0.57)\n",
      "Training F1:[0.76, 0.71](best:0.8 , 0.71)\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Loss =  tensor([30.7744])\n",
      "Loss =  tensor([31.0929])\n",
      "Loss =  tensor([31.8544])\n",
      "Loss =  tensor([31.1358])\n",
      "Loss =  tensor([33.0045])\n",
      "Loss =  tensor([30.2578])\n",
      "Loss =  tensor([31.5631])\n",
      "Loss =  tensor([31.8051])\n",
      "Loss =  tensor([31.2454])\n",
      "Loss =  tensor([34.4529])\n",
      "Loss =  tensor([31.8120])\n",
      "Loss =  tensor([33.2578])\n",
      "Loss =  tensor([30.8519])\n",
      "Loss =  tensor([32.4928])\n",
      "Loss =  tensor([29.8359])\n",
      "Loss =  tensor([32.4169])\n",
      "Loss =  tensor([31.2476])\n",
      "Loss =  tensor([32.4210])\n",
      "Loss =  tensor([31.8525])\n",
      "Loss =  tensor([30.6445])\n",
      "Loss =  tensor([31.5877])\n",
      "Loss =  tensor([32.3321])\n",
      "Loss =  tensor([33.0185])\n",
      "Loss =  tensor([32.6909])\n",
      "Loss =  tensor([33.3751])\n",
      "Loss =  tensor([32.8528])\n",
      "Loss =  tensor([31.1224])\n",
      "Loss =  tensor([35.1622])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.45(best:0.47)\n",
      "Validation Root accuracy:0.49(best:0.49)\n",
      "F1:[0.95, 0.36](best:0.97 , 0.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.55(best:0.55)\n",
      "Training Root// accuracy:0.6(best:0.6)\n",
      "Training F1:[0.81, 0.73](best:0.81 , 0.73)\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Loss =  tensor([33.3716])\n",
      "Loss =  tensor([32.0208])\n",
      "Loss =  tensor([31.2071])\n",
      "Loss =  tensor([29.6604])\n",
      "Loss =  tensor([31.8455])\n",
      "Loss =  tensor([32.4043])\n",
      "Loss =  tensor([32.6577])\n",
      "Loss =  tensor([31.7725])\n",
      "Loss =  tensor([30.8948])\n",
      "Loss =  tensor([31.5684])\n",
      "Loss =  tensor([30.6152])\n",
      "Loss =  tensor([30.7087])\n",
      "Loss =  tensor([31.2029])\n",
      "Loss =  tensor([31.4539])\n",
      "Loss =  tensor([32.7060])\n",
      "Loss =  tensor([32.3947])\n",
      "Loss =  tensor([32.5291])\n",
      "Loss =  tensor([32.1435])\n",
      "Loss =  tensor([30.7141])\n",
      "Loss =  tensor([32.3150])\n",
      "Loss =  tensor([32.7179])\n",
      "Loss =  tensor([32.8619])\n",
      "Loss =  tensor([34.0993])\n",
      "Loss =  tensor([33.6952])\n",
      "Loss =  tensor([29.9563])\n",
      "Loss =  tensor([30.9580])\n",
      "Loss =  tensor([33.0040])\n",
      "Loss =  tensor([32.7302])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.54)\n",
      "Validation Root accuracy:0.73(best:0.73)\n",
      "F1:[0.93, 0.45](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.57(best:0.57)\n",
      "Training Root// accuracy:0.7(best:0.7)\n",
      "Training F1:[0.81, 0.85](best:0.81 , 0.85)\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Loss =  tensor([30.8178])\n",
      "Loss =  tensor([29.5129])\n",
      "Loss =  tensor([33.5483])\n",
      "Loss =  tensor([33.3212])\n",
      "Loss =  tensor([31.3112])\n",
      "Loss =  tensor([31.6967])\n",
      "Loss =  tensor([34.8370])\n",
      "Loss =  tensor([30.8615])\n",
      "Loss =  tensor([31.1301])\n",
      "Loss =  tensor([32.0097])\n",
      "Loss =  tensor([31.0820])\n",
      "Loss =  tensor([32.8097])\n",
      "Loss =  tensor([32.5460])\n",
      "Loss =  tensor([30.6316])\n",
      "Loss =  tensor([33.2803])\n",
      "Loss =  tensor([31.7548])\n",
      "Loss =  tensor([31.2290])\n",
      "Loss =  tensor([29.9551])\n",
      "Loss =  tensor([32.9976])\n",
      "Loss =  tensor([32.3901])\n",
      "Loss =  tensor([31.7589])\n",
      "Loss =  tensor([30.6809])\n",
      "Loss =  tensor([32.5200])\n",
      "Loss =  tensor([31.7600])\n",
      "Loss =  tensor([30.9209])\n",
      "Loss =  tensor([29.9130])\n",
      "Loss =  tensor([32.4043])\n",
      "Loss =  tensor([31.4234])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.4(best:0.54)\n",
      "Validation Root accuracy:0.44(best:0.73)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.56(best:0.57)\n",
      "Training Root// accuracy:0.63(best:0.7)\n",
      "Training F1:[0.82, 0.75](best:0.82 , 0.85)\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Loss =  tensor([30.9927])\n",
      "Loss =  tensor([31.5352])\n",
      "Loss =  tensor([32.2674])\n",
      "Loss =  tensor([31.9397])\n",
      "Loss =  tensor([32.9485])\n",
      "Loss =  tensor([31.2341])\n",
      "Loss =  tensor([32.2000])\n",
      "Loss =  tensor([31.8909])\n",
      "Loss =  tensor([31.5736])\n",
      "Loss =  tensor([31.2552])\n",
      "Loss =  tensor([30.1035])\n",
      "Loss =  tensor([32.8886])\n",
      "Loss =  tensor([32.8508])\n",
      "Loss =  tensor([31.1343])\n",
      "Loss =  tensor([31.0922])\n",
      "Loss =  tensor([31.7851])\n",
      "Loss =  tensor([33.9158])\n",
      "Loss =  tensor([31.5693])\n",
      "Loss =  tensor([32.2327])\n",
      "Loss =  tensor([31.4593])\n",
      "Loss =  tensor([32.0544])\n",
      "Loss =  tensor([35.3326])\n",
      "Loss =  tensor([32.5574])\n",
      "Loss =  tensor([30.5238])\n",
      "Loss =  tensor([32.3284])\n",
      "Loss =  tensor([31.5746])\n",
      "Loss =  tensor([31.1287])\n",
      "Loss =  tensor([33.0176])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.55(best:0.55)\n",
      "Validation Root accuracy:0.72(best:0.73)\n",
      "F1:[0.92, 0.37](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.55(best:0.57)\n",
      "Training Root// accuracy:0.61(best:0.7)\n",
      "Training F1:[0.73, 0.83](best:0.82 , 0.85)\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Loss =  tensor([32.3431])\n",
      "Loss =  tensor([30.2020])\n",
      "Loss =  tensor([31.5572])\n",
      "Loss =  tensor([33.4940])\n",
      "Loss =  tensor([33.4538])\n",
      "Loss =  tensor([31.9723])\n",
      "Loss =  tensor([29.9038])\n",
      "Loss =  tensor([32.3124])\n",
      "Loss =  tensor([31.3034])\n",
      "Loss =  tensor([31.6145])\n",
      "Loss =  tensor([31.9356])\n",
      "Loss =  tensor([31.7389])\n",
      "Loss =  tensor([31.9720])\n",
      "Loss =  tensor([30.3411])\n",
      "Loss =  tensor([31.9180])\n",
      "Loss =  tensor([30.4228])\n",
      "Loss =  tensor([29.8240])\n",
      "Loss =  tensor([32.5472])\n",
      "Loss =  tensor([31.1806])\n",
      "Loss =  tensor([30.7455])\n",
      "Loss =  tensor([30.6629])\n",
      "Loss =  tensor([32.0388])\n",
      "Loss =  tensor([31.9326])\n",
      "Loss =  tensor([31.4165])\n",
      "Loss =  tensor([32.1941])\n",
      "Loss =  tensor([31.5119])\n",
      "Loss =  tensor([31.5302])\n",
      "Loss =  tensor([31.0562])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.5(best:0.55)\n",
      "Validation Root accuracy:0.68(best:0.73)\n",
      "F1:[0.92, 0.38](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.58(best:0.58)\n",
      "Training Root// accuracy:0.71(best:0.71)\n",
      "Training F1:[0.82, 0.84](best:0.82 , 0.85)\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Loss =  tensor([29.2867])\n",
      "Loss =  tensor([30.9126])\n",
      "Loss =  tensor([32.4694])\n",
      "Loss =  tensor([30.6110])\n",
      "Loss =  tensor([31.2688])\n",
      "Loss =  tensor([29.7137])\n",
      "Loss =  tensor([32.2793])\n",
      "Loss =  tensor([31.0321])\n",
      "Loss =  tensor([31.6714])\n",
      "Loss =  tensor([30.9209])\n",
      "Loss =  tensor([31.5667])\n",
      "Loss =  tensor([33.7769])\n",
      "Loss =  tensor([31.5500])\n",
      "Loss =  tensor([30.4094])\n",
      "Loss =  tensor([30.2520])\n",
      "Loss =  tensor([35.4709])\n",
      "Loss =  tensor([32.7469])\n",
      "Loss =  tensor([31.9150])\n",
      "Loss =  tensor([33.5024])\n",
      "Loss =  tensor([33.0533])\n",
      "Loss =  tensor([30.6612])\n",
      "Loss =  tensor([30.1551])\n",
      "Loss =  tensor([30.6381])\n",
      "Loss =  tensor([32.7572])\n",
      "Loss =  tensor([32.7795])\n",
      "Loss =  tensor([31.0020])\n",
      "Loss =  tensor([32.1883])\n",
      "Loss =  tensor([33.6765])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.53(best:0.55)\n",
      "Validation Root accuracy:0.74(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.58(best:0.58)\n",
      "Training Root// accuracy:0.69(best:0.71)\n",
      "Training F1:[0.78, 0.88](best:0.82 , 0.88)\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Loss =  tensor([30.5929])\n",
      "Loss =  tensor([32.6373])\n",
      "Loss =  tensor([31.3055])\n",
      "Loss =  tensor([31.7260])\n",
      "Loss =  tensor([29.6692])\n",
      "Loss =  tensor([31.3635])\n",
      "Loss =  tensor([31.6154])\n",
      "Loss =  tensor([32.3832])\n",
      "Loss =  tensor([31.8968])\n",
      "Loss =  tensor([28.5439])\n",
      "Loss =  tensor([31.3185])\n",
      "Loss =  tensor([31.1861])\n",
      "Loss =  tensor([29.7474])\n",
      "Loss =  tensor([33.0443])\n",
      "Loss =  tensor([33.0895])\n",
      "Loss =  tensor([30.6874])\n",
      "Loss =  tensor([32.0575])\n",
      "Loss =  tensor([32.6527])\n",
      "Loss =  tensor([32.6788])\n",
      "Loss =  tensor([31.5100])\n",
      "Loss =  tensor([30.0395])\n",
      "Loss =  tensor([31.0662])\n",
      "Loss =  tensor([32.2506])\n",
      "Loss =  tensor([32.4510])\n",
      "Loss =  tensor([33.4653])\n",
      "Loss =  tensor([31.2907])\n",
      "Loss =  tensor([31.7171])\n",
      "Loss =  tensor([31.1982])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.46(best:0.55)\n",
      "Validation Root accuracy:0.63(best:0.74)\n",
      "F1:[0.92, 0.35](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.59(best:0.59)\n",
      "Training Root// accuracy:0.76(best:0.76)\n",
      "Training F1:[0.87, 0.85](best:0.87 , 0.88)\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Loss =  tensor([30.1307])\n",
      "Loss =  tensor([31.0071])\n",
      "Loss =  tensor([30.4300])\n",
      "Loss =  tensor([29.7099])\n",
      "Loss =  tensor([30.9552])\n",
      "Loss =  tensor([30.7411])\n",
      "Loss =  tensor([30.1298])\n",
      "Loss =  tensor([29.9457])\n",
      "Loss =  tensor([30.9999])\n",
      "Loss =  tensor([30.8391])\n",
      "Loss =  tensor([31.0180])\n",
      "Loss =  tensor([30.3134])\n",
      "Loss =  tensor([30.6773])\n",
      "Loss =  tensor([31.9599])\n",
      "Loss =  tensor([33.3400])\n",
      "Loss =  tensor([31.7905])\n",
      "Loss =  tensor([30.3010])\n",
      "Loss =  tensor([32.7354])\n",
      "Loss =  tensor([30.8034])\n",
      "Loss =  tensor([31.0813])\n",
      "Loss =  tensor([30.8300])\n",
      "Loss =  tensor([31.7982])\n",
      "Loss =  tensor([30.0134])\n",
      "Loss =  tensor([30.2973])\n",
      "Loss =  tensor([32.2799])\n",
      "Loss =  tensor([32.6478])\n",
      "Loss =  tensor([31.2779])\n",
      "Loss =  tensor([33.3263])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.4(best:0.55)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.91, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.59(best:0.59)\n",
      "Training Root// accuracy:0.76(best:0.76)\n",
      "Training F1:[0.84, 0.89](best:0.87 , 0.89)\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Loss =  tensor([29.7635])\n",
      "Loss =  tensor([32.8251])\n",
      "Loss =  tensor([30.2918])\n",
      "Loss =  tensor([28.8620])\n",
      "Loss =  tensor([30.6328])\n",
      "Loss =  tensor([30.7225])\n",
      "Loss =  tensor([30.0057])\n",
      "Loss =  tensor([33.4329])\n",
      "Loss =  tensor([33.5967])\n",
      "Loss =  tensor([29.8237])\n",
      "Loss =  tensor([31.5193])\n",
      "Loss =  tensor([32.0545])\n",
      "Loss =  tensor([30.3658])\n",
      "Loss =  tensor([31.5367])\n",
      "Loss =  tensor([31.7173])\n",
      "Loss =  tensor([30.5130])\n",
      "Loss =  tensor([31.6157])\n",
      "Loss =  tensor([30.8812])\n",
      "Loss =  tensor([31.5214])\n",
      "Loss =  tensor([30.3306])\n",
      "Loss =  tensor([30.8133])\n",
      "Loss =  tensor([31.3794])\n",
      "Loss =  tensor([33.3196])\n",
      "Loss =  tensor([31.1959])\n",
      "Loss =  tensor([30.9021])\n",
      "Loss =  tensor([32.1283])\n",
      "Loss =  tensor([31.0983])\n",
      "Loss =  tensor([34.0590])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.55)\n",
      "Validation Root accuracy:0.66(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.6(best:0.6)\n",
      "Training Root// accuracy:0.78(best:0.78)\n",
      "Training F1:[0.85, 0.9](best:0.87 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Loss =  tensor([30.2109])\n",
      "Loss =  tensor([32.8593])\n",
      "Loss =  tensor([30.6873])\n",
      "Loss =  tensor([28.9670])\n",
      "Loss =  tensor([32.1857])\n",
      "Loss =  tensor([32.1672])\n",
      "Loss =  tensor([30.7175])\n",
      "Loss =  tensor([29.8246])\n",
      "Loss =  tensor([30.0114])\n",
      "Loss =  tensor([30.6788])\n",
      "Loss =  tensor([30.1396])\n",
      "Loss =  tensor([31.1868])\n",
      "Loss =  tensor([30.9168])\n",
      "Loss =  tensor([30.0358])\n",
      "Loss =  tensor([30.0938])\n",
      "Loss =  tensor([32.7062])\n",
      "Loss =  tensor([32.8813])\n",
      "Loss =  tensor([31.0302])\n",
      "Loss =  tensor([31.9228])\n",
      "Loss =  tensor([33.6737])\n",
      "Loss =  tensor([29.1784])\n",
      "Loss =  tensor([30.8275])\n",
      "Loss =  tensor([29.9191])\n",
      "Loss =  tensor([30.5694])\n",
      "Loss =  tensor([30.5171])\n",
      "Loss =  tensor([28.4388])\n",
      "Loss =  tensor([31.0428])\n",
      "Loss =  tensor([29.1752])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.48(best:0.55)\n",
      "Validation Root accuracy:0.64(best:0.74)\n",
      "F1:[0.9, 0.21](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.6(best:0.6)\n",
      "Training Root// accuracy:0.79(best:0.79)\n",
      "Training F1:[0.87, 0.89](best:0.87 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Loss =  tensor([31.0694])\n",
      "Loss =  tensor([30.9620])\n",
      "Loss =  tensor([30.4603])\n",
      "Loss =  tensor([30.4092])\n",
      "Loss =  tensor([29.8669])\n",
      "Loss =  tensor([29.6147])\n",
      "Loss =  tensor([29.8395])\n",
      "Loss =  tensor([29.8605])\n",
      "Loss =  tensor([30.3823])\n",
      "Loss =  tensor([29.0250])\n",
      "Loss =  tensor([31.5823])\n",
      "Loss =  tensor([29.4007])\n",
      "Loss =  tensor([28.7233])\n",
      "Loss =  tensor([29.2668])\n",
      "Loss =  tensor([32.6444])\n",
      "Loss =  tensor([30.3877])\n",
      "Loss =  tensor([31.6424])\n",
      "Loss =  tensor([29.3379])\n",
      "Loss =  tensor([29.9686])\n",
      "Loss =  tensor([31.3848])\n",
      "Loss =  tensor([33.7580])\n",
      "Loss =  tensor([30.3854])\n",
      "Loss =  tensor([29.1979])\n",
      "Loss =  tensor([32.1367])\n",
      "Loss =  tensor([31.9831])\n",
      "Loss =  tensor([30.7279])\n",
      "Loss =  tensor([31.9484])\n",
      "Loss =  tensor([28.7639])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.41(best:0.55)\n",
      "Validation Root accuracy:0.64(best:0.74)\n",
      "F1:[0.9, 0.24](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.6(best:0.6)\n",
      "Training Root// accuracy:0.8(best:0.8)\n",
      "Training F1:[0.88, 0.9](best:0.88 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Loss =  tensor([28.5435])\n",
      "Loss =  tensor([30.8787])\n",
      "Loss =  tensor([31.4075])\n",
      "Loss =  tensor([29.2749])\n",
      "Loss =  tensor([33.3462])\n",
      "Loss =  tensor([30.8294])\n",
      "Loss =  tensor([27.9648])\n",
      "Loss =  tensor([29.1288])\n",
      "Loss =  tensor([30.7755])\n",
      "Loss =  tensor([30.1145])\n",
      "Loss =  tensor([30.2999])\n",
      "Loss =  tensor([29.7228])\n",
      "Loss =  tensor([30.7892])\n",
      "Loss =  tensor([29.3039])\n",
      "Loss =  tensor([30.8723])\n",
      "Loss =  tensor([32.0255])\n",
      "Loss =  tensor([32.2342])\n",
      "Loss =  tensor([32.6536])\n",
      "Loss =  tensor([31.5648])\n",
      "Loss =  tensor([30.5457])\n",
      "Loss =  tensor([30.5411])\n",
      "Loss =  tensor([31.9140])\n",
      "Loss =  tensor([31.7353])\n",
      "Loss =  tensor([30.3816])\n",
      "Loss =  tensor([31.3935])\n",
      "Loss =  tensor([31.1876])\n",
      "Loss =  tensor([29.8022])\n",
      "Loss =  tensor([30.5329])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.55)\n",
      "Validation Root accuracy:0.6(best:0.74)\n",
      "F1:[0.9, 0.23](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.81(best:0.81)\n",
      "Training F1:[0.89, 0.89](best:0.89 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Loss =  tensor([30.1992])\n",
      "Loss =  tensor([29.7530])\n",
      "Loss =  tensor([29.3493])\n",
      "Loss =  tensor([30.3822])\n",
      "Loss =  tensor([29.3712])\n",
      "Loss =  tensor([29.2307])\n",
      "Loss =  tensor([30.6145])\n",
      "Loss =  tensor([29.6610])\n",
      "Loss =  tensor([29.6397])\n",
      "Loss =  tensor([31.1353])\n",
      "Loss =  tensor([29.4049])\n",
      "Loss =  tensor([29.8892])\n",
      "Loss =  tensor([30.5312])\n",
      "Loss =  tensor([30.7356])\n",
      "Loss =  tensor([30.6477])\n",
      "Loss =  tensor([29.4394])\n",
      "Loss =  tensor([31.3769])\n",
      "Loss =  tensor([29.7733])\n",
      "Loss =  tensor([31.2969])\n",
      "Loss =  tensor([29.6719])\n",
      "Loss =  tensor([28.9808])\n",
      "Loss =  tensor([31.3359])\n",
      "Loss =  tensor([29.9983])\n",
      "Loss =  tensor([28.4630])\n",
      "Loss =  tensor([29.6531])\n",
      "Loss =  tensor([29.0926])\n",
      "Loss =  tensor([30.9931])\n",
      "Loss =  tensor([28.5494])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.47(best:0.55)\n",
      "Validation Root accuracy:0.63(best:0.74)\n",
      "F1:[0.89, 0.18](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.81(best:0.81)\n",
      "Training F1:[0.89, 0.91](best:0.89 , 0.91)\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Loss =  tensor([28.2162])\n",
      "Loss =  tensor([30.2220])\n",
      "Loss =  tensor([28.6725])\n",
      "Loss =  tensor([28.0002])\n",
      "Loss =  tensor([30.6092])\n",
      "Loss =  tensor([27.5054])\n",
      "Loss =  tensor([31.8746])\n",
      "Loss =  tensor([32.8792])\n",
      "Loss =  tensor([29.9356])\n",
      "Loss =  tensor([29.8072])\n",
      "Loss =  tensor([30.2605])\n",
      "Loss =  tensor([31.6715])\n",
      "Loss =  tensor([30.7068])\n",
      "Loss =  tensor([31.1073])\n",
      "Loss =  tensor([29.4929])\n",
      "Loss =  tensor([31.0898])\n",
      "Loss =  tensor([31.1731])\n",
      "Loss =  tensor([30.6254])\n",
      "Loss =  tensor([28.4868])\n",
      "Loss =  tensor([30.2585])\n",
      "Loss =  tensor([31.2928])\n",
      "Loss =  tensor([30.7972])\n",
      "Loss =  tensor([29.8911])\n",
      "Loss =  tensor([32.5286])\n",
      "Loss =  tensor([31.0684])\n",
      "Loss =  tensor([32.5045])\n",
      "Loss =  tensor([32.7645])\n",
      "Loss =  tensor([29.9289])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.53(best:0.55)\n",
      "Validation Root accuracy:0.62(best:0.74)\n",
      "F1:[0.9, 0.26](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.82(best:0.82)\n",
      "Training F1:[0.9, 0.91](best:0.9 , 0.91)\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Loss =  tensor([28.9426])\n",
      "Loss =  tensor([32.2213])\n",
      "Loss =  tensor([32.7493])\n",
      "Loss =  tensor([31.2606])\n",
      "Loss =  tensor([33.4090])\n",
      "Loss =  tensor([30.4600])\n",
      "Loss =  tensor([31.9552])\n",
      "Loss =  tensor([30.5903])\n",
      "Loss =  tensor([30.4655])\n",
      "Loss =  tensor([30.0543])\n",
      "Loss =  tensor([32.2878])\n",
      "Loss =  tensor([30.7546])\n",
      "Loss =  tensor([30.6742])\n",
      "Loss =  tensor([29.2641])\n",
      "Loss =  tensor([30.4606])\n",
      "Loss =  tensor([31.6072])\n",
      "Loss =  tensor([29.8339])\n",
      "Loss =  tensor([30.5253])\n",
      "Loss =  tensor([29.2247])\n",
      "Loss =  tensor([30.0587])\n",
      "Loss =  tensor([30.6118])\n",
      "Loss =  tensor([31.1104])\n",
      "Loss =  tensor([30.5217])\n",
      "Loss =  tensor([30.0631])\n",
      "Loss =  tensor([29.2898])\n",
      "Loss =  tensor([29.2933])\n",
      "Loss =  tensor([27.4026])\n",
      "Loss =  tensor([29.1240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.55)\n",
      "Validation Root accuracy:0.66(best:0.74)\n",
      "F1:[0.9, 0.25](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.62)\n",
      "Training Root// accuracy:0.8(best:0.82)\n",
      "Training F1:[0.87, 0.91](best:0.9 , 0.91)\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Loss =  tensor([28.2057])\n",
      "Loss =  tensor([27.1855])\n",
      "Loss =  tensor([31.1760])\n",
      "Loss =  tensor([30.4936])\n",
      "Loss =  tensor([30.4971])\n",
      "Loss =  tensor([32.1718])\n",
      "Loss =  tensor([29.2985])\n",
      "Loss =  tensor([30.0000])\n",
      "Loss =  tensor([30.5448])\n",
      "Loss =  tensor([30.2960])\n",
      "Loss =  tensor([31.2663])\n",
      "Loss =  tensor([28.9770])\n",
      "Loss =  tensor([30.7326])\n",
      "Loss =  tensor([27.2502])\n",
      "Loss =  tensor([29.1853])\n",
      "Loss =  tensor([30.9066])\n",
      "Loss =  tensor([30.9863])\n",
      "Loss =  tensor([30.8861])\n",
      "Loss =  tensor([29.8071])\n",
      "Loss =  tensor([29.7738])\n",
      "Loss =  tensor([31.4662])\n",
      "Loss =  tensor([29.4728])\n",
      "Loss =  tensor([30.0695])\n",
      "Loss =  tensor([30.8994])\n",
      "Loss =  tensor([28.3638])\n",
      "Loss =  tensor([31.6052])\n",
      "Loss =  tensor([29.1157])\n",
      "Loss =  tensor([30.8582])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.55)\n",
      "Validation Root accuracy:0.66(best:0.74)\n",
      "F1:[0.9, 0.25](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.84(best:0.84)\n",
      "Training F1:[0.9, 0.92](best:0.9 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Loss =  tensor([30.0294])\n",
      "Loss =  tensor([30.4782])\n",
      "Loss =  tensor([29.9099])\n",
      "Loss =  tensor([29.0847])\n",
      "Loss =  tensor([28.5633])\n",
      "Loss =  tensor([28.7232])\n",
      "Loss =  tensor([31.3288])\n",
      "Loss =  tensor([30.9092])\n",
      "Loss =  tensor([27.9157])\n",
      "Loss =  tensor([29.2004])\n",
      "Loss =  tensor([30.6358])\n",
      "Loss =  tensor([28.7757])\n",
      "Loss =  tensor([30.3924])\n",
      "Loss =  tensor([31.2222])\n",
      "Loss =  tensor([30.5065])\n",
      "Loss =  tensor([27.8858])\n",
      "Loss =  tensor([29.0566])\n",
      "Loss =  tensor([30.4668])\n",
      "Loss =  tensor([30.8172])\n",
      "Loss =  tensor([29.2539])\n",
      "Loss =  tensor([28.6988])\n",
      "Loss =  tensor([30.2408])\n",
      "Loss =  tensor([30.7535])\n",
      "Loss =  tensor([29.2160])\n",
      "Loss =  tensor([31.1078])\n",
      "Loss =  tensor([30.3715])\n",
      "Loss =  tensor([32.3565])\n",
      "Loss =  tensor([28.3959])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.5(best:0.55)\n",
      "Validation Root accuracy:0.66(best:0.74)\n",
      "F1:[0.9, 0.25](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.84(best:0.84)\n",
      "Training F1:[0.91, 0.92](best:0.91 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Loss =  tensor([27.6482])\n",
      "Loss =  tensor([29.5321])\n",
      "Loss =  tensor([30.2442])\n",
      "Loss =  tensor([28.6903])\n",
      "Loss =  tensor([28.2606])\n",
      "Loss =  tensor([29.0639])\n",
      "Loss =  tensor([30.0224])\n",
      "Loss =  tensor([28.8624])\n",
      "Loss =  tensor([26.6174])\n",
      "Loss =  tensor([30.0500])\n",
      "Loss =  tensor([28.2195])\n",
      "Loss =  tensor([27.9993])\n",
      "Loss =  tensor([29.4926])\n",
      "Loss =  tensor([28.4695])\n",
      "Loss =  tensor([29.8250])\n",
      "Loss =  tensor([29.7506])\n",
      "Loss =  tensor([29.2495])\n",
      "Loss =  tensor([28.7844])\n",
      "Loss =  tensor([29.0627])\n",
      "Loss =  tensor([29.4609])\n",
      "Loss =  tensor([28.5128])\n",
      "Loss =  tensor([28.8515])\n",
      "Loss =  tensor([27.5755])\n",
      "Loss =  tensor([31.8133])\n",
      "Loss =  tensor([28.6337])\n",
      "Loss =  tensor([31.2819])\n",
      "Loss =  tensor([31.7810])\n",
      "Loss =  tensor([30.9576])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.48(best:0.55)\n",
      "Validation Root accuracy:0.65(best:0.74)\n",
      "F1:[0.9, 0.25](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.86(best:0.86)\n",
      "Training F1:[0.93, 0.93](best:0.93 , 0.93)\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Loss =  tensor([28.8652])\n",
      "Loss =  tensor([29.1978])\n",
      "Loss =  tensor([29.6541])\n",
      "Loss =  tensor([31.9372])\n",
      "Loss =  tensor([28.4460])\n",
      "Loss =  tensor([30.6509])\n",
      "Loss =  tensor([29.0902])\n",
      "Loss =  tensor([29.4626])\n",
      "Loss =  tensor([29.1279])\n",
      "Loss =  tensor([29.0424])\n",
      "Loss =  tensor([28.3860])\n",
      "Loss =  tensor([30.2323])\n",
      "Loss =  tensor([29.5734])\n",
      "Loss =  tensor([28.6027])\n",
      "Loss =  tensor([29.4907])\n",
      "Loss =  tensor([29.9119])\n",
      "Loss =  tensor([29.4631])\n",
      "Loss =  tensor([30.3507])\n",
      "Loss =  tensor([27.9102])\n",
      "Loss =  tensor([30.8500])\n",
      "Loss =  tensor([28.6718])\n",
      "Loss =  tensor([30.6852])\n",
      "Loss =  tensor([29.6183])\n",
      "Loss =  tensor([30.2711])\n",
      "Loss =  tensor([28.2804])\n",
      "Loss =  tensor([29.9838])\n",
      "Loss =  tensor([28.3449])\n",
      "Loss =  tensor([28.9474])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.55)\n",
      "Validation Root accuracy:0.58(best:0.74)\n",
      "F1:[0.9, 0.26](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.86(best:0.86)\n",
      "Training F1:[0.93, 0.92](best:0.93 , 0.93)\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Loss =  tensor([29.4111])\n",
      "Loss =  tensor([30.3908])\n",
      "Loss =  tensor([31.6583])\n",
      "Loss =  tensor([30.3060])\n",
      "Loss =  tensor([29.5276])\n",
      "Loss =  tensor([30.9710])\n",
      "Loss =  tensor([28.9663])\n",
      "Loss =  tensor([28.0976])\n",
      "Loss =  tensor([28.2504])\n",
      "Loss =  tensor([28.7041])\n",
      "Loss =  tensor([29.3388])\n",
      "Loss =  tensor([30.2556])\n",
      "Loss =  tensor([28.8792])\n",
      "Loss =  tensor([28.3355])\n",
      "Loss =  tensor([27.8399])\n",
      "Loss =  tensor([27.9302])\n",
      "Loss =  tensor([27.5655])\n",
      "Loss =  tensor([29.9122])\n",
      "Loss =  tensor([28.9226])\n",
      "Loss =  tensor([28.6465])\n",
      "Loss =  tensor([28.4146])\n",
      "Loss =  tensor([29.2000])\n",
      "Loss =  tensor([29.0374])\n",
      "Loss =  tensor([29.8245])\n",
      "Loss =  tensor([30.0219])\n",
      "Loss =  tensor([28.7000])\n",
      "Loss =  tensor([29.1927])\n",
      "Loss =  tensor([31.3321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.47(best:0.55)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.88(best:0.88)\n",
      "Training F1:[0.92, 0.94](best:0.93 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Loss =  tensor([27.3456])\n",
      "Loss =  tensor([27.6815])\n",
      "Loss =  tensor([27.2345])\n",
      "Loss =  tensor([27.0237])\n",
      "Loss =  tensor([32.1686])\n",
      "Loss =  tensor([29.0179])\n",
      "Loss =  tensor([31.4009])\n",
      "Loss =  tensor([31.1925])\n",
      "Loss =  tensor([30.7992])\n",
      "Loss =  tensor([30.0165])\n",
      "Loss =  tensor([29.3972])\n",
      "Loss =  tensor([29.9606])\n",
      "Loss =  tensor([28.4117])\n",
      "Loss =  tensor([30.6839])\n",
      "Loss =  tensor([29.0724])\n",
      "Loss =  tensor([26.9454])\n",
      "Loss =  tensor([29.9376])\n",
      "Loss =  tensor([33.8814])\n",
      "Loss =  tensor([32.8620])\n",
      "Loss =  tensor([29.0605])\n",
      "Loss =  tensor([31.5826])\n",
      "Loss =  tensor([35.6370])\n",
      "Loss =  tensor([33.0117])\n",
      "Loss =  tensor([30.5430])\n",
      "Loss =  tensor([28.2606])\n",
      "Loss =  tensor([30.5392])\n",
      "Loss =  tensor([31.7367])\n",
      "Loss =  tensor([28.2092])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.55(best:0.55)\n",
      "Validation Root accuracy:0.66(best:0.74)\n",
      "F1:[0.91, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.87(best:0.88)\n",
      "Training F1:[0.93, 0.93](best:0.93 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Loss =  tensor([30.1925])\n",
      "Loss =  tensor([29.6044])\n",
      "Loss =  tensor([28.0568])\n",
      "Loss =  tensor([28.0916])\n",
      "Loss =  tensor([29.0684])\n",
      "Loss =  tensor([30.3286])\n",
      "Loss =  tensor([27.2177])\n",
      "Loss =  tensor([29.7338])\n",
      "Loss =  tensor([29.7439])\n",
      "Loss =  tensor([27.7615])\n",
      "Loss =  tensor([29.4954])\n",
      "Loss =  tensor([27.9708])\n",
      "Loss =  tensor([31.6382])\n",
      "Loss =  tensor([29.1481])\n",
      "Loss =  tensor([29.3866])\n",
      "Loss =  tensor([30.6212])\n",
      "Loss =  tensor([28.2333])\n",
      "Loss =  tensor([30.1458])\n",
      "Loss =  tensor([29.9417])\n",
      "Loss =  tensor([29.1326])\n",
      "Loss =  tensor([27.3266])\n",
      "Loss =  tensor([29.6805])\n",
      "Loss =  tensor([29.3357])\n",
      "Loss =  tensor([28.5532])\n",
      "Loss =  tensor([30.2093])\n",
      "Loss =  tensor([26.8695])\n",
      "Loss =  tensor([27.6019])\n",
      "Loss =  tensor([30.1252])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.48(best:0.55)\n",
      "Validation Root accuracy:0.65(best:0.74)\n",
      "F1:[0.9, 0.24](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.88(best:0.88)\n",
      "Training F1:[0.93, 0.94](best:0.93 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Loss =  tensor([28.3198])\n",
      "Loss =  tensor([27.9493])\n",
      "Loss =  tensor([29.3747])\n",
      "Loss =  tensor([29.5125])\n",
      "Loss =  tensor([31.9169])\n",
      "Loss =  tensor([31.5897])\n",
      "Loss =  tensor([31.0590])\n",
      "Loss =  tensor([27.7517])\n",
      "Loss =  tensor([29.5747])\n",
      "Loss =  tensor([27.9697])\n",
      "Loss =  tensor([30.6374])\n",
      "Loss =  tensor([30.8637])\n",
      "Loss =  tensor([29.5995])\n",
      "Loss =  tensor([27.4756])\n",
      "Loss =  tensor([28.0299])\n",
      "Loss =  tensor([27.3927])\n",
      "Loss =  tensor([28.7550])\n",
      "Loss =  tensor([29.5189])\n",
      "Loss =  tensor([28.2720])\n",
      "Loss =  tensor([27.9767])\n",
      "Loss =  tensor([29.4363])\n",
      "Loss =  tensor([28.4554])\n",
      "Loss =  tensor([28.0765])\n",
      "Loss =  tensor([28.7621])\n",
      "Loss =  tensor([29.5071])\n",
      "Loss =  tensor([28.6399])\n",
      "Loss =  tensor([29.6520])\n",
      "Loss =  tensor([30.3013])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.48(best:0.55)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:03:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.89(best:0.89)\n",
      "Training F1:[0.93, 0.95](best:0.93 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Loss =  tensor([28.7419])\n",
      "Loss =  tensor([28.1596])\n",
      "Loss =  tensor([29.3006])\n",
      "Loss =  tensor([28.3812])\n",
      "Loss =  tensor([26.4434])\n",
      "Loss =  tensor([28.1941])\n",
      "Loss =  tensor([27.2085])\n",
      "Loss =  tensor([27.7381])\n",
      "Loss =  tensor([27.2008])\n",
      "Loss =  tensor([30.1436])\n",
      "Loss =  tensor([28.9377])\n",
      "Loss =  tensor([26.7904])\n",
      "Loss =  tensor([28.1165])\n",
      "Loss =  tensor([29.1572])\n",
      "Loss =  tensor([29.0276])\n",
      "Loss =  tensor([29.7407])\n",
      "Loss =  tensor([29.1606])\n",
      "Loss =  tensor([27.0283])\n",
      "Loss =  tensor([29.4811])\n",
      "Loss =  tensor([28.3255])\n",
      "Loss =  tensor([28.2769])\n",
      "Loss =  tensor([29.9283])\n",
      "Loss =  tensor([29.8459])\n",
      "Loss =  tensor([32.5481])\n",
      "Loss =  tensor([30.3070])\n",
      "Loss =  tensor([30.6349])\n",
      "Loss =  tensor([32.2494])\n",
      "Loss =  tensor([27.1848])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.56(best:0.56)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.91, 0.3](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.9(best:0.9)\n",
      "Training F1:[0.95, 0.94](best:0.95 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Loss =  tensor([28.5531])\n",
      "Loss =  tensor([26.7798])\n",
      "Loss =  tensor([29.2590])\n",
      "Loss =  tensor([26.0787])\n",
      "Loss =  tensor([30.2809])\n",
      "Loss =  tensor([29.8457])\n",
      "Loss =  tensor([26.5189])\n",
      "Loss =  tensor([28.4911])\n",
      "Loss =  tensor([28.5236])\n",
      "Loss =  tensor([26.2887])\n",
      "Loss =  tensor([27.3826])\n",
      "Loss =  tensor([29.6041])\n",
      "Loss =  tensor([29.5152])\n",
      "Loss =  tensor([30.0153])\n",
      "Loss =  tensor([28.7834])\n",
      "Loss =  tensor([28.2521])\n",
      "Loss =  tensor([27.3402])\n",
      "Loss =  tensor([28.4756])\n",
      "Loss =  tensor([28.5083])\n",
      "Loss =  tensor([28.2664])\n",
      "Loss =  tensor([26.2445])\n",
      "Loss =  tensor([26.7419])\n",
      "Loss =  tensor([28.7476])\n",
      "Loss =  tensor([27.6711])\n",
      "Loss =  tensor([29.8728])\n",
      "Loss =  tensor([28.4561])\n",
      "Loss =  tensor([28.7209])\n",
      "Loss =  tensor([28.7090])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.56)\n",
      "Validation Root accuracy:0.67(best:0.74)\n",
      "F1:[0.91, 0.26](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.9(best:0.9)\n",
      "Training F1:[0.94, 0.95](best:0.95 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Loss =  tensor([27.2251])\n",
      "Loss =  tensor([29.4522])\n",
      "Loss =  tensor([29.1954])\n",
      "Loss =  tensor([27.7300])\n",
      "Loss =  tensor([27.6039])\n",
      "Loss =  tensor([27.5478])\n",
      "Loss =  tensor([28.3025])\n",
      "Loss =  tensor([27.5273])\n",
      "Loss =  tensor([27.3523])\n",
      "Loss =  tensor([27.7292])\n",
      "Loss =  tensor([27.0623])\n",
      "Loss =  tensor([30.6931])\n",
      "Loss =  tensor([30.1168])\n",
      "Loss =  tensor([28.7379])\n",
      "Loss =  tensor([29.6240])\n",
      "Loss =  tensor([30.1001])\n",
      "Loss =  tensor([29.0851])\n",
      "Loss =  tensor([28.4005])\n",
      "Loss =  tensor([27.5239])\n",
      "Loss =  tensor([28.5603])\n",
      "Loss =  tensor([25.9752])\n",
      "Loss =  tensor([27.5605])\n",
      "Loss =  tensor([28.6525])\n",
      "Loss =  tensor([28.8580])\n",
      "Loss =  tensor([28.9954])\n",
      "Loss =  tensor([26.8796])\n",
      "Loss =  tensor([28.6680])\n",
      "Loss =  tensor([28.2666])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.56)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.31](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.9(best:0.9)\n",
      "Training F1:[0.95, 0.95](best:0.95 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Loss =  tensor([28.2533])\n",
      "Loss =  tensor([29.7117])\n",
      "Loss =  tensor([29.1873])\n",
      "Loss =  tensor([26.6878])\n",
      "Loss =  tensor([29.3059])\n",
      "Loss =  tensor([26.4003])\n",
      "Loss =  tensor([28.2877])\n",
      "Loss =  tensor([28.0756])\n",
      "Loss =  tensor([27.6994])\n",
      "Loss =  tensor([31.8959])\n",
      "Loss =  tensor([29.1991])\n",
      "Loss =  tensor([27.8687])\n",
      "Loss =  tensor([29.6313])\n",
      "Loss =  tensor([27.8034])\n",
      "Loss =  tensor([29.0343])\n",
      "Loss =  tensor([31.1783])\n",
      "Loss =  tensor([29.0350])\n",
      "Loss =  tensor([29.5763])\n",
      "Loss =  tensor([28.4976])\n",
      "Loss =  tensor([28.8900])\n",
      "Loss =  tensor([27.6272])\n",
      "Loss =  tensor([29.9611])\n",
      "Loss =  tensor([28.4165])\n",
      "Loss =  tensor([28.5767])\n",
      "Loss =  tensor([29.9941])\n",
      "Loss =  tensor([26.2563])\n",
      "Loss =  tensor([29.3052])\n",
      "Loss =  tensor([31.1877])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.56)\n",
      "Validation Root accuracy:0.66(best:0.74)\n",
      "F1:[0.91, 0.28](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.91(best:0.91)\n",
      "Training F1:[0.95, 0.95](best:0.95 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Loss =  tensor([28.7457])\n",
      "Loss =  tensor([27.9595])\n",
      "Loss =  tensor([27.9270])\n",
      "Loss =  tensor([28.3607])\n",
      "Loss =  tensor([26.9326])\n",
      "Loss =  tensor([29.5967])\n",
      "Loss =  tensor([27.0756])\n",
      "Loss =  tensor([29.8844])\n",
      "Loss =  tensor([32.3321])\n",
      "Loss =  tensor([28.3332])\n",
      "Loss =  tensor([28.9935])\n",
      "Loss =  tensor([28.4718])\n",
      "Loss =  tensor([28.8202])\n",
      "Loss =  tensor([28.0976])\n",
      "Loss =  tensor([31.3987])\n",
      "Loss =  tensor([28.8632])\n",
      "Loss =  tensor([28.2062])\n",
      "Loss =  tensor([31.9876])\n",
      "Loss =  tensor([28.3573])\n",
      "Loss =  tensor([27.5979])\n",
      "Loss =  tensor([29.0408])\n",
      "Loss =  tensor([27.6032])\n",
      "Loss =  tensor([29.1164])\n",
      "Loss =  tensor([30.0155])\n",
      "Loss =  tensor([28.7319])\n",
      "Loss =  tensor([27.3111])\n",
      "Loss =  tensor([30.3366])\n",
      "Loss =  tensor([29.6077])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.47(best:0.56)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.91, 0.31](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.9(best:0.91)\n",
      "Training F1:[0.94, 0.96](best:0.95 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Loss =  tensor([28.5170])\n",
      "Loss =  tensor([32.7093])\n",
      "Loss =  tensor([37.8062])\n",
      "Loss =  tensor([32.6577])\n",
      "Loss =  tensor([32.6738])\n",
      "Loss =  tensor([27.7549])\n",
      "Loss =  tensor([30.4439])\n",
      "Loss =  tensor([28.1008])\n",
      "Loss =  tensor([27.7339])\n",
      "Loss =  tensor([28.4424])\n",
      "Loss =  tensor([28.3139])\n",
      "Loss =  tensor([28.1137])\n",
      "Loss =  tensor([27.9281])\n",
      "Loss =  tensor([27.6589])\n",
      "Loss =  tensor([27.8155])\n",
      "Loss =  tensor([26.6215])\n",
      "Loss =  tensor([28.3372])\n",
      "Loss =  tensor([28.5504])\n",
      "Loss =  tensor([29.7035])\n",
      "Loss =  tensor([26.8225])\n",
      "Loss =  tensor([26.4317])\n",
      "Loss =  tensor([28.8085])\n",
      "Loss =  tensor([27.7152])\n",
      "Loss =  tensor([26.7153])\n",
      "Loss =  tensor([26.8845])\n",
      "Loss =  tensor([28.3251])\n",
      "Loss =  tensor([28.4261])\n",
      "Loss =  tensor([27.7701])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.56)\n",
      "Validation Root accuracy:0.62(best:0.74)\n",
      "F1:[0.9, 0.26](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.9(best:0.91)\n",
      "Training F1:[0.96, 0.93](best:0.96 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Loss =  tensor([26.9168])\n",
      "Loss =  tensor([30.4659])\n",
      "Loss =  tensor([34.0674])\n",
      "Loss =  tensor([31.4354])\n",
      "Loss =  tensor([29.0294])\n",
      "Loss =  tensor([27.4128])\n",
      "Loss =  tensor([28.4114])\n",
      "Loss =  tensor([28.6417])\n",
      "Loss =  tensor([28.9973])\n",
      "Loss =  tensor([29.5075])\n",
      "Loss =  tensor([30.4490])\n",
      "Loss =  tensor([29.7848])\n",
      "Loss =  tensor([29.0490])\n",
      "Loss =  tensor([29.4696])\n",
      "Loss =  tensor([32.3136])\n",
      "Loss =  tensor([31.8516])\n",
      "Loss =  tensor([30.8615])\n",
      "Loss =  tensor([30.4284])\n",
      "Loss =  tensor([30.5486])\n",
      "Loss =  tensor([29.4262])\n",
      "Loss =  tensor([28.2077])\n",
      "Loss =  tensor([26.9445])\n",
      "Loss =  tensor([29.2959])\n",
      "Loss =  tensor([29.4020])\n",
      "Loss =  tensor([29.0894])\n",
      "Loss =  tensor([28.4396])\n",
      "Loss =  tensor([27.3538])\n",
      "Loss =  tensor([27.1376])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.46(best:0.56)\n",
      "Validation Root accuracy:0.65(best:0.74)\n",
      "F1:[0.91, 0.27](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.89(best:0.91)\n",
      "Training F1:[0.94, 0.95](best:0.96 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Loss =  tensor([28.6099])\n",
      "Loss =  tensor([26.6693])\n",
      "Loss =  tensor([27.0445])\n",
      "Loss =  tensor([25.9403])\n",
      "Loss =  tensor([26.7313])\n",
      "Loss =  tensor([28.2006])\n",
      "Loss =  tensor([26.3235])\n",
      "Loss =  tensor([28.0770])\n",
      "Loss =  tensor([29.5516])\n",
      "Loss =  tensor([28.4032])\n",
      "Loss =  tensor([28.6894])\n",
      "Loss =  tensor([27.8052])\n",
      "Loss =  tensor([30.2867])\n",
      "Loss =  tensor([29.0797])\n",
      "Loss =  tensor([28.7671])\n",
      "Loss =  tensor([27.1686])\n",
      "Loss =  tensor([28.5006])\n",
      "Loss =  tensor([27.2995])\n",
      "Loss =  tensor([28.5045])\n",
      "Loss =  tensor([27.8150])\n",
      "Loss =  tensor([27.3315])\n",
      "Loss =  tensor([27.5145])\n",
      "Loss =  tensor([30.2951])\n",
      "Loss =  tensor([28.1478])\n",
      "Loss =  tensor([27.9169])\n",
      "Loss =  tensor([27.1659])\n",
      "Loss =  tensor([27.9682])\n",
      "Loss =  tensor([27.3272])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.53(best:0.56)\n",
      "Validation Root accuracy:0.67(best:0.74)\n",
      "F1:[0.91, 0.26](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.92(best:0.92)\n",
      "Training F1:[0.96, 0.95](best:0.96 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Loss =  tensor([27.8456])\n",
      "Loss =  tensor([28.3735])\n",
      "Loss =  tensor([27.2707])\n",
      "Loss =  tensor([27.4085])\n",
      "Loss =  tensor([27.7184])\n",
      "Loss =  tensor([27.4364])\n",
      "Loss =  tensor([28.4703])\n",
      "Loss =  tensor([28.0849])\n",
      "Loss =  tensor([27.8296])\n",
      "Loss =  tensor([26.5783])\n",
      "Loss =  tensor([28.7088])\n",
      "Loss =  tensor([28.2092])\n",
      "Loss =  tensor([26.2185])\n",
      "Loss =  tensor([27.7149])\n",
      "Loss =  tensor([26.7479])\n",
      "Loss =  tensor([28.3025])\n",
      "Loss =  tensor([27.5754])\n",
      "Loss =  tensor([26.3810])\n",
      "Loss =  tensor([29.6658])\n",
      "Loss =  tensor([27.8858])\n",
      "Loss =  tensor([28.0582])\n",
      "Loss =  tensor([29.9464])\n",
      "Loss =  tensor([27.7201])\n",
      "Loss =  tensor([29.6579])\n",
      "Loss =  tensor([25.7545])\n",
      "Loss =  tensor([28.2996])\n",
      "Loss =  tensor([26.6377])\n",
      "Loss =  tensor([25.6826])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.5(best:0.56)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.31](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.92(best:0.92)\n",
      "Training F1:[0.96, 0.95](best:0.96 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Loss =  tensor([26.6348])\n",
      "Loss =  tensor([25.2993])\n",
      "Loss =  tensor([27.6221])\n",
      "Loss =  tensor([26.9679])\n",
      "Loss =  tensor([26.6011])\n",
      "Loss =  tensor([29.1076])\n",
      "Loss =  tensor([27.6775])\n",
      "Loss =  tensor([27.1682])\n",
      "Loss =  tensor([27.1042])\n",
      "Loss =  tensor([25.1975])\n",
      "Loss =  tensor([27.8295])\n",
      "Loss =  tensor([28.0396])\n",
      "Loss =  tensor([28.0203])\n",
      "Loss =  tensor([25.9092])\n",
      "Loss =  tensor([27.9816])\n",
      "Loss =  tensor([27.4742])\n",
      "Loss =  tensor([28.8397])\n",
      "Loss =  tensor([27.8819])\n",
      "Loss =  tensor([28.8170])\n",
      "Loss =  tensor([29.9835])\n",
      "Loss =  tensor([29.3060])\n",
      "Loss =  tensor([26.0535])\n",
      "Loss =  tensor([28.3721])\n",
      "Loss =  tensor([26.7315])\n",
      "Loss =  tensor([31.7125])\n",
      "Loss =  tensor([30.9771])\n",
      "Loss =  tensor([27.7530])\n",
      "Loss =  tensor([31.7337])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.56)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Loss =  tensor([25.7479])\n",
      "Loss =  tensor([28.7095])\n",
      "Loss =  tensor([30.3542])\n",
      "Loss =  tensor([28.2139])\n",
      "Loss =  tensor([29.4156])\n",
      "Loss =  tensor([31.6641])\n",
      "Loss =  tensor([27.9280])\n",
      "Loss =  tensor([28.7730])\n",
      "Loss =  tensor([29.6211])\n",
      "Loss =  tensor([29.1473])\n",
      "Loss =  tensor([27.7068])\n",
      "Loss =  tensor([29.2020])\n",
      "Loss =  tensor([28.8215])\n",
      "Loss =  tensor([28.9408])\n",
      "Loss =  tensor([32.0563])\n",
      "Loss =  tensor([28.3159])\n",
      "Loss =  tensor([26.8594])\n",
      "Loss =  tensor([27.0438])\n",
      "Loss =  tensor([27.3884])\n",
      "Loss =  tensor([27.1784])\n",
      "Loss =  tensor([29.5559])\n",
      "Loss =  tensor([28.6621])\n",
      "Loss =  tensor([29.3066])\n",
      "Loss =  tensor([28.4383])\n",
      "Loss =  tensor([28.1825])\n",
      "Loss =  tensor([27.5875])\n",
      "Loss =  tensor([25.8729])\n",
      "Loss =  tensor([27.0226])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.53(best:0.56)\n",
      "Validation Root accuracy:0.67(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.65)\n",
      "Training Root// accuracy:0.92(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Loss =  tensor([25.7562])\n",
      "Loss =  tensor([25.6599])\n",
      "Loss =  tensor([27.7044])\n",
      "Loss =  tensor([28.4486])\n",
      "Loss =  tensor([27.7952])\n",
      "Loss =  tensor([27.2453])\n",
      "Loss =  tensor([29.3237])\n",
      "Loss =  tensor([30.1401])\n",
      "Loss =  tensor([27.8016])\n",
      "Loss =  tensor([29.9491])\n",
      "Loss =  tensor([32.9514])\n",
      "Loss =  tensor([29.5829])\n",
      "Loss =  tensor([27.4749])\n",
      "Loss =  tensor([31.5306])\n",
      "Loss =  tensor([38.5167])\n",
      "Loss =  tensor([33.6589])\n",
      "Loss =  tensor([28.3637])\n",
      "Loss =  tensor([32.1554])\n",
      "Loss =  tensor([35.3972])\n",
      "Loss =  tensor([36.5834])\n",
      "Loss =  tensor([30.2502])\n",
      "Loss =  tensor([28.7916])\n",
      "Loss =  tensor([29.3540])\n",
      "Loss =  tensor([26.3585])\n",
      "Loss =  tensor([28.1163])\n",
      "Loss =  tensor([26.9456])\n",
      "Loss =  tensor([27.9103])\n",
      "Loss =  tensor([28.5041])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.45(best:0.56)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.91, 0.31](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.65)\n",
      "Training Root// accuracy:0.92(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Loss =  tensor([26.5893])\n",
      "Loss =  tensor([27.1899])\n",
      "Loss =  tensor([28.4119])\n",
      "Loss =  tensor([26.7476])\n",
      "Loss =  tensor([28.8819])\n",
      "Loss =  tensor([28.4453])\n",
      "Loss =  tensor([27.1588])\n",
      "Loss =  tensor([28.0798])\n",
      "Loss =  tensor([28.5121])\n",
      "Loss =  tensor([29.2573])\n",
      "Loss =  tensor([27.6030])\n",
      "Loss =  tensor([32.0294])\n",
      "Loss =  tensor([29.7221])\n",
      "Loss =  tensor([27.4484])\n",
      "Loss =  tensor([27.8163])\n",
      "Loss =  tensor([26.8279])\n",
      "Loss =  tensor([26.2126])\n",
      "Loss =  tensor([25.6975])\n",
      "Loss =  tensor([28.0479])\n",
      "Loss =  tensor([31.4478])\n",
      "Loss =  tensor([27.3997])\n",
      "Loss =  tensor([26.8430])\n",
      "Loss =  tensor([28.9108])\n",
      "Loss =  tensor([28.4070])\n",
      "Loss =  tensor([25.5893])\n",
      "Loss =  tensor([27.9523])\n",
      "Loss =  tensor([27.2860])\n",
      "Loss =  tensor([26.6647])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.56)\n",
      "Validation Root accuracy:0.63(best:0.74)\n",
      "F1:[0.9, 0.23](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.65)\n",
      "Training Root// accuracy:0.92(best:0.93)\n",
      "Training F1:[0.97, 0.95](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Loss =  tensor([28.2078])\n",
      "Loss =  tensor([26.7785])\n",
      "Loss =  tensor([27.5585])\n",
      "Loss =  tensor([25.4342])\n",
      "Loss =  tensor([26.8779])\n",
      "Loss =  tensor([27.8680])\n",
      "Loss =  tensor([27.2914])\n",
      "Loss =  tensor([27.6007])\n",
      "Loss =  tensor([31.0254])\n",
      "Loss =  tensor([27.6396])\n",
      "Loss =  tensor([26.4667])\n",
      "Loss =  tensor([30.0242])\n",
      "Loss =  tensor([27.8169])\n",
      "Loss =  tensor([26.3151])\n",
      "Loss =  tensor([25.5644])\n",
      "Loss =  tensor([27.2850])\n",
      "Loss =  tensor([28.7472])\n",
      "Loss =  tensor([27.9142])\n",
      "Loss =  tensor([29.4882])\n",
      "Loss =  tensor([32.8617])\n",
      "Loss =  tensor([28.2868])\n",
      "Loss =  tensor([28.1206])\n",
      "Loss =  tensor([28.9875])\n",
      "Loss =  tensor([30.7062])\n",
      "Loss =  tensor([27.3007])\n",
      "Loss =  tensor([26.9731])\n",
      "Loss =  tensor([27.7893])\n",
      "Loss =  tensor([25.1426])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.55(best:0.56)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.27](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Loss =  tensor([27.3143])\n",
      "Loss =  tensor([28.3892])\n",
      "Loss =  tensor([29.2457])\n",
      "Loss =  tensor([28.1872])\n",
      "Loss =  tensor([28.7488])\n",
      "Loss =  tensor([28.5611])\n",
      "Loss =  tensor([27.5242])\n",
      "Loss =  tensor([29.2889])\n",
      "Loss =  tensor([31.3471])\n",
      "Loss =  tensor([28.8278])\n",
      "Loss =  tensor([25.3943])\n",
      "Loss =  tensor([29.5802])\n",
      "Loss =  tensor([27.8994])\n",
      "Loss =  tensor([26.5778])\n",
      "Loss =  tensor([28.4116])\n",
      "Loss =  tensor([27.4698])\n",
      "Loss =  tensor([27.9995])\n",
      "Loss =  tensor([28.0961])\n",
      "Loss =  tensor([25.6673])\n",
      "Loss =  tensor([26.2171])\n",
      "Loss =  tensor([26.3836])\n",
      "Loss =  tensor([28.8739])\n",
      "Loss =  tensor([26.5638])\n",
      "Loss =  tensor([27.5143])\n",
      "Loss =  tensor([31.5283])\n",
      "Loss =  tensor([29.4559])\n",
      "Loss =  tensor([30.4282])\n",
      "Loss =  tensor([27.4116])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.56(best:0.56)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.27](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Loss =  tensor([26.1996])\n",
      "Loss =  tensor([26.0113])\n",
      "Loss =  tensor([27.8391])\n",
      "Loss =  tensor([26.8474])\n",
      "Loss =  tensor([28.9827])\n",
      "Loss =  tensor([28.0385])\n",
      "Loss =  tensor([26.7502])\n",
      "Loss =  tensor([27.5733])\n",
      "Loss =  tensor([27.3565])\n",
      "Loss =  tensor([26.7900])\n",
      "Loss =  tensor([27.2192])\n",
      "Loss =  tensor([26.2051])\n",
      "Loss =  tensor([28.3492])\n",
      "Loss =  tensor([26.3643])\n",
      "Loss =  tensor([26.6677])\n",
      "Loss =  tensor([27.8311])\n",
      "Loss =  tensor([28.5433])\n",
      "Loss =  tensor([28.7528])\n",
      "Loss =  tensor([31.0642])\n",
      "Loss =  tensor([28.6745])\n",
      "Loss =  tensor([28.0688])\n",
      "Loss =  tensor([30.0023])\n",
      "Loss =  tensor([26.6930])\n",
      "Loss =  tensor([29.4585])\n",
      "Loss =  tensor([27.8364])\n",
      "Loss =  tensor([26.4864])\n",
      "Loss =  tensor([30.3053])\n",
      "Loss =  tensor([30.2752])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.55(best:0.56)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.3](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Loss =  tensor([27.1326])\n",
      "Loss =  tensor([29.1668])\n",
      "Loss =  tensor([32.1361])\n",
      "Loss =  tensor([27.5357])\n",
      "Loss =  tensor([25.7302])\n",
      "Loss =  tensor([27.3972])\n",
      "Loss =  tensor([25.4341])\n",
      "Loss =  tensor([28.4339])\n",
      "Loss =  tensor([27.6044])\n",
      "Loss =  tensor([25.3644])\n",
      "Loss =  tensor([30.3287])\n",
      "Loss =  tensor([31.4675])\n",
      "Loss =  tensor([29.8574])\n",
      "Loss =  tensor([27.1098])\n",
      "Loss =  tensor([30.1091])\n",
      "Loss =  tensor([27.2209])\n",
      "Loss =  tensor([26.1653])\n",
      "Loss =  tensor([28.1549])\n",
      "Loss =  tensor([27.3276])\n",
      "Loss =  tensor([27.2444])\n",
      "Loss =  tensor([30.6718])\n",
      "Loss =  tensor([29.5341])\n",
      "Loss =  tensor([26.6788])\n",
      "Loss =  tensor([26.1579])\n",
      "Loss =  tensor([27.3566])\n",
      "Loss =  tensor([27.0136])\n",
      "Loss =  tensor([27.8434])\n",
      "Loss =  tensor([27.9593])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.56)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.9, 0.24](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.94)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Loss =  tensor([26.5512])\n",
      "Loss =  tensor([29.8769])\n",
      "Loss =  tensor([35.5972])\n",
      "Loss =  tensor([35.1143])\n",
      "Loss =  tensor([30.8399])\n",
      "Loss =  tensor([27.5233])\n",
      "Loss =  tensor([28.5574])\n",
      "Loss =  tensor([27.9570])\n",
      "Loss =  tensor([27.1218])\n",
      "Loss =  tensor([27.7957])\n",
      "Loss =  tensor([26.7677])\n",
      "Loss =  tensor([26.8003])\n",
      "Loss =  tensor([27.6003])\n",
      "Loss =  tensor([26.3625])\n",
      "Loss =  tensor([26.0139])\n",
      "Loss =  tensor([28.5878])\n",
      "Loss =  tensor([27.7252])\n",
      "Loss =  tensor([26.1945])\n",
      "Loss =  tensor([26.5917])\n",
      "Loss =  tensor([27.2078])\n",
      "Loss =  tensor([27.4257])\n",
      "Loss =  tensor([27.2464])\n",
      "Loss =  tensor([27.7049])\n",
      "Loss =  tensor([25.6697])\n",
      "Loss =  tensor([31.0979])\n",
      "Loss =  tensor([31.6522])\n",
      "Loss =  tensor([31.4344])\n",
      "Loss =  tensor([26.0781])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.56)\n",
      "Validation Root accuracy:0.63(best:0.74)\n",
      "F1:[0.92, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.94)\n",
      "Training F1:[0.98, 0.95](best:0.98 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Loss =  tensor([26.7388])\n",
      "Loss =  tensor([27.5103])\n",
      "Loss =  tensor([29.8913])\n",
      "Loss =  tensor([27.3200])\n",
      "Loss =  tensor([26.6311])\n",
      "Loss =  tensor([28.0047])\n",
      "Loss =  tensor([27.1782])\n",
      "Loss =  tensor([25.7963])\n",
      "Loss =  tensor([27.7215])\n",
      "Loss =  tensor([29.3250])\n",
      "Loss =  tensor([29.3194])\n",
      "Loss =  tensor([26.8796])\n",
      "Loss =  tensor([28.0832])\n",
      "Loss =  tensor([31.0412])\n",
      "Loss =  tensor([28.9484])\n",
      "Loss =  tensor([27.1042])\n",
      "Loss =  tensor([28.9673])\n",
      "Loss =  tensor([26.9284])\n",
      "Loss =  tensor([26.6342])\n",
      "Loss =  tensor([25.2753])\n",
      "Loss =  tensor([28.3612])\n",
      "Loss =  tensor([28.1667])\n",
      "Loss =  tensor([27.5336])\n",
      "Loss =  tensor([29.5764])\n",
      "Loss =  tensor([27.4451])\n",
      "Loss =  tensor([28.4087])\n",
      "Loss =  tensor([27.5856])\n",
      "Loss =  tensor([24.3797])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.55(best:0.56)\n",
      "Validation Root accuracy:0.73(best:0.74)\n",
      "F1:[0.92, 0.4](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.98 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Loss =  tensor([26.7860])\n",
      "Loss =  tensor([27.6803])\n",
      "Loss =  tensor([26.4233])\n",
      "Loss =  tensor([29.1062])\n",
      "Loss =  tensor([27.7836])\n",
      "Loss =  tensor([25.7830])\n",
      "Loss =  tensor([28.7561])\n",
      "Loss =  tensor([26.7368])\n",
      "Loss =  tensor([28.5097])\n",
      "Loss =  tensor([26.8098])\n",
      "Loss =  tensor([26.6912])\n",
      "Loss =  tensor([27.0135])\n",
      "Loss =  tensor([27.0031])\n",
      "Loss =  tensor([26.7593])\n",
      "Loss =  tensor([25.7867])\n",
      "Loss =  tensor([26.8435])\n",
      "Loss =  tensor([28.6774])\n",
      "Loss =  tensor([30.2588])\n",
      "Loss =  tensor([26.6537])\n",
      "Loss =  tensor([25.4537])\n",
      "Loss =  tensor([26.5394])\n",
      "Loss =  tensor([27.5754])\n",
      "Loss =  tensor([27.0869])\n",
      "Loss =  tensor([27.0308])\n",
      "Loss =  tensor([25.8780])\n",
      "Loss =  tensor([27.1974])\n",
      "Loss =  tensor([28.0745])\n",
      "Loss =  tensor([26.3973])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.56)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.91, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.98 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Loss =  tensor([27.6910])\n",
      "Loss =  tensor([27.9788])\n",
      "Loss =  tensor([27.1394])\n",
      "Loss =  tensor([27.1591])\n",
      "Loss =  tensor([27.1240])\n",
      "Loss =  tensor([26.1272])\n",
      "Loss =  tensor([26.6174])\n",
      "Loss =  tensor([26.5345])\n",
      "Loss =  tensor([26.8256])\n",
      "Loss =  tensor([27.2949])\n",
      "Loss =  tensor([27.0631])\n",
      "Loss =  tensor([29.2446])\n",
      "Loss =  tensor([28.6194])\n",
      "Loss =  tensor([26.6269])\n",
      "Loss =  tensor([29.5712])\n",
      "Loss =  tensor([30.2931])\n",
      "Loss =  tensor([28.4810])\n",
      "Loss =  tensor([26.3826])\n",
      "Loss =  tensor([27.6840])\n",
      "Loss =  tensor([28.4444])\n",
      "Loss =  tensor([27.2989])\n",
      "Loss =  tensor([26.7397])\n",
      "Loss =  tensor([27.6831])\n",
      "Loss =  tensor([30.6478])\n",
      "Loss =  tensor([31.6019])\n",
      "Loss =  tensor([29.4451])\n",
      "Loss =  tensor([27.4194])\n",
      "Loss =  tensor([36.3277])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.58(best:0.58)\n",
      "Validation Root accuracy:0.65(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.98, 0.96](best:0.98 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Loss =  tensor([28.1523])\n",
      "Loss =  tensor([32.3939])\n",
      "Loss =  tensor([31.4262])\n",
      "Loss =  tensor([29.8007])\n",
      "Loss =  tensor([25.8864])\n",
      "Loss =  tensor([32.1786])\n",
      "Loss =  tensor([37.7691])\n",
      "Loss =  tensor([31.6296])\n",
      "Loss =  tensor([30.5470])\n",
      "Loss =  tensor([26.9445])\n",
      "Loss =  tensor([29.7391])\n",
      "Loss =  tensor([28.7725])\n",
      "Loss =  tensor([26.5850])\n",
      "Loss =  tensor([26.9832])\n",
      "Loss =  tensor([26.5515])\n",
      "Loss =  tensor([27.1349])\n",
      "Loss =  tensor([26.4785])\n",
      "Loss =  tensor([27.7756])\n",
      "Loss =  tensor([27.4071])\n",
      "Loss =  tensor([27.0007])\n",
      "Loss =  tensor([27.0602])\n",
      "Loss =  tensor([29.2575])\n",
      "Loss =  tensor([27.5968])\n",
      "Loss =  tensor([27.0346])\n",
      "Loss =  tensor([27.5276])\n",
      "Loss =  tensor([28.6932])\n",
      "Loss =  tensor([27.8133])\n",
      "Loss =  tensor([29.6959])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.58)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.9, 0.25](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.98 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Loss =  tensor([27.0258])\n",
      "Loss =  tensor([27.4583])\n",
      "Loss =  tensor([26.4639])\n",
      "Loss =  tensor([27.0783])\n",
      "Loss =  tensor([27.1040])\n",
      "Loss =  tensor([27.2721])\n",
      "Loss =  tensor([26.5816])\n",
      "Loss =  tensor([28.7372])\n",
      "Loss =  tensor([31.6325])\n",
      "Loss =  tensor([29.1543])\n",
      "Loss =  tensor([27.5979])\n",
      "Loss =  tensor([29.3030])\n",
      "Loss =  tensor([31.6014])\n",
      "Loss =  tensor([26.7552])\n",
      "Loss =  tensor([28.0938])\n",
      "Loss =  tensor([28.6630])\n",
      "Loss =  tensor([27.1431])\n",
      "Loss =  tensor([26.1670])\n",
      "Loss =  tensor([27.2554])\n",
      "Loss =  tensor([27.5878])\n",
      "Loss =  tensor([26.3510])\n",
      "Loss =  tensor([26.4313])\n",
      "Loss =  tensor([26.5854])\n",
      "Loss =  tensor([29.7829])\n",
      "Loss =  tensor([27.6618])\n",
      "Loss =  tensor([25.6322])\n",
      "Loss =  tensor([27.7813])\n",
      "Loss =  tensor([27.6149])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.58)\n",
      "Validation Root accuracy:0.67(best:0.74)\n",
      "F1:[0.9, 0.24](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.98 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Loss =  tensor([27.5086])\n",
      "Loss =  tensor([25.6468])\n",
      "Loss =  tensor([26.5484])\n",
      "Loss =  tensor([28.6442])\n",
      "Loss =  tensor([27.6040])\n",
      "Loss =  tensor([26.8894])\n",
      "Loss =  tensor([29.9265])\n",
      "Loss =  tensor([33.1632])\n",
      "Loss =  tensor([28.0622])\n",
      "Loss =  tensor([26.1036])\n",
      "Loss =  tensor([26.0116])\n",
      "Loss =  tensor([25.4920])\n",
      "Loss =  tensor([27.5677])\n",
      "Loss =  tensor([25.8436])\n",
      "Loss =  tensor([28.3049])\n",
      "Loss =  tensor([26.1544])\n",
      "Loss =  tensor([25.5504])\n",
      "Loss =  tensor([26.2445])\n",
      "Loss =  tensor([28.4152])\n",
      "Loss =  tensor([27.4746])\n",
      "Loss =  tensor([27.7247])\n",
      "Loss =  tensor([26.3719])\n",
      "Loss =  tensor([26.1919])\n",
      "Loss =  tensor([28.9203])\n",
      "Loss =  tensor([27.2803])\n",
      "Loss =  tensor([30.8790])\n",
      "Loss =  tensor([34.6899])\n",
      "Loss =  tensor([34.9391])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.58)\n",
      "Validation Root accuracy:0.73(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.96, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 51\n",
      "Loss =  tensor([26.4391])\n",
      "Loss =  tensor([29.1958])\n",
      "Loss =  tensor([30.6363])\n",
      "Loss =  tensor([32.8591])\n",
      "Loss =  tensor([27.4493])\n",
      "Loss =  tensor([27.6184])\n",
      "Loss =  tensor([31.3937])\n",
      "Loss =  tensor([30.5325])\n",
      "Loss =  tensor([27.5696])\n",
      "Loss =  tensor([29.1319])\n",
      "Loss =  tensor([32.2175])\n",
      "Loss =  tensor([29.1951])\n",
      "Loss =  tensor([26.6898])\n",
      "Loss =  tensor([28.2723])\n",
      "Loss =  tensor([28.6418])\n",
      "Loss =  tensor([28.6781])\n",
      "Loss =  tensor([26.5724])\n",
      "Loss =  tensor([29.9840])\n",
      "Loss =  tensor([29.7430])\n",
      "Loss =  tensor([29.1440])\n",
      "Loss =  tensor([27.0403])\n",
      "Loss =  tensor([28.4352])\n",
      "Loss =  tensor([32.7584])\n",
      "Loss =  tensor([29.5833])\n",
      "Loss =  tensor([28.8677])\n",
      "Loss =  tensor([28.6513])\n",
      "Loss =  tensor([28.6751])\n",
      "Loss =  tensor([29.6586])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.58)\n",
      "Validation Root accuracy:0.65(best:0.74)\n",
      "F1:[0.92, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.94)\n",
      "Training F1:[0.97, 0.96](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 52\n",
      "Loss =  tensor([26.3783])\n",
      "Loss =  tensor([27.0487])\n",
      "Loss =  tensor([27.1126])\n",
      "Loss =  tensor([27.6173])\n",
      "Loss =  tensor([27.9895])\n",
      "Loss =  tensor([27.6620])\n",
      "Loss =  tensor([27.3662])\n",
      "Loss =  tensor([27.1109])\n",
      "Loss =  tensor([25.3500])\n",
      "Loss =  tensor([26.3571])\n",
      "Loss =  tensor([26.9404])\n",
      "Loss =  tensor([25.7579])\n",
      "Loss =  tensor([27.2873])\n",
      "Loss =  tensor([27.3306])\n",
      "Loss =  tensor([27.7207])\n",
      "Loss =  tensor([27.1588])\n",
      "Loss =  tensor([27.2733])\n",
      "Loss =  tensor([26.4758])\n",
      "Loss =  tensor([27.1540])\n",
      "Loss =  tensor([27.9715])\n",
      "Loss =  tensor([26.5627])\n",
      "Loss =  tensor([27.8835])\n",
      "Loss =  tensor([27.4364])\n",
      "Loss =  tensor([24.8719])\n",
      "Loss =  tensor([27.5249])\n",
      "Loss =  tensor([26.6587])\n",
      "Loss =  tensor([25.7581])\n",
      "Loss =  tensor([25.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.58)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.92, 0.34](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 53\n",
      "Loss =  tensor([25.8305])\n",
      "Loss =  tensor([25.8298])\n",
      "Loss =  tensor([25.8407])\n",
      "Loss =  tensor([26.5101])\n",
      "Loss =  tensor([27.0776])\n",
      "Loss =  tensor([24.5649])\n",
      "Loss =  tensor([28.4007])\n",
      "Loss =  tensor([25.6938])\n",
      "Loss =  tensor([25.7260])\n",
      "Loss =  tensor([27.3445])\n",
      "Loss =  tensor([27.4431])\n",
      "Loss =  tensor([26.6457])\n",
      "Loss =  tensor([28.8850])\n",
      "Loss =  tensor([28.6227])\n",
      "Loss =  tensor([26.1889])\n",
      "Loss =  tensor([32.1499])\n",
      "Loss =  tensor([28.0985])\n",
      "Loss =  tensor([26.9222])\n",
      "Loss =  tensor([30.4509])\n",
      "Loss =  tensor([33.7015])\n",
      "Loss =  tensor([28.6349])\n",
      "Loss =  tensor([26.0543])\n",
      "Loss =  tensor([27.1359])\n",
      "Loss =  tensor([29.2120])\n",
      "Loss =  tensor([27.0629])\n",
      "Loss =  tensor([26.6075])\n",
      "Loss =  tensor([28.3319])\n",
      "Loss =  tensor([30.3674])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.47(best:0.58)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.32](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 54\n",
      "Loss =  tensor([26.6830])\n",
      "Loss =  tensor([27.2022])\n",
      "Loss =  tensor([24.9329])\n",
      "Loss =  tensor([25.2591])\n",
      "Loss =  tensor([26.8457])\n",
      "Loss =  tensor([26.6996])\n",
      "Loss =  tensor([27.4665])\n",
      "Loss =  tensor([26.0762])\n",
      "Loss =  tensor([27.6394])\n",
      "Loss =  tensor([29.2609])\n",
      "Loss =  tensor([27.2711])\n",
      "Loss =  tensor([27.1249])\n",
      "Loss =  tensor([30.1768])\n",
      "Loss =  tensor([28.8567])\n",
      "Loss =  tensor([26.1799])\n",
      "Loss =  tensor([28.7392])\n",
      "Loss =  tensor([25.3105])\n",
      "Loss =  tensor([28.4486])\n",
      "Loss =  tensor([27.5998])\n",
      "Loss =  tensor([28.1302])\n",
      "Loss =  tensor([29.3308])\n",
      "Loss =  tensor([28.4319])\n",
      "Loss =  tensor([30.2826])\n",
      "Loss =  tensor([28.5750])\n",
      "Loss =  tensor([28.8115])\n",
      "Loss =  tensor([26.0984])\n",
      "Loss =  tensor([26.1531])\n",
      "Loss =  tensor([26.5074])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.59(best:0.59)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.91, 0.32](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 55\n",
      "Loss =  tensor([26.8358])\n",
      "Loss =  tensor([27.6974])\n",
      "Loss =  tensor([27.0593])\n",
      "Loss =  tensor([26.8385])\n",
      "Loss =  tensor([25.3456])\n",
      "Loss =  tensor([25.7372])\n",
      "Loss =  tensor([26.6554])\n",
      "Loss =  tensor([27.1491])\n",
      "Loss =  tensor([26.0267])\n",
      "Loss =  tensor([28.5980])\n",
      "Loss =  tensor([25.7662])\n",
      "Loss =  tensor([26.6673])\n",
      "Loss =  tensor([25.3367])\n",
      "Loss =  tensor([27.6330])\n",
      "Loss =  tensor([25.5073])\n",
      "Loss =  tensor([24.5944])\n",
      "Loss =  tensor([26.0236])\n",
      "Loss =  tensor([25.8569])\n",
      "Loss =  tensor([27.8436])\n",
      "Loss =  tensor([27.1544])\n",
      "Loss =  tensor([26.4877])\n",
      "Loss =  tensor([27.4473])\n",
      "Loss =  tensor([29.4824])\n",
      "Loss =  tensor([26.1894])\n",
      "Loss =  tensor([29.6959])\n",
      "Loss =  tensor([32.2805])\n",
      "Loss =  tensor([28.9527])\n",
      "Loss =  tensor([28.0553])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.58(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.39](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 56\n",
      "Loss =  tensor([25.9869])\n",
      "Loss =  tensor([29.1198])\n",
      "Loss =  tensor([26.5738])\n",
      "Loss =  tensor([26.9755])\n",
      "Loss =  tensor([27.7813])\n",
      "Loss =  tensor([30.7206])\n",
      "Loss =  tensor([28.4332])\n",
      "Loss =  tensor([25.7666])\n",
      "Loss =  tensor([32.7142])\n",
      "Loss =  tensor([35.6164])\n",
      "Loss =  tensor([35.2295])\n",
      "Loss =  tensor([28.2504])\n",
      "Loss =  tensor([29.0580])\n",
      "Loss =  tensor([32.6292])\n",
      "Loss =  tensor([30.5189])\n",
      "Loss =  tensor([26.7768])\n",
      "Loss =  tensor([26.3806])\n",
      "Loss =  tensor([27.3730])\n",
      "Loss =  tensor([28.2711])\n",
      "Loss =  tensor([25.6920])\n",
      "Loss =  tensor([28.1528])\n",
      "Loss =  tensor([27.4409])\n",
      "Loss =  tensor([27.8447])\n",
      "Loss =  tensor([27.6004])\n",
      "Loss =  tensor([26.6479])\n",
      "Loss =  tensor([26.5463])\n",
      "Loss =  tensor([28.9594])\n",
      "Loss =  tensor([32.9137])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.57(best:0.59)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.91, 0.31](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.94(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 57\n",
      "Loss =  tensor([27.0981])\n",
      "Loss =  tensor([25.9671])\n",
      "Loss =  tensor([26.4992])\n",
      "Loss =  tensor([26.6108])\n",
      "Loss =  tensor([28.0082])\n",
      "Loss =  tensor([26.5378])\n",
      "Loss =  tensor([26.2526])\n",
      "Loss =  tensor([26.0163])\n",
      "Loss =  tensor([26.9493])\n",
      "Loss =  tensor([26.5978])\n",
      "Loss =  tensor([27.0619])\n",
      "Loss =  tensor([27.2999])\n",
      "Loss =  tensor([26.0998])\n",
      "Loss =  tensor([27.0724])\n",
      "Loss =  tensor([26.9529])\n",
      "Loss =  tensor([27.0072])\n",
      "Loss =  tensor([27.4889])\n",
      "Loss =  tensor([26.3760])\n",
      "Loss =  tensor([27.3861])\n",
      "Loss =  tensor([26.9742])\n",
      "Loss =  tensor([25.7081])\n",
      "Loss =  tensor([29.2894])\n",
      "Loss =  tensor([29.1048])\n",
      "Loss =  tensor([29.8283])\n",
      "Loss =  tensor([26.1329])\n",
      "Loss =  tensor([29.2155])\n",
      "Loss =  tensor([27.3394])\n",
      "Loss =  tensor([26.6617])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.5(best:0.59)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.91, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 58\n",
      "Loss =  tensor([24.9564])\n",
      "Loss =  tensor([26.5151])\n",
      "Loss =  tensor([28.4165])\n",
      "Loss =  tensor([26.6096])\n",
      "Loss =  tensor([25.4560])\n",
      "Loss =  tensor([27.6654])\n",
      "Loss =  tensor([27.0904])\n",
      "Loss =  tensor([26.0388])\n",
      "Loss =  tensor([25.7159])\n",
      "Loss =  tensor([26.1460])\n",
      "Loss =  tensor([25.8228])\n",
      "Loss =  tensor([26.5190])\n",
      "Loss =  tensor([27.5427])\n",
      "Loss =  tensor([26.6393])\n",
      "Loss =  tensor([27.2961])\n",
      "Loss =  tensor([26.2867])\n",
      "Loss =  tensor([25.4755])\n",
      "Loss =  tensor([28.7027])\n",
      "Loss =  tensor([27.2606])\n",
      "Loss =  tensor([26.4844])\n",
      "Loss =  tensor([29.8492])\n",
      "Loss =  tensor([30.5564])\n",
      "Loss =  tensor([29.5797])\n",
      "Loss =  tensor([27.9630])\n",
      "Loss =  tensor([30.0083])\n",
      "Loss =  tensor([35.1365])\n",
      "Loss =  tensor([33.7961])\n",
      "Loss =  tensor([31.0023])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.5(best:0.59)\n",
      "Validation Root accuracy:0.68(best:0.74)\n",
      "F1:[0.92, 0.34](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 59\n",
      "Loss =  tensor([27.5735])\n",
      "Loss =  tensor([32.5652])\n",
      "Loss =  tensor([39.1013])\n",
      "Loss =  tensor([42.1714])\n",
      "Loss =  tensor([36.2930])\n",
      "Loss =  tensor([27.8467])\n",
      "Loss =  tensor([28.8414])\n",
      "Loss =  tensor([32.4515])\n",
      "Loss =  tensor([31.6757])\n",
      "Loss =  tensor([28.8554])\n",
      "Loss =  tensor([28.2078])\n",
      "Loss =  tensor([27.3983])\n",
      "Loss =  tensor([28.7464])\n",
      "Loss =  tensor([30.1364])\n",
      "Loss =  tensor([28.3446])\n",
      "Loss =  tensor([27.5571])\n",
      "Loss =  tensor([27.2099])\n",
      "Loss =  tensor([27.0096])\n",
      "Loss =  tensor([28.8652])\n",
      "Loss =  tensor([28.6828])\n",
      "Loss =  tensor([27.6016])\n",
      "Loss =  tensor([26.5290])\n",
      "Loss =  tensor([27.0002])\n",
      "Loss =  tensor([27.1237])\n",
      "Loss =  tensor([26.8417])\n",
      "Loss =  tensor([28.6519])\n",
      "Loss =  tensor([26.2348])\n",
      "Loss =  tensor([27.2035])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.56(best:0.59)\n",
      "Validation Root accuracy:0.72(best:0.74)\n",
      "F1:[0.92, 0.37](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.93(best:0.95)\n",
      "Training F1:[0.96, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 60\n",
      "Loss =  tensor([27.7727])\n",
      "Loss =  tensor([26.4583])\n",
      "Loss =  tensor([27.5122])\n",
      "Loss =  tensor([28.2714])\n",
      "Loss =  tensor([28.1058])\n",
      "Loss =  tensor([29.2195])\n",
      "Loss =  tensor([25.5343])\n",
      "Loss =  tensor([30.3450])\n",
      "Loss =  tensor([28.6805])\n",
      "Loss =  tensor([27.7717])\n",
      "Loss =  tensor([26.3564])\n",
      "Loss =  tensor([26.7755])\n",
      "Loss =  tensor([27.6800])\n",
      "Loss =  tensor([26.1556])\n",
      "Loss =  tensor([26.5712])\n",
      "Loss =  tensor([25.5211])\n",
      "Loss =  tensor([25.8467])\n",
      "Loss =  tensor([26.6295])\n",
      "Loss =  tensor([27.2965])\n",
      "Loss =  tensor([25.8154])\n",
      "Loss =  tensor([26.1835])\n",
      "Loss =  tensor([26.7429])\n",
      "Loss =  tensor([29.0524])\n",
      "Loss =  tensor([28.1252])\n",
      "Loss =  tensor([26.9802])\n",
      "Loss =  tensor([28.3603])\n",
      "Loss =  tensor([28.7696])\n",
      "Loss =  tensor([29.4449])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.59)\n",
      "Validation Root accuracy:0.69(best:0.74)\n",
      "F1:[0.92, 0.36](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 61\n",
      "Loss =  tensor([26.1589])\n",
      "Loss =  tensor([26.3716])\n",
      "Loss =  tensor([26.4719])\n",
      "Loss =  tensor([26.9401])\n",
      "Loss =  tensor([29.2046])\n",
      "Loss =  tensor([28.5912])\n",
      "Loss =  tensor([27.1856])\n",
      "Loss =  tensor([28.9124])\n",
      "Loss =  tensor([27.8301])\n",
      "Loss =  tensor([26.2301])\n",
      "Loss =  tensor([26.2374])\n",
      "Loss =  tensor([24.6848])\n",
      "Loss =  tensor([25.4687])\n",
      "Loss =  tensor([27.7557])\n",
      "Loss =  tensor([27.4595])\n",
      "Loss =  tensor([25.6573])\n",
      "Loss =  tensor([26.1149])\n",
      "Loss =  tensor([25.9362])\n",
      "Loss =  tensor([26.3698])\n",
      "Loss =  tensor([26.8290])\n",
      "Loss =  tensor([25.4331])\n",
      "Loss =  tensor([26.2319])\n",
      "Loss =  tensor([25.7485])\n",
      "Loss =  tensor([25.5529])\n",
      "Loss =  tensor([27.2029])\n",
      "Loss =  tensor([27.5276])\n",
      "Loss =  tensor([26.3629])\n",
      "Loss =  tensor([27.2369])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.56(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.36](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 62\n",
      "Loss =  tensor([25.6025])\n",
      "Loss =  tensor([25.5729])\n",
      "Loss =  tensor([26.1721])\n",
      "Loss =  tensor([24.8113])\n",
      "Loss =  tensor([26.9831])\n",
      "Loss =  tensor([27.0038])\n",
      "Loss =  tensor([25.6863])\n",
      "Loss =  tensor([28.1299])\n",
      "Loss =  tensor([25.1723])\n",
      "Loss =  tensor([26.9915])\n",
      "Loss =  tensor([25.5112])\n",
      "Loss =  tensor([28.9487])\n",
      "Loss =  tensor([26.5485])\n",
      "Loss =  tensor([25.9767])\n",
      "Loss =  tensor([28.3227])\n",
      "Loss =  tensor([26.4440])\n",
      "Loss =  tensor([27.2464])\n",
      "Loss =  tensor([28.7007])\n",
      "Loss =  tensor([26.6054])\n",
      "Loss =  tensor([26.8327])\n",
      "Loss =  tensor([26.7467])\n",
      "Loss =  tensor([25.8484])\n",
      "Loss =  tensor([25.7923])\n",
      "Loss =  tensor([27.9130])\n",
      "Loss =  tensor([28.2179])\n",
      "Loss =  tensor([26.5881])\n",
      "Loss =  tensor([28.8233])\n",
      "Loss =  tensor([29.9432])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.91, 0.33](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 63\n",
      "Loss =  tensor([26.0130])\n",
      "Loss =  tensor([26.3911])\n",
      "Loss =  tensor([26.3288])\n",
      "Loss =  tensor([26.0333])\n",
      "Loss =  tensor([25.8591])\n",
      "Loss =  tensor([25.9975])\n",
      "Loss =  tensor([27.4121])\n",
      "Loss =  tensor([26.7813])\n",
      "Loss =  tensor([25.2183])\n",
      "Loss =  tensor([27.3687])\n",
      "Loss =  tensor([24.2615])\n",
      "Loss =  tensor([27.8065])\n",
      "Loss =  tensor([26.1116])\n",
      "Loss =  tensor([28.9160])\n",
      "Loss =  tensor([24.7253])\n",
      "Loss =  tensor([27.0801])\n",
      "Loss =  tensor([26.4435])\n",
      "Loss =  tensor([26.0047])\n",
      "Loss =  tensor([25.6816])\n",
      "Loss =  tensor([30.0754])\n",
      "Loss =  tensor([29.5119])\n",
      "Loss =  tensor([25.1893])\n",
      "Loss =  tensor([27.9275])\n",
      "Loss =  tensor([30.0467])\n",
      "Loss =  tensor([27.8334])\n",
      "Loss =  tensor([25.8487])\n",
      "Loss =  tensor([28.4905])\n",
      "Loss =  tensor([33.7390])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.59)\n",
      "Validation Root accuracy:0.73(best:0.74)\n",
      "F1:[0.92, 0.39](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 64\n",
      "Loss =  tensor([25.6285])\n",
      "Loss =  tensor([27.5586])\n",
      "Loss =  tensor([28.1292])\n",
      "Loss =  tensor([27.2126])\n",
      "Loss =  tensor([28.2291])\n",
      "Loss =  tensor([29.3800])\n",
      "Loss =  tensor([29.3041])\n",
      "Loss =  tensor([25.6456])\n",
      "Loss =  tensor([25.4709])\n",
      "Loss =  tensor([27.0471])\n",
      "Loss =  tensor([28.6086])\n",
      "Loss =  tensor([29.4802])\n",
      "Loss =  tensor([26.8776])\n",
      "Loss =  tensor([25.5612])\n",
      "Loss =  tensor([30.7677])\n",
      "Loss =  tensor([25.1647])\n",
      "Loss =  tensor([26.4750])\n",
      "Loss =  tensor([28.1442])\n",
      "Loss =  tensor([25.0837])\n",
      "Loss =  tensor([26.6907])\n",
      "Loss =  tensor([25.1284])\n",
      "Loss =  tensor([25.7594])\n",
      "Loss =  tensor([27.2544])\n",
      "Loss =  tensor([26.9082])\n",
      "Loss =  tensor([28.6470])\n",
      "Loss =  tensor([28.8783])\n",
      "Loss =  tensor([26.3481])\n",
      "Loss =  tensor([28.0308])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.59)\n",
      "Validation Root accuracy:0.72(best:0.74)\n",
      "F1:[0.92, 0.39](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 65\n",
      "Loss =  tensor([26.7360])\n",
      "Loss =  tensor([27.1202])\n",
      "Loss =  tensor([26.0676])\n",
      "Loss =  tensor([27.9742])\n",
      "Loss =  tensor([25.6072])\n",
      "Loss =  tensor([24.6423])\n",
      "Loss =  tensor([26.2652])\n",
      "Loss =  tensor([26.4059])\n",
      "Loss =  tensor([25.7323])\n",
      "Loss =  tensor([27.5329])\n",
      "Loss =  tensor([25.8681])\n",
      "Loss =  tensor([26.1277])\n",
      "Loss =  tensor([25.2416])\n",
      "Loss =  tensor([26.4466])\n",
      "Loss =  tensor([26.3502])\n",
      "Loss =  tensor([30.7407])\n",
      "Loss =  tensor([35.5942])\n",
      "Loss =  tensor([28.5506])\n",
      "Loss =  tensor([25.4782])\n",
      "Loss =  tensor([34.9101])\n",
      "Loss =  tensor([36.9446])\n",
      "Loss =  tensor([36.0062])\n",
      "Loss =  tensor([27.9718])\n",
      "Loss =  tensor([27.0312])\n",
      "Loss =  tensor([30.5599])\n",
      "Loss =  tensor([29.4088])\n",
      "Loss =  tensor([26.6990])\n",
      "Loss =  tensor([25.2754])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.39](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 66\n",
      "Loss =  tensor([25.7332])\n",
      "Loss =  tensor([26.5779])\n",
      "Loss =  tensor([25.9481])\n",
      "Loss =  tensor([27.0939])\n",
      "Loss =  tensor([25.8917])\n",
      "Loss =  tensor([27.0525])\n",
      "Loss =  tensor([26.6766])\n",
      "Loss =  tensor([27.8629])\n",
      "Loss =  tensor([29.6183])\n",
      "Loss =  tensor([26.0668])\n",
      "Loss =  tensor([29.3480])\n",
      "Loss =  tensor([32.2502])\n",
      "Loss =  tensor([30.4347])\n",
      "Loss =  tensor([28.5952])\n",
      "Loss =  tensor([28.0815])\n",
      "Loss =  tensor([33.4146])\n",
      "Loss =  tensor([31.8275])\n",
      "Loss =  tensor([26.7728])\n",
      "Loss =  tensor([25.7159])\n",
      "Loss =  tensor([31.7808])\n",
      "Loss =  tensor([30.2732])\n",
      "Loss =  tensor([27.5298])\n",
      "Loss =  tensor([28.0821])\n",
      "Loss =  tensor([31.9016])\n",
      "Loss =  tensor([27.3902])\n",
      "Loss =  tensor([27.3888])\n",
      "Loss =  tensor([30.2864])\n",
      "Loss =  tensor([31.4853])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.49(best:0.59)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.92, 0.39](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.96)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 67\n",
      "Loss =  tensor([26.5127])\n",
      "Loss =  tensor([26.9823])\n",
      "Loss =  tensor([26.5744])\n",
      "Loss =  tensor([27.4418])\n",
      "Loss =  tensor([25.9415])\n",
      "Loss =  tensor([25.4717])\n",
      "Loss =  tensor([25.5312])\n",
      "Loss =  tensor([25.6147])\n",
      "Loss =  tensor([26.7409])\n",
      "Loss =  tensor([27.3147])\n",
      "Loss =  tensor([26.6472])\n",
      "Loss =  tensor([26.2411])\n",
      "Loss =  tensor([27.0142])\n",
      "Loss =  tensor([27.6545])\n",
      "Loss =  tensor([25.8061])\n",
      "Loss =  tensor([28.4014])\n",
      "Loss =  tensor([26.8342])\n",
      "Loss =  tensor([27.5958])\n",
      "Loss =  tensor([24.8218])\n",
      "Loss =  tensor([27.0254])\n",
      "Loss =  tensor([26.0061])\n",
      "Loss =  tensor([26.7462])\n",
      "Loss =  tensor([28.5762])\n",
      "Loss =  tensor([25.4944])\n",
      "Loss =  tensor([30.0013])\n",
      "Loss =  tensor([31.7118])\n",
      "Loss =  tensor([28.4989])\n",
      "Loss =  tensor([28.0542])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.37](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 68\n",
      "Loss =  tensor([26.3130])\n",
      "Loss =  tensor([34.1195])\n",
      "Loss =  tensor([40.3003])\n",
      "Loss =  tensor([38.8340])\n",
      "Loss =  tensor([39.6679])\n",
      "Loss =  tensor([32.4839])\n",
      "Loss =  tensor([26.4841])\n",
      "Loss =  tensor([29.9948])\n",
      "Loss =  tensor([39.8649])\n",
      "Loss =  tensor([38.5912])\n",
      "Loss =  tensor([36.2887])\n",
      "Loss =  tensor([29.3926])\n",
      "Loss =  tensor([26.3547])\n",
      "Loss =  tensor([29.2957])\n",
      "Loss =  tensor([32.4507])\n",
      "Loss =  tensor([30.0663])\n",
      "Loss =  tensor([26.6309])\n",
      "Loss =  tensor([26.4129])\n",
      "Loss =  tensor([28.8176])\n",
      "Loss =  tensor([26.5687])\n",
      "Loss =  tensor([26.1884])\n",
      "Loss =  tensor([27.0105])\n",
      "Loss =  tensor([29.0027])\n",
      "Loss =  tensor([26.5481])\n",
      "Loss =  tensor([26.3080])\n",
      "Loss =  tensor([28.1819])\n",
      "Loss =  tensor([25.0966])\n",
      "Loss =  tensor([27.6077])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.59)\n",
      "Validation Root accuracy:0.6(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.96)\n",
      "Training F1:[0.98, 0.95](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 69\n",
      "Loss =  tensor([25.3173])\n",
      "Loss =  tensor([26.3456])\n",
      "Loss =  tensor([25.4664])\n",
      "Loss =  tensor([25.1855])\n",
      "Loss =  tensor([26.9466])\n",
      "Loss =  tensor([26.4461])\n",
      "Loss =  tensor([26.4042])\n",
      "Loss =  tensor([25.7015])\n",
      "Loss =  tensor([26.8229])\n",
      "Loss =  tensor([25.8409])\n",
      "Loss =  tensor([26.1842])\n",
      "Loss =  tensor([27.7266])\n",
      "Loss =  tensor([27.3999])\n",
      "Loss =  tensor([25.1028])\n",
      "Loss =  tensor([27.7999])\n",
      "Loss =  tensor([27.8564])\n",
      "Loss =  tensor([26.9177])\n",
      "Loss =  tensor([26.1940])\n",
      "Loss =  tensor([25.7858])\n",
      "Loss =  tensor([28.0597])\n",
      "Loss =  tensor([27.5262])\n",
      "Loss =  tensor([26.0697])\n",
      "Loss =  tensor([27.8186])\n",
      "Loss =  tensor([25.6630])\n",
      "Loss =  tensor([27.5741])\n",
      "Loss =  tensor([30.3941])\n",
      "Loss =  tensor([28.0626])\n",
      "Loss =  tensor([27.5652])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.59(best:0.59)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.91, 0.29](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 70\n",
      "Loss =  tensor([26.2392])\n",
      "Loss =  tensor([26.8214])\n",
      "Loss =  tensor([27.3701])\n",
      "Loss =  tensor([24.8980])\n",
      "Loss =  tensor([28.4212])\n",
      "Loss =  tensor([28.2865])\n",
      "Loss =  tensor([28.9978])\n",
      "Loss =  tensor([26.1669])\n",
      "Loss =  tensor([27.9567])\n",
      "Loss =  tensor([27.1626])\n",
      "Loss =  tensor([25.8883])\n",
      "Loss =  tensor([27.0597])\n",
      "Loss =  tensor([26.6842])\n",
      "Loss =  tensor([24.6575])\n",
      "Loss =  tensor([26.3748])\n",
      "Loss =  tensor([26.7779])\n",
      "Loss =  tensor([26.8417])\n",
      "Loss =  tensor([28.0106])\n",
      "Loss =  tensor([26.7233])\n",
      "Loss =  tensor([26.4116])\n",
      "Loss =  tensor([27.7796])\n",
      "Loss =  tensor([26.7289])\n",
      "Loss =  tensor([25.5834])\n",
      "Loss =  tensor([27.3055])\n",
      "Loss =  tensor([25.5783])\n",
      "Loss =  tensor([26.2372])\n",
      "Loss =  tensor([28.6187])\n",
      "Loss =  tensor([27.1028])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.51(best:0.59)\n",
      "Validation Root accuracy:0.7(best:0.74)\n",
      "F1:[0.92, 0.39](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.97](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 71\n",
      "Loss =  tensor([26.7880])\n",
      "Loss =  tensor([24.2836])\n",
      "Loss =  tensor([26.0535])\n",
      "Loss =  tensor([26.7462])\n",
      "Loss =  tensor([24.8871])\n",
      "Loss =  tensor([24.8424])\n",
      "Loss =  tensor([27.3885])\n",
      "Loss =  tensor([25.4602])\n",
      "Loss =  tensor([24.8199])\n",
      "Loss =  tensor([27.6036])\n",
      "Loss =  tensor([25.8817])\n",
      "Loss =  tensor([26.4821])\n",
      "Loss =  tensor([24.8446])\n",
      "Loss =  tensor([26.4071])\n",
      "Loss =  tensor([29.6629])\n",
      "Loss =  tensor([30.9427])\n",
      "Loss =  tensor([29.4541])\n",
      "Loss =  tensor([26.6939])\n",
      "Loss =  tensor([25.8226])\n",
      "Loss =  tensor([28.4622])\n",
      "Loss =  tensor([26.7494])\n",
      "Loss =  tensor([27.6682])\n",
      "Loss =  tensor([26.5814])\n",
      "Loss =  tensor([29.4952])\n",
      "Loss =  tensor([30.3231])\n",
      "Loss =  tensor([27.9295])\n",
      "Loss =  tensor([26.5079])\n",
      "Loss =  tensor([27.9000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.52(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.4](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 72\n",
      "Loss =  tensor([25.3435])\n",
      "Loss =  tensor([26.8892])\n",
      "Loss =  tensor([25.5304])\n",
      "Loss =  tensor([25.0759])\n",
      "Loss =  tensor([28.0154])\n",
      "Loss =  tensor([25.0520])\n",
      "Loss =  tensor([26.9857])\n",
      "Loss =  tensor([29.0618])\n",
      "Loss =  tensor([31.1653])\n",
      "Loss =  tensor([26.0189])\n",
      "Loss =  tensor([25.1509])\n",
      "Loss =  tensor([27.4492])\n",
      "Loss =  tensor([25.1251])\n",
      "Loss =  tensor([25.5667])\n",
      "Loss =  tensor([24.6149])\n",
      "Loss =  tensor([26.5775])\n",
      "Loss =  tensor([29.2186])\n",
      "Loss =  tensor([28.5936])\n",
      "Loss =  tensor([27.5361])\n",
      "Loss =  tensor([27.5696])\n",
      "Loss =  tensor([25.3618])\n",
      "Loss =  tensor([26.6349])\n",
      "Loss =  tensor([27.2431])\n",
      "Loss =  tensor([25.5994])\n",
      "Loss =  tensor([26.7248])\n",
      "Loss =  tensor([26.3934])\n",
      "Loss =  tensor([25.6722])\n",
      "Loss =  tensor([26.6212])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.55(best:0.59)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.4](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 73\n",
      "Loss =  tensor([25.7149])\n",
      "Loss =  tensor([24.6094])\n",
      "Loss =  tensor([26.7399])\n",
      "Loss =  tensor([27.0085])\n",
      "Loss =  tensor([28.0799])\n",
      "Loss =  tensor([26.7611])\n",
      "Loss =  tensor([25.9708])\n",
      "Loss =  tensor([28.2993])\n",
      "Loss =  tensor([26.2320])\n",
      "Loss =  tensor([25.3003])\n",
      "Loss =  tensor([27.9480])\n",
      "Loss =  tensor([27.4204])\n",
      "Loss =  tensor([27.1794])\n",
      "Loss =  tensor([24.7427])\n",
      "Loss =  tensor([25.6708])\n",
      "Loss =  tensor([26.0371])\n",
      "Loss =  tensor([28.4133])\n",
      "Loss =  tensor([27.1618])\n",
      "Loss =  tensor([25.9584])\n",
      "Loss =  tensor([27.6453])\n",
      "Loss =  tensor([26.5647])\n",
      "Loss =  tensor([26.6744])\n",
      "Loss =  tensor([28.2708])\n",
      "Loss =  tensor([25.6108])\n",
      "Loss =  tensor([28.1935])\n",
      "Loss =  tensor([28.4508])\n",
      "Loss =  tensor([26.2191])\n",
      "Loss =  tensor([27.1174])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.47(best:0.59)\n",
      "Validation Root accuracy:0.72(best:0.74)\n",
      "F1:[0.92, 0.41](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 74\n",
      "Loss =  tensor([25.2870])\n",
      "Loss =  tensor([27.2994])\n",
      "Loss =  tensor([28.0133])\n",
      "Loss =  tensor([25.3182])\n",
      "Loss =  tensor([26.1969])\n",
      "Loss =  tensor([25.3453])\n",
      "Loss =  tensor([26.6915])\n",
      "Loss =  tensor([25.4935])\n",
      "Loss =  tensor([27.7723])\n",
      "Loss =  tensor([27.1763])\n",
      "Loss =  tensor([29.3812])\n",
      "Loss =  tensor([26.1779])\n",
      "Loss =  tensor([27.2897])\n",
      "Loss =  tensor([27.0215])\n",
      "Loss =  tensor([27.2619])\n",
      "Loss =  tensor([28.0050])\n",
      "Loss =  tensor([26.9965])\n",
      "Loss =  tensor([27.0430])\n",
      "Loss =  tensor([27.0984])\n",
      "Loss =  tensor([26.6177])\n",
      "Loss =  tensor([26.8781])\n",
      "Loss =  tensor([29.4721])\n",
      "Loss =  tensor([31.0297])\n",
      "Loss =  tensor([26.3646])\n",
      "Loss =  tensor([25.7773])\n",
      "Loss =  tensor([26.3999])\n",
      "Loss =  tensor([26.0633])\n",
      "Loss =  tensor([29.4017])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.6)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.91, 0.35](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 75\n",
      "Loss =  tensor([24.3812])\n",
      "Loss =  tensor([26.0118])\n",
      "Loss =  tensor([26.1146])\n",
      "Loss =  tensor([26.8387])\n",
      "Loss =  tensor([25.3329])\n",
      "Loss =  tensor([26.0278])\n",
      "Loss =  tensor([27.0887])\n",
      "Loss =  tensor([25.6537])\n",
      "Loss =  tensor([24.4653])\n",
      "Loss =  tensor([23.5174])\n",
      "Loss =  tensor([26.5538])\n",
      "Loss =  tensor([27.1923])\n",
      "Loss =  tensor([25.4097])\n",
      "Loss =  tensor([26.1565])\n",
      "Loss =  tensor([26.6957])\n",
      "Loss =  tensor([28.0659])\n",
      "Loss =  tensor([26.9252])\n",
      "Loss =  tensor([25.4650])\n",
      "Loss =  tensor([25.9229])\n",
      "Loss =  tensor([26.1042])\n",
      "Loss =  tensor([26.9855])\n",
      "Loss =  tensor([26.5434])\n",
      "Loss =  tensor([27.3544])\n",
      "Loss =  tensor([25.8548])\n",
      "Loss =  tensor([23.9611])\n",
      "Loss =  tensor([25.3681])\n",
      "Loss =  tensor([26.5573])\n",
      "Loss =  tensor([26.8716])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:13\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.53(best:0.6)\n",
      "Validation Root accuracy:0.71(best:0.74)\n",
      "F1:[0.92, 0.37](best:0.97 , 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:03:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 76\n",
      "Loss =  tensor([25.8881])\n",
      "Loss =  tensor([25.2020])\n",
      "Loss =  tensor([25.4449])\n",
      "Loss =  tensor([25.5588])\n",
      "Loss =  tensor([27.6647])\n",
      "Loss =  tensor([26.5696])\n",
      "Loss =  tensor([25.8949])\n",
      "Loss =  tensor([25.0361])\n",
      "Loss =  tensor([25.5744])\n",
      "Loss =  tensor([24.8444])\n",
      "Loss =  tensor([25.9443])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "#     trn = get_trn()\n",
    "    print(\"\\n\\nEpoch %d\" % epoch)\n",
    "    logging.info('Epoch: '+str(epoch))\n",
    "#     pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trn)/BATCH_SIZE).start()\n",
    "    params = []\n",
    "    for i in range(0,len(trn),BATCH_SIZE):\n",
    "        count+=1\n",
    "        batch = trn[i:min(i+BATCH_SIZE,len(trn))]\n",
    "        def closure():\n",
    "            global count\n",
    "            optimizer.zero_grad()\n",
    "            _,total_loss = model.getLoss(trn[0].root)\n",
    "            for tree in batch:\n",
    "                _, loss = model.getLoss(tree.root)\n",
    "                total_loss += loss\n",
    "\n",
    "            total_loss = total_loss/len(batch)\n",
    "            #L2 reg\n",
    "            param_dict = dict()\n",
    "            for name, param in model.named_parameters():\n",
    "                param_dict[name] = param.data.clone()\n",
    "                if param.requires_grad:\n",
    "                        total_loss += 0.5*l2_reg[name]*(torch.norm(param)**2)\n",
    "            params.append(param_dict)\n",
    "            print('Loss = ',total_loss.data)\n",
    "            logging.info('Loss = '+str(total_loss.data))\n",
    "            logger.scalar_summary('loss', total_loss.data, count)\n",
    "            total_loss.backward()\n",
    "            clip_grad_norm_(model.parameters(),5,2)\n",
    "            return total_loss\n",
    "#         pbar.update(i/BATCH_SIZE)\n",
    "        optimizer.step(closure)\n",
    "\n",
    "#     pbar.finish()\n",
    "\n",
    "    avg_param = dict()\n",
    "    for name, param1 in model.named_parameters():\n",
    "            avg_param[name] = param1.data.clone()\n",
    "\n",
    "    for i in range(1,len(params)):\n",
    "        for name, param in params[i].items():\n",
    "            avg_param[name] += param.clone()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name == 'embedding.weight':\n",
    "            continue\n",
    "        param.data = avg_param[name]/len(params)\n",
    "\n",
    "    correctRoot, correctAll, f1 = model.evaluate(dev)\n",
    "    # correctRoot = model.eval_sent_lvl(dev,LR_clf)\n",
    "    if bestAll<correctAll: bestAll=correctAll\n",
    "    if bestRoot<correctRoot: bestRoot=correctRoot\n",
    "    if bestF1_0<f1[0]: bestF1_0=f1[0]\n",
    "    if bestF1_1<f1[1]: bestF1_1=f1[1]\n",
    "    print(\"\\nValidation All-nodes accuracy:\"+str(round(correctAll,2))+\"(best:\"+str(round(bestAll,2))+\")\")\n",
    "    print(\"Validation Root accuracy:\" + str(round(correctRoot,2))+\"(best:\"+str(round(bestRoot,2))+\")\")\n",
    "    print(\"F1:\"+str([round(x,2) for x in f1])+\"(best:\"+str(round(bestF1_0,2))+\" , \"+str(round(bestF1_1,2))+\")\")\n",
    "    logging.info(\"Validation All-nodes accuracy:\"+str(round(correctAll,2))+\"(best:\"+str(round(bestAll,2))+\")\")\n",
    "    logging.info(\"Validation Root accuracy:\" + str(round(correctRoot,2))+\"(best:\"+str(round(bestRoot,2))+\")\")\n",
    "    logging.info(\"F1:\"+str([round(x,2) for x in f1])+\"(best:\"+str(round(bestF1_0,2))+\" , \"+str(round(bestF1_1,2))+\")\")\n",
    "    correct_trn_Root, correct_trn_All, f1_trn = model.evaluate(trn)\n",
    "    # correctRoot = model.eval_sent_lvl(dev,LR_clf)\n",
    "    if best_trn_All<correct_trn_All: best_trn_All=correct_trn_All\n",
    "    if best_trn_Root<correct_trn_Root: best_trn_Root=correct_trn_Root\n",
    "    if best_trn_F1_0<f1_trn[0]: best_trn_F1_0=f1_trn[0]\n",
    "    if best_trn_F1_1<f1_trn[1]: best_trn_F1_1=f1_trn[1]\n",
    "    print(\"\\nTraining All-nodes accuracy:\"+str(round(correct_trn_All,2))+\"(best:\"+str(round(best_trn_All,2))+\")\")\n",
    "    print(\"Training Root// accuracy:\" + str(round(correct_trn_Root,2))+\"(best:\"+str(round(best_trn_Root,2))+\")\")\n",
    "    print(\"Training F1:\"+str([round(x,2) for x in f1_trn])+\"(best:\"+str(round(best_trn_F1_0,2))+\" , \"+str(round(best_trn_F1_1,2))+\")\")\n",
    "    logging.info(\"Training All-nodes accuracy:\"+str(round(correct_trn_All,2))+\"(best:\"+str(round(best_trn_All,2))+\")\")\n",
    "    logging.info(\"Training Root accuracy:\" + str(round(correct_trn_Root,2))+\"(best:\"+str(round(best_trn_Root,2))+\")\")\n",
    "    logging.info(\"Training F1:\"+str([round(x,2) for x in f1_trn])+\"(best:\"+str(round(best_trn_F1_0,2))+\" , \"+str(round(best_trn_F1_1,2))+\")\")\n",
    "    info = {'valid_root_acc':correctRoot, 'valid_tree_acc':correctAll, 'train_root_acc':correct_trn_Root, 'train_tree_acc':correct_trn_All}\n",
    "    for tag, value in info.items():\n",
    "        logger.scalar_summary(tag,value,epoch)\n",
    "    random.shuffle(trn)\n",
    "    if epoch>0 and epoch%10==0:\n",
    "        pickle.dump(model,open(\"./models/checkpoints/\"+namecode+'_epoch_'+str(epoch)+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open(\"./models/\"+namecode+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
