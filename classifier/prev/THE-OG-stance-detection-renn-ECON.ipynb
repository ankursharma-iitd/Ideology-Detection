{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import progressbar\n",
    "import torch\n",
    "import pickle\n",
    "from mytree import *\n",
    "from utils import *\n",
    "from treeUtil import *\n",
    "import tqdm\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import functools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import string\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import nltk.tree\n",
    "from ast import literal_eval\n",
    "import pptree\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from spacy.pipeline import merge_entities\n",
    "nlp = en_core_web_sm.load()\n",
    "nlp.add_pipe(merge_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False if in-domain; True if general\n",
    "proanti = False\n",
    "w2vec = False\n",
    "ner = True\n",
    "blackout = False\n",
    "balanced = True\n",
    "undersample = False\n",
    "non_trainable = True\n",
    "economic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic_w2v_0ProAnti_0General_1NER_0Blackout_1Balance_0Undersample_1Fixed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {0:'ProAnti', 1:'General', 2:'NER', 3:'Blackout', 4:'Balance', 5:'Undersample', 6:'Fixed'}\n",
    "bool_list = [proanti, w2vec, ner, blackout, balanced, undersample, non_trainable]\n",
    "corpus_path = '../data/new/economic'\n",
    "namecode = 'economic_w2v'\n",
    "for index, bb in enumerate(bool_list):\n",
    "    namecode += '_'\n",
    "    if bb:\n",
    "        namecode += '1'\n",
    "    else:\n",
    "        namecode += '0'\n",
    "    namecode += dic[index]\n",
    "namecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For logging\n",
    "import logging\n",
    "\n",
    "#Remove all the previous handlers\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "#Create the file for logging purposes -> CHANGE THE LEVEL TYPE TO logging.DEBUG when debugging or finding faults\n",
    "logging.basicConfig(filename='log_'+namecode+'.log',\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "                            level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger('./logs_'+namecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveNN(nn.Module):\n",
    "    def __init__(self, word_embeddings, vocab, embedSize=300, numClasses=2, beta = 0.3, use_weight = True, non_trainable = non_trainable):\n",
    "        super(RecursiveNN, self).__init__()\n",
    "#             if (w2vec):\n",
    "#                 self.embedding = nn.Embedding(len(vocab), embedSize)\n",
    "#                 self.embedding.load_state_dict({'weight': w2vec_weights})\n",
    "        self.embedding = nn.Embedding.from_pretrained(word_embeddings)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        if non_trainable:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(len(vocab), embedSize)\n",
    "        self.embedding = nn.Embedding(len(vocab), embedSize)\n",
    "        self.W = nn.Linear(2*embedSize, embedSize, bias=True)\n",
    "        self.nonLinear = torch.tanh\n",
    "        self.projection = nn.Linear(embedSize, numClasses, bias=True)\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.loss = Var(torch.FloatTensor([0]))\n",
    "        self.V = vocab\n",
    "        self.beta = beta\n",
    "        self.use_weight = use_weight\n",
    "        self.total_rep = None #\n",
    "        self.count_rep = 0 #\n",
    "        self.numClasses = numClasses\n",
    "\n",
    "    def traverse(self, node):\n",
    "        if node.isLeaf:\n",
    "            if node.getLeafWord() in self.V:  # check if right word is in vocabulary\n",
    "                word = node.getLeafWord()\n",
    "            else:  # otherwise use the unknown token\n",
    "                word = 'UNK'\n",
    "            # print(self.V[word],len(self.V),word,(torch.LongTensor([int(self.V[word])])))\n",
    "            currentNode = (self.embedding(Var(torch.LongTensor([int(self.V[word])]))))\n",
    "        else: currentNode = self.nonLinear(self.W(torch.cat((self.traverse(node.left),self.traverse(node.right)),1)))\n",
    "        currentNode = currentNode/(torch.norm(currentNode))\n",
    "\n",
    "        assert node.label!=None\n",
    "        self.nodeProbList.append(self.projection(currentNode))\n",
    "        # print (node.label)\n",
    "        self.labelList.append(torch.LongTensor([node.label]))\n",
    "        loss_weight = 1-self.beta if node.annotated else self.beta\n",
    "        self.loss += (loss_weight*F.cross_entropy(input=torch.cat([self.projection(currentNode)]),target=Var(torch.cat([torch.LongTensor([node.label])]))))\n",
    "\n",
    "        #\n",
    "        if not node.isRoot():\n",
    "            if self.total_rep is None:\n",
    "                self.total_rep = currentNode.data.clone()\n",
    "            else:\n",
    "                self.total_rep += currentNode.data.clone()\n",
    "            self.count_rep += 1\n",
    "        #\n",
    "\n",
    "        return currentNode        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.loss = Var(torch.FloatTensor([0]))\n",
    "        self.traverse(x)\n",
    "        self.labelList = Var(torch.cat(self.labelList))\n",
    "        return torch.cat(self.nodeProbList)\n",
    "\n",
    "    def getLoss(self, tree):\n",
    "        nodes = self.forward(tree)\n",
    "        predictions = nodes.max(dim=1)[1]\n",
    "        loss = self.loss\n",
    "        return predictions,loss\n",
    "\n",
    "    def getRep(self, tree):\n",
    "        self.count_rep = 0\n",
    "        self.total_rep = None\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.loss = Var(torch.FloatTensor([0]))\n",
    "\n",
    "        root_rep = self.traverse(tree)\n",
    "\n",
    "        return (torch.cat((root_rep,self.total_rep/self.count_rep),1)).data.numpy().T.flatten()\n",
    "\n",
    "\n",
    "    def evaluate(self, trees):\n",
    "            pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "            n = nAll = correctRoot = correctAll = 0.0\n",
    "            tp = [1e-2]*self.numClasses\n",
    "            fp = [1e-2]*self.numClasses\n",
    "            fn = [1e-2]*self.numClasses\n",
    "            f1 = [0.]*self.numClasses\n",
    "            for j, tree in enumerate(trees):\n",
    "                predictions,_ = self.getLoss(tree.root)\n",
    "#                     print((predictions.cpu().data).numpy(),(predictions.cpu().data).numpy().shape)\n",
    "#                     print((self.labelList.cpu().data).numpy(), (self.labelList.cpu().data).numpy().shape)\n",
    "                correct = ((predictions.cpu().data).numpy()==(self.labelList.cpu().data).numpy())\n",
    "#                     print(correct)\n",
    "                correctAll += correct.sum()\n",
    "                nAll += np.shape(correct.squeeze())[0] if np.size(correct)!=1 else 1 \n",
    "                correctRoot += correct.squeeze()[-1] if np.size(correct)!=1 else correct[-1]\n",
    "#                     print(correct.squeeze()[-1] if np.size(correct)!=1 else correct[-1])\n",
    "#                     print('actual: {}'.format(tree.root.label))\n",
    "                for i in range(self.numClasses):\n",
    "                    size = np.size((predictions.cpu().data).numpy())\n",
    "                    if size!=1:\n",
    "                        pred = (predictions.cpu().data).numpy().squeeze()[-1]\n",
    "                        actual = (self.labelList.cpu().data).numpy().squeeze()[-1]\n",
    "                    else:\n",
    "                        pred = (predictions.cpu().data).numpy()[-1]\n",
    "                        actual = (self.labelList.cpu().data).numpy()[-1]\n",
    "                    if pred==i and actual==i:\n",
    "                        tp[i]+=1\n",
    "                    elif pred==i and actual!=i:\n",
    "                        fn[i]+=1\n",
    "                    elif pred==i and actual!=i:\n",
    "                        fp[i]+=1\n",
    "                n += 1\n",
    "                pbar.update(j)\n",
    "#             print(tp,fp,fn)\n",
    "            for i in range(self.numClasses):\n",
    "                p =(1.0*tp[i]/(tp[i]+fp[i]))\n",
    "                r =(1.0*tp[i]/(tp[i]+fn[i]))\n",
    "                f1[i] = (2*p*r)/(p+r)\n",
    "            pbar.finish()\n",
    "            return correctRoot / n, correctAll/nAll, f1\n",
    "\n",
    "    def eval_sent_lvl(self,trees,clf):\n",
    "        pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "        n = nAll = correctRoot = correctAll = 0.0\n",
    "        X_predict = []\n",
    "        Y_gold = []\n",
    "        for j, tree in enumerate(trees):\n",
    "            tree_rep = model.getRep(tree.root)\n",
    "            X_predict.append(tree_rep)\n",
    "            Y_gold.append(tree.root.label)\n",
    "        acc = clf.score(np.array(X_predict),np.array(Y_gold))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_trees = 'econ_step1_trees.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(\"./trees/df_\"+file_trees, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = set(sum(df_train['tokens'],[]))\n",
    "\n",
    "word2idx = {}\n",
    "word2idx['UNK']=0\n",
    "i = 1\n",
    "for token in list(all_tokens):\n",
    "    word2idx[token] = i\n",
    "    i+=1\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: 'Sharma',\n",
       " 2: 'bamboo',\n",
       " 3: 'difficulty',\n",
       " 4: 'inflicted',\n",
       " 5: 'tools',\n",
       " 6: 'ignore',\n",
       " 7: 'resurface',\n",
       " 8: 'unbanked',\n",
       " 9: 'editor',\n",
       " 10: 'Old',\n",
       " 11: 'collect',\n",
       " 12: 'Nabard',\n",
       " 13: 'Ban',\n",
       " 14: 'subjugated',\n",
       " 15: 'sits',\n",
       " 16: 'Madan',\n",
       " 17: 'fertilizer',\n",
       " 18: 'busy',\n",
       " 19: 'celebrating',\n",
       " 20: 'Anand',\n",
       " 21: 'maturity',\n",
       " 22: 'cap',\n",
       " 23: 'TV',\n",
       " 24: 'ecstatic',\n",
       " 25: 'whose',\n",
       " 26: 'municipal',\n",
       " 27: 'boosting',\n",
       " 28: 'my',\n",
       " 29: 'Future',\n",
       " 30: 'partners',\n",
       " 31: 'Mehbooba',\n",
       " 32: 'bear',\n",
       " 33: 'MRP',\n",
       " 34: 'firmly',\n",
       " 35: 'Sahebganj',\n",
       " 36: 'Babu',\n",
       " 37: 'group',\n",
       " 38: 'BCCI',\n",
       " 39: 'professor',\n",
       " 40: 'promised',\n",
       " 41: 'Istprime',\n",
       " 42: 'juices',\n",
       " 43: 'E',\n",
       " 44: 'victory',\n",
       " 45: 'trade',\n",
       " 46: 'slab',\n",
       " 47: 'Private',\n",
       " 48: 'shorter',\n",
       " 49: 'Pmghaziabad',\n",
       " 50: 'board',\n",
       " 51: 'affected',\n",
       " 52: 'easy',\n",
       " 53: 'legitimate',\n",
       " 54: 'called',\n",
       " 55: 'Mocking',\n",
       " 56: 'Agriculturists',\n",
       " 57: 'Patiala',\n",
       " 58: 'assembly',\n",
       " 59: 'Ambanis',\n",
       " 60: 'administration',\n",
       " 61: 'contaminated',\n",
       " 62: 'advantage',\n",
       " 63: 'admitted',\n",
       " 64: 'Bhagwan',\n",
       " 65: 'shot',\n",
       " 66: 'flustered',\n",
       " 67: 'employees',\n",
       " 68: 'negated',\n",
       " 69: 'Ugrahan',\n",
       " 70: 'challenge',\n",
       " 71: 'sake',\n",
       " 72: 'AUR',\n",
       " 73: 'Shivrajsinghchouhan',\n",
       " 74: 'British',\n",
       " 75: 'Gudagur',\n",
       " 76: 'alliance',\n",
       " 77: 'better',\n",
       " 78: 'Badals',\n",
       " 79: 'Upma',\n",
       " 80: 'operator',\n",
       " 81: 'declaring',\n",
       " 82: 'constituting',\n",
       " 83: 'grave',\n",
       " 84: 'coconut',\n",
       " 85: 'mum',\n",
       " 86: 'Pmnew',\n",
       " 87: 'mistrust',\n",
       " 88: 'videoconference',\n",
       " 89: 'lesser',\n",
       " 90: 'makers',\n",
       " 91: 'or',\n",
       " 92: 'drought',\n",
       " 93: 'Istin',\n",
       " 94: 'tilling',\n",
       " 95: 'midnight',\n",
       " 96: 'Icai',\n",
       " 97: 'Dcc',\n",
       " 98: 'SCS',\n",
       " 99: 'beforehand',\n",
       " 100: 'brighten',\n",
       " 101: 'Non',\n",
       " 102: 'paid',\n",
       " 103: 'overwhelming',\n",
       " 104: 'tomato',\n",
       " 105: 'bowl',\n",
       " 106: 'drama',\n",
       " 107: 'during',\n",
       " 108: 'negative',\n",
       " 109: 'drastic',\n",
       " 110: 'expects',\n",
       " 111: 'unannounced',\n",
       " 112: 'nation',\n",
       " 113: 'paramount',\n",
       " 114: 'recently',\n",
       " 115: 'sections',\n",
       " 116: 'Tiwari',\n",
       " 117: 'recent',\n",
       " 118: 'installed',\n",
       " 119: 'intense',\n",
       " 120: 'overcome',\n",
       " 121: 'committees',\n",
       " 122: 'neglect',\n",
       " 123: 'meetings',\n",
       " 124: 'noted',\n",
       " 125: 'Water',\n",
       " 126: 'Arjun',\n",
       " 127: 'previous',\n",
       " 128: 'misplaced',\n",
       " 129: 'deeper',\n",
       " 130: 'T',\n",
       " 131: 'immigrants',\n",
       " 132: 'Pradesh',\n",
       " 133: 'amount',\n",
       " 134: 'DY',\n",
       " 135: 'bringing',\n",
       " 136: 'parked',\n",
       " 137: 'Mulayam',\n",
       " 138: 'unscrupulous',\n",
       " 139: 'lists',\n",
       " 140: 'DEC',\n",
       " 141: 'Maidur',\n",
       " 142: 'grab',\n",
       " 143: 'transitions',\n",
       " 144: 'Relief',\n",
       " 145: 'conceal',\n",
       " 146: 'KRS',\n",
       " 147: 'feed',\n",
       " 148: 'urged',\n",
       " 149: 'Ex',\n",
       " 150: 'training',\n",
       " 151: 'insensitive',\n",
       " 152: 'entrepreneurial',\n",
       " 153: 'faster',\n",
       " 154: 'kitchen',\n",
       " 155: 'visit',\n",
       " 156: 'America',\n",
       " 157: 'revolving',\n",
       " 158: 'once',\n",
       " 159: 'light',\n",
       " 160: 'sincerity',\n",
       " 161: 'develop',\n",
       " 162: 'cop',\n",
       " 163: 'cattle',\n",
       " 164: 'favour',\n",
       " 165: 'Arabhavi',\n",
       " 166: 'urgent',\n",
       " 167: 'outreach',\n",
       " 168: 'Panchayat',\n",
       " 169: 'samples',\n",
       " 170: 'engaging',\n",
       " 171: 'feeder',\n",
       " 172: 'ambitious',\n",
       " 173: 'atrocities',\n",
       " 174: 'Newswe',\n",
       " 175: 'washout',\n",
       " 176: 'misinterpreted',\n",
       " 177: 'Dodhia',\n",
       " 178: 'passage',\n",
       " 179: 'television',\n",
       " 180: 'indirectly',\n",
       " 181: 'ATMs',\n",
       " 182: 'promoted',\n",
       " 183: 'taken',\n",
       " 184: 'lawmakers',\n",
       " 185: 'Cpi',\n",
       " 186: 'processing',\n",
       " 187: 'achieved',\n",
       " 188: 'transitioning',\n",
       " 189: 'flicking',\n",
       " 190: 'mongering',\n",
       " 191: 'grains',\n",
       " 192: 'jam',\n",
       " 193: 'newly',\n",
       " 194: 'BN',\n",
       " 195: 'deliver',\n",
       " 196: 'garments',\n",
       " 197: 'Vidhan',\n",
       " 198: 'applicant',\n",
       " 199: 'mileage',\n",
       " 200: 'her',\n",
       " 201: 'riverfront',\n",
       " 202: 'hopeful',\n",
       " 203: 'instances',\n",
       " 204: 'pros',\n",
       " 205: 'hoped',\n",
       " 206: 'link',\n",
       " 207: 'terrorists',\n",
       " 208: 'sharp',\n",
       " 209: 'safeguards',\n",
       " 210: 'Dop',\n",
       " 211: 'pointing',\n",
       " 212: 'drip',\n",
       " 213: 'invoice',\n",
       " 214: 'positives',\n",
       " 215: 'predecessor',\n",
       " 216: 'young',\n",
       " 217: 'religion',\n",
       " 218: 'SAB',\n",
       " 219: 'foundation',\n",
       " 220: 'Jind',\n",
       " 221: 'Resowing',\n",
       " 222: 'tolerated',\n",
       " 223: 'scrambling',\n",
       " 224: 'joke',\n",
       " 225: 'Cdms',\n",
       " 226: 'express',\n",
       " 227: 'ISRO',\n",
       " 228: 'Pushpushing',\n",
       " 229: 'brainchild',\n",
       " 230: 'unambiguously',\n",
       " 231: 'Katrawala',\n",
       " 232: 'Aug',\n",
       " 233: 'Faifa',\n",
       " 234: 'misuse',\n",
       " 235: 'strict',\n",
       " 236: 'comprehensive',\n",
       " 237: 'followed',\n",
       " 238: 'controversy',\n",
       " 239: 'pressures',\n",
       " 240: 'turf',\n",
       " 241: 'unauthorised',\n",
       " 242: 'women',\n",
       " 243: 'kind',\n",
       " 244: 'Billchief',\n",
       " 245: 'Ficn',\n",
       " 246: 'seeded',\n",
       " 247: 'grid',\n",
       " 248: 'test',\n",
       " 249: 'currency',\n",
       " 250: 'leaked',\n",
       " 251: 'pave',\n",
       " 252: 'R',\n",
       " 253: 'lands',\n",
       " 254: 'litigants',\n",
       " 255: 'space',\n",
       " 256: 'processes',\n",
       " 257: 'panels',\n",
       " 258: 'initially',\n",
       " 259: 'lucky',\n",
       " 260: 'realized',\n",
       " 261: 'apples',\n",
       " 262: 'slowdown',\n",
       " 263: 'Jai',\n",
       " 264: 'readjust',\n",
       " 265: 'Comparing',\n",
       " 266: 'Jumla',\n",
       " 267: 'angered',\n",
       " 268: 'video',\n",
       " 269: 'pathetic',\n",
       " 270: 'smaller',\n",
       " 271: 'Indian',\n",
       " 272: 'worker',\n",
       " 273: 'saying',\n",
       " 274: 'aggression',\n",
       " 275: 'paddy',\n",
       " 276: 'Prone',\n",
       " 277: 'Cmtargeting',\n",
       " 278: 'irrigating',\n",
       " 279: 'Hindustan',\n",
       " 280: 'One',\n",
       " 281: 'pledge',\n",
       " 282: 'stressed',\n",
       " 283: 'invalidate',\n",
       " 284: 'relating',\n",
       " 285: 'grand',\n",
       " 286: 'misguiding',\n",
       " 287: 'accountants',\n",
       " 288: 'penal',\n",
       " 289: 'seeking',\n",
       " 290: 'convert',\n",
       " 291: 'Environment',\n",
       " 292: 'chasing',\n",
       " 293: 'll',\n",
       " 294: 'linking',\n",
       " 295: 'yes',\n",
       " 296: 'notifications',\n",
       " 297: 'Type',\n",
       " 298: 'Participating',\n",
       " 299: 'circle',\n",
       " 300: 'fruition',\n",
       " 301: 'People',\n",
       " 302: 'attract',\n",
       " 303: 'exempted',\n",
       " 304: 'product',\n",
       " 305: 'IITs',\n",
       " 306: 'cm',\n",
       " 307: 'protecting',\n",
       " 308: 'Idli',\n",
       " 309: 'termites',\n",
       " 310: 'Constitution',\n",
       " 311: 'masalas',\n",
       " 312: 'Twitter',\n",
       " 313: 'Raj',\n",
       " 314: 'division',\n",
       " 315: 'foolproof',\n",
       " 316: 'suspension',\n",
       " 317: 'Demonetisation',\n",
       " 318: 'suck',\n",
       " 319: 'flight',\n",
       " 320: 'Ke',\n",
       " 321: 'unaccounted',\n",
       " 322: 'questioned',\n",
       " 323: 'Fadnavis',\n",
       " 324: 'types',\n",
       " 325: 'settle',\n",
       " 326: 'inter',\n",
       " 327: 'Amrg',\n",
       " 328: 'either',\n",
       " 329: 'refreshing',\n",
       " 330: 'Istdismissing',\n",
       " 331: 'As',\n",
       " 332: 'upheavals',\n",
       " 333: 'blue',\n",
       " 334: 'Times',\n",
       " 335: 'labour',\n",
       " 336: 'Tumakuru',\n",
       " 337: 'sharply',\n",
       " 338: 'initiate',\n",
       " 339: 'tariffs',\n",
       " 340: 'then',\n",
       " 341: 'Samanvaya',\n",
       " 342: 'SBN',\n",
       " 343: 'Indo',\n",
       " 344: 'Legislators',\n",
       " 345: 'stunts',\n",
       " 346: 'prescribed',\n",
       " 347: 'Gurgaon',\n",
       " 348: 'satisfactory',\n",
       " 349: 'sufficiency',\n",
       " 350: 'Ajmer',\n",
       " 351: 'seed',\n",
       " 352: 'Yogendra',\n",
       " 353: 'honoured',\n",
       " 354: 'De',\n",
       " 355: 'digital',\n",
       " 356: 'naming',\n",
       " 357: 'Bandra',\n",
       " 358: 'added',\n",
       " 359: 'groups',\n",
       " 360: 'can',\n",
       " 361: 'Less',\n",
       " 362: 'extended',\n",
       " 363: 'decline',\n",
       " 364: 'regularly',\n",
       " 365: 'mulling',\n",
       " 366: 'justification',\n",
       " 367: 'Pandeynaik',\n",
       " 368: 'emergency',\n",
       " 369: 'amendment',\n",
       " 370: 'warnings',\n",
       " 371: 'According',\n",
       " 372: 'Shaktikanta',\n",
       " 373: 'mood',\n",
       " 374: 'reliant',\n",
       " 375: 'assessing',\n",
       " 376: 'Kumaraswamy',\n",
       " 377: 'Senior',\n",
       " 378: 'vibrant',\n",
       " 379: 'engineer',\n",
       " 380: 'considerable',\n",
       " 381: 'involved',\n",
       " 382: 'affidavit',\n",
       " 383: 'enjoying',\n",
       " 384: 'complex',\n",
       " 385: 'consumers',\n",
       " 386: 'Now',\n",
       " 387: 'Meanwhile',\n",
       " 388: 'heavy',\n",
       " 389: 'fly',\n",
       " 390: 'comprising',\n",
       " 391: 'certify',\n",
       " 392: 'Urgently',\n",
       " 393: 'benefitted',\n",
       " 394: 'leveraging',\n",
       " 395: 'Lokpal',\n",
       " 396: 'confident',\n",
       " 397: 'gain',\n",
       " 398: 'Surjeet',\n",
       " 399: 'practices',\n",
       " 400: 'gave',\n",
       " 401: 'cleared',\n",
       " 402: 'hrs',\n",
       " 403: 'Gannaur',\n",
       " 404: 'Ballari',\n",
       " 405: 'tillers',\n",
       " 406: 'Ashrama',\n",
       " 407: 'wider',\n",
       " 408: 'Referring',\n",
       " 409: 'existing',\n",
       " 410: 'communication',\n",
       " 411: 'Agra',\n",
       " 412: 'chambers',\n",
       " 413: 'Wondering',\n",
       " 414: 'deserving',\n",
       " 415: 'dependency',\n",
       " 416: 'tenure',\n",
       " 417: 'glitz',\n",
       " 418: 'release',\n",
       " 419: 'miles',\n",
       " 420: 'Orderedbelgaum',\n",
       " 421: 'remove',\n",
       " 422: 'interact',\n",
       " 423: 'decides',\n",
       " 424: 'lab',\n",
       " 425: 'territories',\n",
       " 426: 'collective',\n",
       " 427: 'copying',\n",
       " 428: 'Also',\n",
       " 429: 'speakers',\n",
       " 430: 'cheers',\n",
       " 431: 'German',\n",
       " 432: 'normalise',\n",
       " 433: 'routes',\n",
       " 434: 'isolation',\n",
       " 435: 'Chinese',\n",
       " 436: 'indefinite',\n",
       " 437: 'substance',\n",
       " 438: 'massive',\n",
       " 439: 'sanctuaries',\n",
       " 440: 'than',\n",
       " 441: 'apex',\n",
       " 442: 'Chiefbangalore',\n",
       " 443: 'sp',\n",
       " 444: 'clarified',\n",
       " 445: 'valedictory',\n",
       " 446: 'number',\n",
       " 447: 'Igps',\n",
       " 448: 'minions',\n",
       " 449: 'GDP',\n",
       " 450: 'abundance',\n",
       " 451: 'hardware',\n",
       " 452: 'wondered',\n",
       " 453: 'Motherly',\n",
       " 454: 'pledged',\n",
       " 455: 'JD',\n",
       " 456: 'obvious',\n",
       " 457: 'Describing',\n",
       " 458: 'protection',\n",
       " 459: 'possibility',\n",
       " 460: 'spotlight',\n",
       " 461: 'auditor',\n",
       " 462: 'weakest',\n",
       " 463: 'km',\n",
       " 464: 'joint',\n",
       " 465: 'requests',\n",
       " 466: 'perennially',\n",
       " 467: 'aftermath',\n",
       " 468: 'Ghaziabad',\n",
       " 469: 'strain',\n",
       " 470: 'earned',\n",
       " 471: 'perhaps',\n",
       " 472: 'unpaid',\n",
       " 473: 'laws',\n",
       " 474: 'Mohan',\n",
       " 475: 'Aicc',\n",
       " 476: 'Eligible',\n",
       " 477: 'Fayeda',\n",
       " 478: 'Sawant',\n",
       " 479: 'input',\n",
       " 480: 'Mamatabanerjee',\n",
       " 481: 'corruption',\n",
       " 482: 'Likewise',\n",
       " 483: 'span',\n",
       " 484: 'union',\n",
       " 485: 'organic',\n",
       " 486: 'heads',\n",
       " 487: 'touted',\n",
       " 488: 'Gowda',\n",
       " 489: 'crediting',\n",
       " 490: 'dying',\n",
       " 491: 'living',\n",
       " 492: 'Wadiyar',\n",
       " 493: 'somehow',\n",
       " 494: 'Oriented',\n",
       " 495: 'Naare',\n",
       " 496: 'team',\n",
       " 497: 'seriousness',\n",
       " 498: 'usable',\n",
       " 499: 'efficiencies',\n",
       " 500: 'scalable',\n",
       " 501: 'summary',\n",
       " 502: 'spokesman',\n",
       " 503: 'Whatever',\n",
       " 504: 'Bhagya',\n",
       " 505: 'remittance',\n",
       " 506: 'determination',\n",
       " 507: 'spirit',\n",
       " 508: 'government',\n",
       " 509: 'full',\n",
       " 510: 'hopes',\n",
       " 511: 'buyer',\n",
       " 512: 'counterpart',\n",
       " 513: 'gross',\n",
       " 514: 'notice',\n",
       " 515: 'ends',\n",
       " 516: 'trove',\n",
       " 517: 'only',\n",
       " 518: 'exist',\n",
       " 519: 'valley',\n",
       " 520: 'Siddaramaiah',\n",
       " 521: 'NASSCOM',\n",
       " 522: 'prepares',\n",
       " 523: 'crying',\n",
       " 524: 'create',\n",
       " 525: 'official',\n",
       " 526: 'main',\n",
       " 527: 'Dmk',\n",
       " 528: 'NDTV',\n",
       " 529: 'security',\n",
       " 530: 'apprehension',\n",
       " 531: 'Thw',\n",
       " 532: 'fruitful',\n",
       " 533: 'work',\n",
       " 534: 'lock',\n",
       " 535: 'Contrary',\n",
       " 536: 'Promising',\n",
       " 537: 'experience',\n",
       " 538: 'frequency',\n",
       " 539: 'render',\n",
       " 540: 'multiplicity',\n",
       " 541: 'agenda',\n",
       " 542: 'blow',\n",
       " 543: 'begun',\n",
       " 544: 'put',\n",
       " 545: 'consider',\n",
       " 546: 'D',\n",
       " 547: 'foodgrains',\n",
       " 548: 'headquarters',\n",
       " 549: 'needs',\n",
       " 550: 'opening',\n",
       " 551: 'cries',\n",
       " 552: 'function',\n",
       " 553: 'jeopardised',\n",
       " 554: 'incorrect',\n",
       " 555: 'proofs',\n",
       " 556: 'Inflationary',\n",
       " 557: 'innovation',\n",
       " 558: 'communicating',\n",
       " 559: 'conveyed',\n",
       " 560: 'irrational',\n",
       " 561: 'committed',\n",
       " 562: 'employee',\n",
       " 563: 'N',\n",
       " 564: 'holes',\n",
       " 565: 'essential',\n",
       " 566: 'canal',\n",
       " 567: 'drop',\n",
       " 568: 'attend',\n",
       " 569: 'art',\n",
       " 570: 'accessible',\n",
       " 571: 'additional',\n",
       " 572: 'enrolled',\n",
       " 573: 'packets',\n",
       " 574: 'globally',\n",
       " 575: 'listening',\n",
       " 576: 'kept',\n",
       " 577: 'going',\n",
       " 578: 'conventions',\n",
       " 579: 'TDP',\n",
       " 580: 'member',\n",
       " 581: 'sciences',\n",
       " 582: 'Deccan',\n",
       " 583: 'Taxability',\n",
       " 584: 'robust',\n",
       " 585: 'it',\n",
       " 586: 'releasing',\n",
       " 587: 'Thaga',\n",
       " 588: 'Tamluk',\n",
       " 589: 'facts',\n",
       " 590: 'interests',\n",
       " 591: 'Istif',\n",
       " 592: 'Cross',\n",
       " 593: 'Similarly',\n",
       " 594: 'Kamal',\n",
       " 595: 'hogwash',\n",
       " 596: 'painting',\n",
       " 597: 'date',\n",
       " 598: 'Noida',\n",
       " 599: 'politicians',\n",
       " 600: 'Bahujan',\n",
       " 601: 'regulators',\n",
       " 602: 'Vijaypur',\n",
       " 603: 'Paise',\n",
       " 604: 'Naidu',\n",
       " 605: 'satellite',\n",
       " 606: 'Transactions',\n",
       " 607: 'Marakkanam',\n",
       " 608: 'efficiency',\n",
       " 609: 'Parleys',\n",
       " 610: 'constituted',\n",
       " 611: 'Swaminathan',\n",
       " 612: 'producers',\n",
       " 613: 'charges',\n",
       " 614: 'Responding',\n",
       " 615: 'denied',\n",
       " 616: 'everything',\n",
       " 617: 'result',\n",
       " 618: 'gradually',\n",
       " 619: 'reap',\n",
       " 620: 'increase',\n",
       " 621: 'laid',\n",
       " 622: 'Despite',\n",
       " 623: 'observe',\n",
       " 624: 'Defence',\n",
       " 625: 'BMW',\n",
       " 626: 'Provident',\n",
       " 627: 'slip',\n",
       " 628: 'Disbursal',\n",
       " 629: 'solar',\n",
       " 630: 'partnership',\n",
       " 631: 'quickly',\n",
       " 632: 'bench',\n",
       " 633: 'difference',\n",
       " 634: 'frequent',\n",
       " 635: 'method',\n",
       " 636: 'neither',\n",
       " 637: 'remain',\n",
       " 638: 'Rupee',\n",
       " 639: 'legislation',\n",
       " 640: 'Yuva',\n",
       " 641: 'soul',\n",
       " 642: 'Ankola',\n",
       " 643: 'deny',\n",
       " 644: 'resumed',\n",
       " 645: 'talk',\n",
       " 646: 'combined',\n",
       " 647: 'Tirupati',\n",
       " 648: 'Rain',\n",
       " 649: 'guess',\n",
       " 650: 'Puttaswamy',\n",
       " 651: 'Acknowledging',\n",
       " 652: 'Instead',\n",
       " 653: 'Of',\n",
       " 654: 'everywhere',\n",
       " 655: 'prosperity',\n",
       " 656: 'praised',\n",
       " 657: 'commodities',\n",
       " 658: 'island',\n",
       " 659: 'has',\n",
       " 660: 'pensions',\n",
       " 661: 'cola',\n",
       " 662: 'duped',\n",
       " 663: 'petition',\n",
       " 664: 'debate',\n",
       " 665: 'hectare',\n",
       " 666: 'STS',\n",
       " 667: 'solidarity',\n",
       " 668: 'Otherwise',\n",
       " 669: 'rainfall',\n",
       " 670: 'P',\n",
       " 671: 'outstanding',\n",
       " 672: 'cheaper',\n",
       " 673: 'gift',\n",
       " 674: 'Ramalingam',\n",
       " 675: 'H',\n",
       " 676: 'dwelling',\n",
       " 677: 'bytes',\n",
       " 678: 'Istwith',\n",
       " 679: 'instructed',\n",
       " 680: 'home',\n",
       " 681: 'Meethere',\n",
       " 682: 'ten',\n",
       " 683: 'consecutive',\n",
       " 684: 'religious',\n",
       " 685: 'true',\n",
       " 686: 'guest',\n",
       " 687: 'ways',\n",
       " 688: 'amongst',\n",
       " 689: 'at',\n",
       " 690: 'wise',\n",
       " 691: 'PC',\n",
       " 692: 'layer',\n",
       " 693: 'rain',\n",
       " 694: 'Reading',\n",
       " 695: 'between',\n",
       " 696: 'provisions',\n",
       " 697: 'eased',\n",
       " 698: 'crowd',\n",
       " 699: 'Targeting',\n",
       " 700: 'First',\n",
       " 701: 'headed',\n",
       " 702: 'schools',\n",
       " 703: 'calibration',\n",
       " 704: 'eventually',\n",
       " 705: 'breakthrough',\n",
       " 706: 'Emphasising',\n",
       " 707: 'Around',\n",
       " 708: 'faith',\n",
       " 709: 'heeded',\n",
       " 710: 'mammoth',\n",
       " 711: 'Taluk',\n",
       " 712: 'countrymen',\n",
       " 713: 'trickle',\n",
       " 714: 'indicating',\n",
       " 715: 'Istkeen',\n",
       " 716: 'ball',\n",
       " 717: 'Nanded',\n",
       " 718: 'biggest',\n",
       " 719: 'caught',\n",
       " 720: 'cards',\n",
       " 721: 'verdict',\n",
       " 722: 'Committees',\n",
       " 723: 'Unnao',\n",
       " 724: 'aspirations',\n",
       " 725: 'Tmc',\n",
       " 726: 'fields',\n",
       " 727: 'image',\n",
       " 728: 'Istunion',\n",
       " 729: 'BSE',\n",
       " 730: 'deserve',\n",
       " 731: 'Kobe',\n",
       " 732: 'tech',\n",
       " 733: 'filers',\n",
       " 734: 'dynasty',\n",
       " 735: 'chairperson',\n",
       " 736: 'Congresss',\n",
       " 737: 'fighting',\n",
       " 738: 'Yavatmal',\n",
       " 739: 'causes',\n",
       " 740: 'Aligarh',\n",
       " 741: 'drinks',\n",
       " 742: 'Drip',\n",
       " 743: 'poll',\n",
       " 744: 'Gulati',\n",
       " 745: 'PERSONs',\n",
       " 746: 'shock',\n",
       " 747: 'Prestige',\n",
       " 748: 'magazine',\n",
       " 749: 'where',\n",
       " 750: 'NSC',\n",
       " 751: 'gardens',\n",
       " 752: 'apace',\n",
       " 753: 'trap',\n",
       " 754: 'entering',\n",
       " 755: 'consequent',\n",
       " 756: 'affair',\n",
       " 757: 'borne',\n",
       " 758: 'presidential',\n",
       " 759: 'in',\n",
       " 760: 'extract',\n",
       " 761: 'square',\n",
       " 762: 'quality',\n",
       " 763: 'plan',\n",
       " 764: 'desk',\n",
       " 765: 'point',\n",
       " 766: 'counterfeit',\n",
       " 767: 'businessman',\n",
       " 768: 'reduce',\n",
       " 769: 'Msme',\n",
       " 770: 'burden',\n",
       " 771: 'illegally',\n",
       " 772: 'awaited',\n",
       " 773: 'Farmerfriendly',\n",
       " 774: 'Ashok',\n",
       " 775: 'dont',\n",
       " 776: 'plight',\n",
       " 777: 'instigating',\n",
       " 778: 'limit',\n",
       " 779: 'roadblocks',\n",
       " 780: 'rose',\n",
       " 781: 'Mantar',\n",
       " 782: 'banker',\n",
       " 783: 'adviser',\n",
       " 784: 'monthly',\n",
       " 785: 'slated',\n",
       " 786: 'insensitivity',\n",
       " 787: 'registry',\n",
       " 788: 'extradite',\n",
       " 789: 'consumer',\n",
       " 790: 'supporters',\n",
       " 791: 'conduct',\n",
       " 792: 'chance',\n",
       " 793: 'students',\n",
       " 794: 'Shivamogga',\n",
       " 795: 'Pelting',\n",
       " 796: 'interacting',\n",
       " 797: 'forced',\n",
       " 798: 'adopts',\n",
       " 799: 'Swinging',\n",
       " 800: 'vigilantism',\n",
       " 801: 'Arecanut',\n",
       " 802: 'offensive',\n",
       " 803: 'shelter',\n",
       " 804: 'TRAI',\n",
       " 805: 'entitlement',\n",
       " 806: 'centres',\n",
       " 807: 'nets',\n",
       " 808: 'loud',\n",
       " 809: 'inputs',\n",
       " 810: 'assailing',\n",
       " 811: 'contributing',\n",
       " 812: 'outlined',\n",
       " 813: 'hed',\n",
       " 814: 'Angadi',\n",
       " 815: 'eliminated',\n",
       " 816: 'positive',\n",
       " 817: 'procurement',\n",
       " 818: 'Almirahs',\n",
       " 819: 'promises',\n",
       " 820: 'school',\n",
       " 821: 'campaign',\n",
       " 822: 'tandem',\n",
       " 823: 'produce',\n",
       " 824: 'month',\n",
       " 825: 'stay',\n",
       " 826: 'proofing',\n",
       " 827: 'asserting',\n",
       " 828: 'multinational',\n",
       " 829: 'used',\n",
       " 830: 'CSC',\n",
       " 831: 'CNG',\n",
       " 832: 'Sthal',\n",
       " 833: 'following',\n",
       " 834: 'engagement',\n",
       " 835: 'Announcing',\n",
       " 836: 'daylong',\n",
       " 837: 'mills',\n",
       " 838: 'piece',\n",
       " 839: 'fear',\n",
       " 840: 'Deepakparekh',\n",
       " 841: 'Dharna',\n",
       " 842: 'list',\n",
       " 843: 'unturned',\n",
       " 844: 'Nafed',\n",
       " 845: 'Yes',\n",
       " 846: 'Sangli',\n",
       " 847: 'crore',\n",
       " 848: 'extremely',\n",
       " 849: 'pal',\n",
       " 850: 'while',\n",
       " 851: 'story',\n",
       " 852: 'summit',\n",
       " 853: 'enabling',\n",
       " 854: 'Unka',\n",
       " 855: 'unified',\n",
       " 856: 'contradict',\n",
       " 857: 'peppering',\n",
       " 858: 'mobilise',\n",
       " 859: 'monetary',\n",
       " 860: 'approve',\n",
       " 861: 'presently',\n",
       " 862: 'Froma',\n",
       " 863: 'liking',\n",
       " 864: 'penalties',\n",
       " 865: 'accounts',\n",
       " 866: 'The',\n",
       " 867: 'bypass',\n",
       " 868: 'Immolated',\n",
       " 869: 'Kpcc',\n",
       " 870: 'properly',\n",
       " 871: 'viability',\n",
       " 872: 'So',\n",
       " 873: 'restraint',\n",
       " 874: 'levels',\n",
       " 875: 'transport',\n",
       " 876: 'found',\n",
       " 877: 'Therefore',\n",
       " 878: 'proactive',\n",
       " 879: 'raising',\n",
       " 880: 'fail',\n",
       " 881: 'biodiversity',\n",
       " 882: 'phone',\n",
       " 883: 'data',\n",
       " 884: 'refinery',\n",
       " 885: 'transformative',\n",
       " 886: 'shaken',\n",
       " 887: 'jibe',\n",
       " 888: 'efficient',\n",
       " 889: 'generally',\n",
       " 890: 'Taluks',\n",
       " 891: 'compensate',\n",
       " 892: 'offences',\n",
       " 893: 'monsoon',\n",
       " 894: 'expanded',\n",
       " 895: 'Highlighting',\n",
       " 896: 'slyly',\n",
       " 897: 'announcement',\n",
       " 898: 'severe',\n",
       " 899: 'request',\n",
       " 900: 'Industrys',\n",
       " 901: 'notification',\n",
       " 902: 'unleashed',\n",
       " 903: 'Profiteering',\n",
       " 904: 'discontent',\n",
       " 905: 'requested',\n",
       " 906: 'dispelling',\n",
       " 907: 'Mozambique',\n",
       " 908: 'testimonials',\n",
       " 909: 'saluting',\n",
       " 910: 'confronting',\n",
       " 911: 'projected',\n",
       " 912: 'deter',\n",
       " 913: 'neighbouring',\n",
       " 914: 'Bill',\n",
       " 915: 'wear',\n",
       " 916: 'offering',\n",
       " 917: 'becomes',\n",
       " 918: 'Badungar',\n",
       " 919: 'pinned',\n",
       " 920: 'breach',\n",
       " 921: 'DEA',\n",
       " 922: 'running',\n",
       " 923: 'experiences',\n",
       " 924: 'including',\n",
       " 925: 'Amethi',\n",
       " 926: 'privilege',\n",
       " 927: 'iCar',\n",
       " 928: 'lauded',\n",
       " 929: 'fraud',\n",
       " 930: 'Jamuna',\n",
       " 931: 'investigate',\n",
       " 932: 'Kumaraswamys',\n",
       " 933: 'corrupt',\n",
       " 934: 'injuries',\n",
       " 935: 'restructured',\n",
       " 936: 'resource',\n",
       " 937: 'managed',\n",
       " 938: 'million',\n",
       " 939: 'Yadav',\n",
       " 940: 'Ltd',\n",
       " 941: 'socially',\n",
       " 942: 'digitisation',\n",
       " 943: 'womens',\n",
       " 944: 'Bharatmala',\n",
       " 945: 'gateway',\n",
       " 946: 'oriented',\n",
       " 947: 'tolerance',\n",
       " 948: 'consent',\n",
       " 949: 'Platform',\n",
       " 950: 'Ramgarh',\n",
       " 951: 'Aidguwahati',\n",
       " 952: 'recalling',\n",
       " 953: 'devastation',\n",
       " 954: 'acre',\n",
       " 955: 'experiments',\n",
       " 956: 'impetus',\n",
       " 957: 'animals',\n",
       " 958: 'Jawans',\n",
       " 959: 'prosperous',\n",
       " 960: 'neglecting',\n",
       " 961: 'Hurriedly',\n",
       " 962: 'Perhaps',\n",
       " 963: 'bail',\n",
       " 964: 'River',\n",
       " 965: 'worsening',\n",
       " 966: 'headwinds',\n",
       " 967: 'Prof',\n",
       " 968: 'burdened',\n",
       " 969: 'mining',\n",
       " 970: 'condolences',\n",
       " 971: 'eaten',\n",
       " 972: 'benefited',\n",
       " 973: 'gold',\n",
       " 974: 'Economic',\n",
       " 975: 'aspiring',\n",
       " 976: 'deprivation',\n",
       " 977: 'Dalits',\n",
       " 978: 'entertain',\n",
       " 979: 'Sub',\n",
       " 980: 'relent',\n",
       " 981: 'inadequate',\n",
       " 982: 'fertility',\n",
       " 983: 'Gansu',\n",
       " 984: 'attaining',\n",
       " 985: 'empowering',\n",
       " 986: 'litres',\n",
       " 987: 'exactly',\n",
       " 988: 'benefit',\n",
       " 989: 'Inclusionmumbai',\n",
       " 990: 'key',\n",
       " 991: 'reservations',\n",
       " 992: 'reaction',\n",
       " 993: 'logging',\n",
       " 994: 'Mr',\n",
       " 995: 'forcing',\n",
       " 996: 'format',\n",
       " 997: 'enigma',\n",
       " 998: 'enact',\n",
       " 999: 'Karzmaafi',\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fine tuned . .\n",
      "Loading economic-word2vec-ner\n"
     ]
    }
   ],
   "source": [
    "if not w2vec:\n",
    "    print(\"Using fine tuned . .\")\n",
    "    if economic:\n",
    "        if ner:\n",
    "            print(\"Loading economic-word2vec-ner\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/economic-word2vec-ner')\n",
    "        elif blackout:\n",
    "            print(\"Loading economic-word2vec-blackout\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/economic-word2vec-blackout')\n",
    "        else:\n",
    "            print(\"Loading economic-word2vec\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/economic-word2vec')\n",
    "    else:\n",
    "        if ner:\n",
    "            print(\"Loading tech-word2vec-ner\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/tech-word2vec-ner')\n",
    "        elif blackout:\n",
    "            print(\"Loading tech-word2vec-blackout\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/tech-word2vec-blackout')\n",
    "        else:\n",
    "            print(\"Loading tech-word2vec\")\n",
    "            unbiased_in_domain_model = KeyedVectors.load('Users/navreetkaur/MTP/finetune-word2vec/w2v-models/tech-word2vec')\n",
    "    \n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/navreetkaur/MTP/finetune-word2vec/w2v-models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[source, PTI, photo, parliamentary, affairs, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Prime, Minister, PERSON, had, recently, said,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We, have, to, understand, the, problems, farm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Speaking, to, select, media, on, the, complet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In, an, interview, for, a, TV, news, channel,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  target\n",
       "0  [source, PTI, photo, parliamentary, affairs, m...       0\n",
       "1  [Prime, Minister, PERSON, had, recently, said,...       0\n",
       "2  [We, have, to, understand, the, problems, farm...       0\n",
       "3  [Speaking, to, select, media, on, the, complet...       1\n",
       "4  [In, an, interview, for, a, TV, news, channel,...       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = np.zeros((len(idx2word), word2vec_model.vector_size))\n",
    "\n",
    "for idx, word in idx2word.items():\n",
    "    if not w2vec:\n",
    "        try: \n",
    "            embed[idx] = unbiased_in_domain_model[word]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                embed[idx] = word2vec_model[word]\n",
    "            except:\n",
    "                embed[idx] = np.random.normal(size=(word2vec_model.vector_size, ))\n",
    "    else:\n",
    "        try:\n",
    "            embed[idx] = word2vec_model[word]\n",
    "        except:\n",
    "            embed[idx] = np.random.normal(size=(word2vec_model.vector_size, ))\n",
    "        \n",
    "embed = torch.from_numpy(embed)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[source, PTI, photo, parliamentary, affairs, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Prime, Minister, PERSON, had, recently, said,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We, have, to, understand, the, problems, farm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Speaking, to, select, media, on, the, complet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In, an, interview, for, a, TV, news, channel,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  target\n",
       "0  [source, PTI, photo, parliamentary, affairs, m...       0\n",
       "1  [Prime, Minister, PERSON, had, recently, said,...       0\n",
       "2  [We, have, to, understand, the, problems, farm...       0\n",
       "3  [Speaking, to, select, media, on, the, complet...       1\n",
       "4  [In, an, interview, for, a, TV, news, channel,...       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    2495\n",
       "1    2495\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7683, 300]), 7683)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape, len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(text):\n",
    "#     print(text)\n",
    "    output = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,depparse,parse',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    output = literal_eval(output)\n",
    "    try:\n",
    "        tree = str(output['sentences'][0]['parse'])\n",
    "    except:\n",
    "        print(output,text)\n",
    "        return\n",
    "    # print (tree)\n",
    "    parse_string = ' '.join(str(tree).split())\n",
    "    # print(parse_string)\n",
    "    # print (\"\\n\\n\")\n",
    "    tree = nltk.tree.Tree.fromstring(parse_string)\n",
    "    tree.chomsky_normal_form()\n",
    "    tree.collapse_unary(collapseRoot=True,collapsePOS=True)\n",
    "    nt = convertNLTK_tree(tree)\n",
    "    return nt\n",
    "\n",
    "def printLabelTree(tree):\n",
    "    def inorder(node,nnode):\n",
    "        if node.isLeaf:\n",
    "            newnode = pptree.Node('H',nnode)\n",
    "            wnode = pptree.Node(node.word,newnode)\n",
    "        elif nnode is not None:\n",
    "            newnode = pptree.Node('H',nnode)\n",
    "            inorder(node.left,newnode)\n",
    "            inorder(node.right,newnode)\n",
    "        elif node.isRoot():\n",
    "            newnode = pptree.Node('H')\n",
    "            inorder(node.left,newnode)\n",
    "            inorder(node.right,newnode)\n",
    "            return newnode\n",
    "        return None\n",
    "    pptree.print_tree(inorder(tree.root,None))\n",
    "\n",
    "def create_trees_using_df(df):\n",
    "    tree = []\n",
    "    for tokens in list(df['tokens']):\n",
    "        if len(tokens)==0:\n",
    "            continue\n",
    "        line = ' '.join(tokens)\n",
    "        line += '\\n'\n",
    "        tree.append(make_tree(line))\n",
    "    return tree\n",
    "\n",
    "def printlabel(root,l):\n",
    "    if root:\n",
    "        l.append(root.label)\n",
    "#         print(root.label)\n",
    "        if root.left:\n",
    "            l+=printlabel(root.left,[])\n",
    "#             print(printlabel(root.left))\n",
    "        if root.right:\n",
    "            l+=printlabel(root.right,[])\n",
    "#             print(printlabel(root.right))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = StanfordCoreNLP('http://localhost', port=9000,timeout=90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral = create_trees_using_df(df_train[df_train.target == 0])\n",
    "# anti = create_trees_using_df(df_train[df_train.target == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_neutral = create_trees_using_df(df_train[df_train.target == 1])\n",
    "# pro = create_trees_using_df(df_train[df_train.target == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral_test = create_trees_using_df(df_test[df_test.target == 0])\n",
    "# non_neutral_test = create_trees_using_df(df_test[df_test.target == 1])\n",
    "# anti_test = create_trees_using_df(df_test[df_test.target == 0])\n",
    "# pro_test = create_trees_using_df(df_test[df_test.target == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout = open(file_trees,'wb')\n",
    "# pickle.dump([pro, anti],fout)\n",
    "# fout.close()\n",
    "# fout = open(file_trees+\"_test\",'wb')\n",
    "# pickle.dump([pro_test, anti_test],fout)\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pro,anti] = pickle.load(open(os.path.join('./trees',file_trees),'rb'))\n",
    "[pro_test,anti_test] = pickle.load(open(os.path.join('./trees',file_trees+\"_test\"),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout = open(file_trees,'wb')\n",
    "# pickle.dump([neutral, non_neutral],fout)\n",
    "# fout.close()\n",
    "# fout = open(file_trees+'_test','wb')\n",
    "# pickle.dump([neutral_test, non_neutral_test],fout)\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA=False\n",
    "def Var(v):\n",
    "    if CUDA: return Variable(v.cuda())\n",
    "    else: return Variable(v)\n",
    "    \n",
    "trees = []\n",
    "raw_words = []\n",
    "vocab = []\n",
    "\n",
    "# print(\"Loading trees...\")\n",
    "# [neutral, non_neutral] = pickle.load(open(file_trees,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for neutral_tree in neutral:\n",
    "#     neutral_tree.root.set_label('neutral')\n",
    "# for non_neutral_tree in non_neutral:\n",
    "#     non_neutral_tree.root.set_label('non_neutral')\n",
    "    \n",
    "for pro_tree in pro:\n",
    "    pro_tree.root.set_label('pro')\n",
    "for anti_tree in anti:\n",
    "    anti_tree.root.set_label('anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for neutral_tree in neutral_test:\n",
    "#     neutral_tree.root.set_label('neutral')\n",
    "# for non_neutral_tree in non_neutral_test:\n",
    "#     non_neutral_tree.root.set_label('non_neutral')\n",
    "    \n",
    "for pro_tree in pro_test:\n",
    "    pro_tree.root.set_label('pro')\n",
    "for anti_tree in anti_test:\n",
    "    anti_tree.root.set_label('anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(neutral,non_neutral):\n",
    "    trees = []\n",
    "    trees.extend(neutral)\n",
    "    trees.extend(non_neutral)\n",
    "    random.shuffle(trees)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytree import *\n",
    "from treeUtil import *\n",
    "# from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "val = {'pro':0,'anti':1,'default':-1}\n",
    "\n",
    "# pro:1, anti:0, neutral:2\n",
    "val_all = {'pro':1,'anti':0,'default':-1,'neutral':2}\n",
    "# neutral:0, non-neutral:1\n",
    "val_neutral = {'neutral':0, 'non_neutral':1, 'default':-1}\n",
    "\n",
    "\n",
    "def convert(T):\n",
    "    label = val[T.label] if (hasattr(T,'label')) else None\n",
    "    print(label)\n",
    "    newTree = convert_primary_new(T,label)\n",
    "    annotate_all(newTree)\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convert_neutral(T):\n",
    "    label = val_neutral[T.label] if (hasattr(T,'label')) else None\n",
    "    print(label)\n",
    "    newTree = convert_primary_new(T,label)\n",
    "    annotate_all(newTree)\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convert_all(T):\n",
    "    label = val_all[T.label] if (hasattr(T,'label')) else None\n",
    "    print(label)\n",
    "    newTree = convert_primary_new(T,label)\n",
    "    annotate_all(newTree)\n",
    "\n",
    "    return newTree\n",
    "\n",
    "\n",
    "def convert_primary(T):\n",
    "    if (hasattr(T,'label')):\n",
    "        print(T.label) \n",
    "    label = val[T.label] if (hasattr(T,'label')) else None\n",
    "    # label = val[T.label] if (hasattr(T,'label') ) else None # changed for ignoring neutral\n",
    "\n",
    "    if isinstance(T,leafObj):\n",
    "        newTree = Node(label,T.word,T.pos)\n",
    "        newTree.isLeaf = True\n",
    "        return newTree\n",
    "    else:\n",
    "        newTree = Node(label)\n",
    "    \n",
    "    leftChild = convert_primary(T.c1)\n",
    "    rightChild = convert_primary(T.c2)\n",
    "    leftChild.parent = newTree\n",
    "    rightChild.parent = newTree\n",
    "\n",
    "    newTree.left = leftChild\n",
    "    newTree.right = rightChild\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convert_primary_new(T,label):\n",
    "    # from IPython import embed; embed()\n",
    "    if T is None:\n",
    "        return None\n",
    "    # label = val[T.label] if (hasattr(T,'label') ) else None # changed for ignoring neutral\n",
    "    T.set_label(label)\n",
    "    # if (T.isLeaf) : print (T.word)\n",
    "\n",
    "    T.left = convert_primary_new(T.left,label)\n",
    "    T.right = convert_primary_new(T.right,label)\n",
    "\n",
    "    return T\n",
    "\n",
    "    # if T.isLeaf:\n",
    "    #     newTree = Node(label,T.word,T.pos)\n",
    "    #     newTree.isLeaf = True\n",
    "    #     return newTree\n",
    "    # else:\n",
    "    #     newTree = Node(label)\n",
    "    \n",
    "    # leftChild = convert_primary_new(T.left)\n",
    "    # rightChild = convert_primary_new(T.right)\n",
    "    # leftChild.parent = newTree\n",
    "    # rightChild.parent = newTree\n",
    "\n",
    "    # newTree.left = leftChild\n",
    "    # newTree.right = rightChild\n",
    "\n",
    "    # return newTree\n",
    "\n",
    "def convertNLTK_tree_primary(tree):\n",
    "    if tree.height()==2:\n",
    "        newTree = Node('default',tree[0],None)\n",
    "        newTree.isLeaf = True\n",
    "        return newTree\n",
    "    newTree = Node('default')\n",
    "    leftChild = convertNLTK_tree_primary(tree[0])\n",
    "    rightChild = convertNLTK_tree_primary(tree[1])\n",
    "    \n",
    "    leftChild.parent = newTree\n",
    "    rightChild.parent = newTree\n",
    "\n",
    "    newTree.left = leftChild\n",
    "    newTree.right = rightChild\n",
    "\n",
    "    return newTree\n",
    "\n",
    "def convertNLTK_tree(tree):\n",
    "    return Tree(convertNLTK_tree_primary(tree))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def annotate_all(T):\n",
    "    if T == None: return\n",
    "    if T.label != None : \n",
    "        T.annotated = True\n",
    "    else:\n",
    "        T.annotated = False\n",
    "        T.set_label(T.parent.label)\n",
    "    annotate_all(T.left)\n",
    "    annotate_all(T.right)\n",
    "\n",
    "def buildBalTree(sent):\n",
    "    words = sent.split(' ')\n",
    "\n",
    "    nodes = words\n",
    "\n",
    "    while len(nodes)>1:\n",
    "        temp = []\n",
    "        for i in range(0,len(nodes),2):\n",
    "            lChild = Node(None,nodes[i],None) if isinstance(nodes[i],str) else nodes[i]\n",
    "            if i+1<len(nodes):\n",
    "                rChild = Node(None,nodes[i+1],None) if isinstance(nodes[i+1],str) else nodes[i+1]\n",
    "            else:\n",
    "                rChild = None\n",
    "            if isinstance(nodes[i],str):\n",
    "                lChild.isLeaf = True\n",
    "                if rChild is not None:\n",
    "                    rChild.isLeaf = True\n",
    "            newNode = Node(None)\n",
    "            lChild.parent = newNode\n",
    "            newNode.left = lChild\n",
    "            newNode.right = rChild\n",
    "            if rChild is not None:\n",
    "                rChild.parent = newNode\n",
    "            temp.append(newNode)\n",
    "        nodes=temp\n",
    "    return Tree(nodes[0])\n",
    "\n",
    "def readFile2Trees(filename):\n",
    "    trees = []\n",
    "    with open(filename,'r') as file:\n",
    "        for line in file:\n",
    "            if line=='\\n':\n",
    "                continue\n",
    "            else:\n",
    "                [labelname,sent] = line.split(': ',1)\n",
    "                tree = buildBalTree(sent)\n",
    "                tree.root.set_label(val[labelname])\n",
    "                if val[labelname]!=2:\n",
    "                    trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# trees = combine(neutral, non_neutral)\n",
    "trees = combine(pro,anti)\n",
    "data = []\n",
    "for i in range(len(trees)):\n",
    "    data.append(Tree(convert(trees[i].root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# trees_test = combine(neutral_test, non_neutral_test)\n",
    "trees_test = combine(pro_test,anti_test)\n",
    "data_test = []\n",
    "for i in range(len(trees_test)):\n",
    "    data_test.append(Tree(convert(trees_test[i].root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA: model = RecursiveNN(embed,word2idx).cuda()\n",
    "else: model = RecursiveNN(embed,word2idx)\n",
    "max_epochs = 100\n",
    "widgets = [progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]\n",
    "l2_reg = {  'embedding.weight' : 1e-6,'W.weight' : 1e-4,'W.bias' : 1e-4,'projection.weight' : 1e-3,'projection.bias' : 1e-3}\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn,dev = data[:int((len(data)+1)*.85)],data[int(len(data)*.85+1):]\n",
    "# len(data), len(trn), len(dev)\n",
    "trn = data\n",
    "dev = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4990, 562)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Start logging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, dampening=0.0)\n",
    "# bestAll=bestRoot=0.0\n",
    "global count\n",
    "count=0\n",
    "BATCH_SIZE = 128\n",
    "# optimizer = torch.optim.LBFGS(model.parameters(), lr=0.5, max_iter=10, history_size = 10)\n",
    "bestAll=bestRoot=0.0\n",
    "bestF1_0=bestF1_1=best_trn_F1_0=best_trn_F1_1=0.0\n",
    "best_trn_All = best_trn_Root = 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic_w2v_0ProAnti_0General_1NER_0Blackout_1Balance_0Undersample_1Fixed'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0\n",
      "Loss =  tensor([29.0931])\n",
      "Loss =  tensor([30.3088])\n",
      "Loss =  tensor([30.9584])\n",
      "Loss =  tensor([31.9195])\n",
      "Loss =  tensor([31.0508])\n",
      "Loss =  tensor([31.1765])\n",
      "Loss =  tensor([32.4459])\n",
      "Loss =  tensor([30.5077])\n",
      "Loss =  tensor([31.6279])\n",
      "Loss =  tensor([30.7308])\n",
      "Loss =  tensor([29.6698])\n",
      "Loss =  tensor([31.3304])\n",
      "Loss =  tensor([32.7565])\n",
      "Loss =  tensor([32.1290])\n",
      "Loss =  tensor([31.2658])\n",
      "Loss =  tensor([31.1065])\n",
      "Loss =  tensor([30.5783])\n",
      "Loss =  tensor([32.4085])\n",
      "Loss =  tensor([31.6185])\n",
      "Loss =  tensor([29.7619])\n",
      "Loss =  tensor([31.9121])\n",
      "Loss =  tensor([32.7546])\n",
      "Loss =  tensor([30.4576])\n",
      "Loss =  tensor([32.4485])\n",
      "Loss =  tensor([31.7281])\n",
      "Loss =  tensor([31.6076])\n",
      "Loss =  tensor([30.4839])\n",
      "Loss =  tensor([31.1275])\n",
      "Loss =  tensor([31.9844])\n",
      "Loss =  tensor([31.1605])\n",
      "Loss =  tensor([32.1875])\n",
      "Loss =  tensor([30.6662])\n",
      "Loss =  tensor([30.1169])\n",
      "Loss =  tensor([31.0200])\n",
      "Loss =  tensor([30.3119])\n",
      "Loss =  tensor([30.8230])\n",
      "Loss =  tensor([32.8568])\n",
      "Loss =  tensor([30.9063])\n",
      "Loss =  tensor([32.7045])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:14\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.79(best:0.79)\n",
      "Validation Root accuracy:0.78(best:0.78)\n",
      "F1:[0.5, 0.88](best:0.5 , 0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.51(best:0.51)\n",
      "Training Root// accuracy:0.5(best:0.5)\n",
      "Training F1:[0.5, 0.67](best:0.5 , 0.67)\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Loss =  tensor([30.8218])\n",
      "Loss =  tensor([32.9269])\n",
      "Loss =  tensor([30.6159])\n",
      "Loss =  tensor([31.3655])\n",
      "Loss =  tensor([33.0867])\n",
      "Loss =  tensor([31.7942])\n",
      "Loss =  tensor([30.6844])\n",
      "Loss =  tensor([29.3063])\n",
      "Loss =  tensor([30.7847])\n",
      "Loss =  tensor([31.2766])\n",
      "Loss =  tensor([31.4609])\n",
      "Loss =  tensor([31.3415])\n",
      "Loss =  tensor([29.8070])\n",
      "Loss =  tensor([30.4422])\n",
      "Loss =  tensor([29.7151])\n",
      "Loss =  tensor([29.8555])\n",
      "Loss =  tensor([31.8121])\n",
      "Loss =  tensor([31.8358])\n",
      "Loss =  tensor([30.6305])\n",
      "Loss =  tensor([31.2411])\n",
      "Loss =  tensor([31.3408])\n",
      "Loss =  tensor([30.9250])\n",
      "Loss =  tensor([30.1999])\n",
      "Loss =  tensor([31.3868])\n",
      "Loss =  tensor([30.7794])\n",
      "Loss =  tensor([32.2304])\n",
      "Loss =  tensor([30.7337])\n",
      "Loss =  tensor([32.6010])\n",
      "Loss =  tensor([31.7989])\n",
      "Loss =  tensor([31.5146])\n",
      "Loss =  tensor([32.9680])\n",
      "Loss =  tensor([31.2069])\n",
      "Loss =  tensor([30.6702])\n",
      "Loss =  tensor([29.4703])\n",
      "Loss =  tensor([30.9245])\n",
      "Loss =  tensor([30.7789])\n",
      "Loss =  tensor([29.4680])\n",
      "Loss =  tensor([30.1738])\n",
      "Loss =  tensor([29.5771])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:18\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.72(best:0.79)\n",
      "Validation Root accuracy:0.78(best:0.78)\n",
      "F1:[0.63, 0.88](best:0.63 , 0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.52(best:0.52)\n",
      "Training Root// accuracy:0.51(best:0.51)\n",
      "Training F1:[0.77, 0.67](best:0.77 , 0.67)\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Loss =  tensor([31.2084])\n",
      "Loss =  tensor([30.9345])\n",
      "Loss =  tensor([29.5911])\n",
      "Loss =  tensor([29.8822])\n",
      "Loss =  tensor([32.5195])\n",
      "Loss =  tensor([33.3571])\n",
      "Loss =  tensor([30.8409])\n",
      "Loss =  tensor([29.7201])\n",
      "Loss =  tensor([33.0634])\n",
      "Loss =  tensor([32.2850])\n",
      "Loss =  tensor([30.0041])\n",
      "Loss =  tensor([32.5070])\n",
      "Loss =  tensor([31.9204])\n",
      "Loss =  tensor([31.6172])\n",
      "Loss =  tensor([30.5986])\n",
      "Loss =  tensor([28.8608])\n",
      "Loss =  tensor([29.5069])\n",
      "Loss =  tensor([30.7513])\n",
      "Loss =  tensor([29.5065])\n",
      "Loss =  tensor([30.1839])\n",
      "Loss =  tensor([32.5465])\n",
      "Loss =  tensor([29.3765])\n",
      "Loss =  tensor([30.9612])\n",
      "Loss =  tensor([32.7683])\n",
      "Loss =  tensor([32.4196])\n",
      "Loss =  tensor([31.4063])\n",
      "Loss =  tensor([28.2224])\n",
      "Loss =  tensor([30.4658])\n",
      "Loss =  tensor([29.1703])\n",
      "Loss =  tensor([30.0506])\n",
      "Loss =  tensor([31.6081])\n",
      "Loss =  tensor([32.1730])\n",
      "Loss =  tensor([32.3721])\n",
      "Loss =  tensor([31.5788])\n",
      "Loss =  tensor([30.1217])\n",
      "Loss =  tensor([32.1136])\n",
      "Loss =  tensor([30.5186])\n",
      "Loss =  tensor([32.8575])\n",
      "Loss =  tensor([30.0375])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:13\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.74(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.35, 0.88](best:0.63 , 0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.53(best:0.53)\n",
      "Training Root// accuracy:0.55(best:0.55)\n",
      "Training F1:[0.78, 0.69](best:0.78 , 0.69)\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Loss =  tensor([31.6491])\n",
      "Loss =  tensor([33.4938])\n",
      "Loss =  tensor([30.8799])\n",
      "Loss =  tensor([29.1449])\n",
      "Loss =  tensor([31.7359])\n",
      "Loss =  tensor([30.7277])\n",
      "Loss =  tensor([33.5414])\n",
      "Loss =  tensor([32.4369])\n",
      "Loss =  tensor([32.1058])\n",
      "Loss =  tensor([31.7100])\n",
      "Loss =  tensor([30.6842])\n",
      "Loss =  tensor([31.8613])\n",
      "Loss =  tensor([30.4233])\n",
      "Loss =  tensor([33.0476])\n",
      "Loss =  tensor([31.8368])\n",
      "Loss =  tensor([29.9808])\n",
      "Loss =  tensor([30.0855])\n",
      "Loss =  tensor([32.4038])\n",
      "Loss =  tensor([31.0847])\n",
      "Loss =  tensor([30.6317])\n",
      "Loss =  tensor([30.9785])\n",
      "Loss =  tensor([33.1051])\n",
      "Loss =  tensor([33.0998])\n",
      "Loss =  tensor([31.2475])\n",
      "Loss =  tensor([31.5147])\n",
      "Loss =  tensor([29.3114])\n",
      "Loss =  tensor([33.6022])\n",
      "Loss =  tensor([31.5619])\n",
      "Loss =  tensor([31.8911])\n",
      "Loss =  tensor([30.6995])\n",
      "Loss =  tensor([31.3032])\n",
      "Loss =  tensor([31.6628])\n",
      "Loss =  tensor([29.0921])\n",
      "Loss =  tensor([31.6011])\n",
      "Loss =  tensor([29.6849])\n",
      "Loss =  tensor([30.2026])\n",
      "Loss =  tensor([30.4652])\n",
      "Loss =  tensor([30.6224])\n",
      "Loss =  tensor([31.6418])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:12\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.41, 0.88](best:0.63 , 0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.53(best:0.53)\n",
      "Training Root// accuracy:0.55(best:0.55)\n",
      "Training F1:[0.79, 0.69](best:0.79 , 0.69)\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Loss =  tensor([30.5742])\n",
      "Loss =  tensor([32.3676])\n",
      "Loss =  tensor([30.8045])\n",
      "Loss =  tensor([30.8640])\n",
      "Loss =  tensor([28.8435])\n",
      "Loss =  tensor([30.0512])\n",
      "Loss =  tensor([29.3442])\n",
      "Loss =  tensor([33.0737])\n",
      "Loss =  tensor([33.1131])\n",
      "Loss =  tensor([29.7806])\n",
      "Loss =  tensor([30.6918])\n",
      "Loss =  tensor([31.1997])\n",
      "Loss =  tensor([32.3100])\n",
      "Loss =  tensor([30.7207])\n",
      "Loss =  tensor([31.4935])\n",
      "Loss =  tensor([29.7042])\n",
      "Loss =  tensor([32.7317])\n",
      "Loss =  tensor([31.9609])\n",
      "Loss =  tensor([32.6922])\n",
      "Loss =  tensor([31.4076])\n",
      "Loss =  tensor([30.3830])\n",
      "Loss =  tensor([30.0885])\n",
      "Loss =  tensor([31.3385])\n",
      "Loss =  tensor([31.1658])\n",
      "Loss =  tensor([30.0822])\n",
      "Loss =  tensor([30.4902])\n",
      "Loss =  tensor([30.3360])\n",
      "Loss =  tensor([30.8704])\n",
      "Loss =  tensor([30.9825])\n",
      "Loss =  tensor([31.3356])\n",
      "Loss =  tensor([30.7614])\n",
      "Loss =  tensor([29.5511])\n",
      "Loss =  tensor([30.7679])\n",
      "Loss =  tensor([31.3351])\n",
      "Loss =  tensor([30.6332])\n",
      "Loss =  tensor([30.2092])\n",
      "Loss =  tensor([30.3525])\n",
      "Loss =  tensor([30.9515])\n",
      "Loss =  tensor([29.3450])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:14\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.71(best:0.79)\n",
      "Validation Root accuracy:0.68(best:0.78)\n",
      "F1:[0.33, 0.88](best:0.63 , 0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.54(best:0.54)\n",
      "Training Root// accuracy:0.57(best:0.57)\n",
      "Training F1:[0.81, 0.71](best:0.81 , 0.71)\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Loss =  tensor([31.7740])\n",
      "Loss =  tensor([30.2915])\n",
      "Loss =  tensor([32.0258])\n",
      "Loss =  tensor([31.2939])\n",
      "Loss =  tensor([30.9052])\n",
      "Loss =  tensor([31.4230])\n",
      "Loss =  tensor([30.1294])\n",
      "Loss =  tensor([30.6849])\n",
      "Loss =  tensor([29.2265])\n",
      "Loss =  tensor([32.2540])\n",
      "Loss =  tensor([31.1062])\n",
      "Loss =  tensor([31.9590])\n",
      "Loss =  tensor([31.3140])\n",
      "Loss =  tensor([31.2838])\n",
      "Loss =  tensor([30.4930])\n",
      "Loss =  tensor([31.1150])\n",
      "Loss =  tensor([29.9989])\n",
      "Loss =  tensor([31.1202])\n",
      "Loss =  tensor([30.9754])\n",
      "Loss =  tensor([30.2622])\n",
      "Loss =  tensor([30.3024])\n",
      "Loss =  tensor([30.9332])\n",
      "Loss =  tensor([30.5261])\n",
      "Loss =  tensor([28.4963])\n",
      "Loss =  tensor([30.8855])\n",
      "Loss =  tensor([31.1656])\n",
      "Loss =  tensor([30.3516])\n",
      "Loss =  tensor([31.4266])\n",
      "Loss =  tensor([28.7376])\n",
      "Loss =  tensor([30.4695])\n",
      "Loss =  tensor([32.7904])\n",
      "Loss =  tensor([31.9212])\n",
      "Loss =  tensor([29.8689])\n",
      "Loss =  tensor([29.7433])\n",
      "Loss =  tensor([30.9456])\n",
      "Loss =  tensor([28.3747])\n",
      "Loss =  tensor([30.7243])\n",
      "Loss =  tensor([30.0771])\n",
      "Loss =  tensor([32.3705])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:13\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.69(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.49, 0.89](best:0.63 , 0.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.57(best:0.57)\n",
      "Training Root// accuracy:0.64(best:0.64)\n",
      "Training F1:[0.89, 0.74](best:0.89 , 0.74)\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Loss =  tensor([30.4666])\n",
      "Loss =  tensor([30.9623])\n",
      "Loss =  tensor([32.4259])\n",
      "Loss =  tensor([31.4138])\n",
      "Loss =  tensor([29.3342])\n",
      "Loss =  tensor([29.8182])\n",
      "Loss =  tensor([29.3398])\n",
      "Loss =  tensor([30.0673])\n",
      "Loss =  tensor([31.3324])\n",
      "Loss =  tensor([29.9918])\n",
      "Loss =  tensor([29.6121])\n",
      "Loss =  tensor([31.0171])\n",
      "Loss =  tensor([32.2696])\n",
      "Loss =  tensor([29.6225])\n",
      "Loss =  tensor([32.0043])\n",
      "Loss =  tensor([29.5079])\n",
      "Loss =  tensor([29.7952])\n",
      "Loss =  tensor([32.8960])\n",
      "Loss =  tensor([30.1918])\n",
      "Loss =  tensor([30.2512])\n",
      "Loss =  tensor([30.8469])\n",
      "Loss =  tensor([29.8689])\n",
      "Loss =  tensor([30.2479])\n",
      "Loss =  tensor([32.8113])\n",
      "Loss =  tensor([31.1589])\n",
      "Loss =  tensor([30.3501])\n",
      "Loss =  tensor([30.7969])\n",
      "Loss =  tensor([31.1093])\n",
      "Loss =  tensor([32.7893])\n",
      "Loss =  tensor([30.1141])\n",
      "Loss =  tensor([31.1937])\n",
      "Loss =  tensor([31.1627])\n",
      "Loss =  tensor([31.4414])\n",
      "Loss =  tensor([29.3852])\n",
      "Loss =  tensor([28.5714])\n",
      "Loss =  tensor([31.5213])\n",
      "Loss =  tensor([31.8962])\n",
      "Loss =  tensor([30.2901])\n",
      "Loss =  tensor([33.1086])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.44(best:0.78)\n",
      "F1:[0.39, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.56(best:0.57)\n",
      "Training Root// accuracy:0.61(best:0.64)\n",
      "Training F1:[0.73, 0.82](best:0.89 , 0.82)\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Loss =  tensor([29.0736])\n",
      "Loss =  tensor([29.8248])\n",
      "Loss =  tensor([31.3823])\n",
      "Loss =  tensor([29.6099])\n",
      "Loss =  tensor([29.2345])\n",
      "Loss =  tensor([33.1343])\n",
      "Loss =  tensor([31.9210])\n",
      "Loss =  tensor([30.9784])\n",
      "Loss =  tensor([28.6061])\n",
      "Loss =  tensor([30.8828])\n",
      "Loss =  tensor([31.5785])\n",
      "Loss =  tensor([30.4133])\n",
      "Loss =  tensor([31.2162])\n",
      "Loss =  tensor([30.5905])\n",
      "Loss =  tensor([29.5816])\n",
      "Loss =  tensor([31.7920])\n",
      "Loss =  tensor([29.9900])\n",
      "Loss =  tensor([30.1575])\n",
      "Loss =  tensor([29.5116])\n",
      "Loss =  tensor([29.6793])\n",
      "Loss =  tensor([29.3758])\n",
      "Loss =  tensor([30.8228])\n",
      "Loss =  tensor([31.1344])\n",
      "Loss =  tensor([30.9636])\n",
      "Loss =  tensor([30.1548])\n",
      "Loss =  tensor([29.4681])\n",
      "Loss =  tensor([30.3171])\n",
      "Loss =  tensor([29.8668])\n",
      "Loss =  tensor([28.9975])\n",
      "Loss =  tensor([30.5644])\n",
      "Loss =  tensor([31.2397])\n",
      "Loss =  tensor([30.7728])\n",
      "Loss =  tensor([31.1774])\n",
      "Loss =  tensor([30.3081])\n",
      "Loss =  tensor([29.8548])\n",
      "Loss =  tensor([29.5958])\n",
      "Loss =  tensor([28.1706])\n",
      "Loss =  tensor([32.4052])\n",
      "Loss =  tensor([28.0552])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.69(best:0.79)\n",
      "Validation Root accuracy:0.63(best:0.78)\n",
      "F1:[0.44, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.59(best:0.59)\n",
      "Training Root// accuracy:0.76(best:0.76)\n",
      "Training F1:[0.87, 0.86](best:0.89 , 0.86)\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Loss =  tensor([29.9019])\n",
      "Loss =  tensor([29.2348])\n",
      "Loss =  tensor([29.4034])\n",
      "Loss =  tensor([30.1998])\n",
      "Loss =  tensor([29.7277])\n",
      "Loss =  tensor([30.4499])\n",
      "Loss =  tensor([28.1307])\n",
      "Loss =  tensor([30.2173])\n",
      "Loss =  tensor([27.3556])\n",
      "Loss =  tensor([29.7869])\n",
      "Loss =  tensor([29.2692])\n",
      "Loss =  tensor([31.8710])\n",
      "Loss =  tensor([31.7452])\n",
      "Loss =  tensor([30.0382])\n",
      "Loss =  tensor([29.3416])\n",
      "Loss =  tensor([30.8882])\n",
      "Loss =  tensor([32.6100])\n",
      "Loss =  tensor([29.7327])\n",
      "Loss =  tensor([30.2362])\n",
      "Loss =  tensor([29.4206])\n",
      "Loss =  tensor([30.4960])\n",
      "Loss =  tensor([32.3433])\n",
      "Loss =  tensor([31.2335])\n",
      "Loss =  tensor([30.1580])\n",
      "Loss =  tensor([32.4193])\n",
      "Loss =  tensor([31.5457])\n",
      "Loss =  tensor([28.6713])\n",
      "Loss =  tensor([33.4371])\n",
      "Loss =  tensor([32.8563])\n",
      "Loss =  tensor([33.8192])\n",
      "Loss =  tensor([28.6456])\n",
      "Loss =  tensor([29.1778])\n",
      "Loss =  tensor([29.2057])\n",
      "Loss =  tensor([32.0192])\n",
      "Loss =  tensor([30.9565])\n",
      "Loss =  tensor([29.8300])\n",
      "Loss =  tensor([29.4135])\n",
      "Loss =  tensor([30.4851])\n",
      "Loss =  tensor([30.0738])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.59(best:0.78)\n",
      "F1:[0.41, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.6(best:0.6)\n",
      "Training Root// accuracy:0.76(best:0.76)\n",
      "Training F1:[0.85, 0.88](best:0.89 , 0.88)\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Loss =  tensor([28.4271])\n",
      "Loss =  tensor([29.1714])\n",
      "Loss =  tensor([29.2364])\n",
      "Loss =  tensor([29.3815])\n",
      "Loss =  tensor([29.9771])\n",
      "Loss =  tensor([29.4172])\n",
      "Loss =  tensor([30.5747])\n",
      "Loss =  tensor([29.9472])\n",
      "Loss =  tensor([30.3204])\n",
      "Loss =  tensor([29.0036])\n",
      "Loss =  tensor([30.9951])\n",
      "Loss =  tensor([29.8951])\n",
      "Loss =  tensor([28.9236])\n",
      "Loss =  tensor([29.5602])\n",
      "Loss =  tensor([29.7327])\n",
      "Loss =  tensor([29.3372])\n",
      "Loss =  tensor([28.5898])\n",
      "Loss =  tensor([31.0126])\n",
      "Loss =  tensor([27.7091])\n",
      "Loss =  tensor([29.7186])\n",
      "Loss =  tensor([29.7350])\n",
      "Loss =  tensor([31.5943])\n",
      "Loss =  tensor([29.6727])\n",
      "Loss =  tensor([30.3036])\n",
      "Loss =  tensor([29.2008])\n",
      "Loss =  tensor([30.5127])\n",
      "Loss =  tensor([31.7600])\n",
      "Loss =  tensor([31.2963])\n",
      "Loss =  tensor([28.5309])\n",
      "Loss =  tensor([28.1386])\n",
      "Loss =  tensor([31.7714])\n",
      "Loss =  tensor([31.1787])\n",
      "Loss =  tensor([31.1993])\n",
      "Loss =  tensor([31.2230])\n",
      "Loss =  tensor([29.5835])\n",
      "Loss =  tensor([30.3738])\n",
      "Loss =  tensor([28.8222])\n",
      "Loss =  tensor([29.3458])\n",
      "Loss =  tensor([28.3413])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.65(best:0.78)\n",
      "F1:[0.47, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.6(best:0.6)\n",
      "Training Root// accuracy:0.78(best:0.78)\n",
      "Training F1:[0.87, 0.88](best:0.89 , 0.88)\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Loss =  tensor([27.3286])\n",
      "Loss =  tensor([28.7756])\n",
      "Loss =  tensor([28.9162])\n",
      "Loss =  tensor([27.4611])\n",
      "Loss =  tensor([28.4076])\n",
      "Loss =  tensor([28.2644])\n",
      "Loss =  tensor([28.3180])\n",
      "Loss =  tensor([29.2985])\n",
      "Loss =  tensor([30.4469])\n",
      "Loss =  tensor([30.5737])\n",
      "Loss =  tensor([30.4504])\n",
      "Loss =  tensor([31.1438])\n",
      "Loss =  tensor([27.4619])\n",
      "Loss =  tensor([31.6905])\n",
      "Loss =  tensor([29.3231])\n",
      "Loss =  tensor([28.5361])\n",
      "Loss =  tensor([29.9243])\n",
      "Loss =  tensor([32.3531])\n",
      "Loss =  tensor([31.0940])\n",
      "Loss =  tensor([29.1268])\n",
      "Loss =  tensor([31.3099])\n",
      "Loss =  tensor([30.2567])\n",
      "Loss =  tensor([29.4784])\n",
      "Loss =  tensor([29.5189])\n",
      "Loss =  tensor([29.2827])\n",
      "Loss =  tensor([28.4228])\n",
      "Loss =  tensor([28.8019])\n",
      "Loss =  tensor([28.8598])\n",
      "Loss =  tensor([27.9062])\n",
      "Loss =  tensor([29.9176])\n",
      "Loss =  tensor([28.5685])\n",
      "Loss =  tensor([30.7860])\n",
      "Loss =  tensor([29.8412])\n",
      "Loss =  tensor([32.4515])\n",
      "Loss =  tensor([28.9075])\n",
      "Loss =  tensor([30.1566])\n",
      "Loss =  tensor([32.1086])\n",
      "Loss =  tensor([30.7532])\n",
      "Loss =  tensor([29.3461])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.67(best:0.78)\n",
      "F1:[0.49, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.81(best:0.81)\n",
      "Training F1:[0.89, 0.9](best:0.89 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Loss =  tensor([29.0201])\n",
      "Loss =  tensor([34.7867])\n",
      "Loss =  tensor([32.9305])\n",
      "Loss =  tensor([33.2458])\n",
      "Loss =  tensor([31.6298])\n",
      "Loss =  tensor([30.3246])\n",
      "Loss =  tensor([29.4365])\n",
      "Loss =  tensor([31.6603])\n",
      "Loss =  tensor([32.6296])\n",
      "Loss =  tensor([29.9424])\n",
      "Loss =  tensor([29.6034])\n",
      "Loss =  tensor([28.2408])\n",
      "Loss =  tensor([29.2664])\n",
      "Loss =  tensor([28.7287])\n",
      "Loss =  tensor([30.9395])\n",
      "Loss =  tensor([29.7592])\n",
      "Loss =  tensor([30.2587])\n",
      "Loss =  tensor([28.8233])\n",
      "Loss =  tensor([28.2453])\n",
      "Loss =  tensor([28.6551])\n",
      "Loss =  tensor([30.4218])\n",
      "Loss =  tensor([28.7605])\n",
      "Loss =  tensor([28.6297])\n",
      "Loss =  tensor([31.9911])\n",
      "Loss =  tensor([33.6347])\n",
      "Loss =  tensor([30.4774])\n",
      "Loss =  tensor([29.7193])\n",
      "Loss =  tensor([31.8814])\n",
      "Loss =  tensor([27.8811])\n",
      "Loss =  tensor([29.3484])\n",
      "Loss =  tensor([30.8246])\n",
      "Loss =  tensor([26.9616])\n",
      "Loss =  tensor([31.1004])\n",
      "Loss =  tensor([29.3140])\n",
      "Loss =  tensor([29.2460])\n",
      "Loss =  tensor([29.4151])\n",
      "Loss =  tensor([28.3681])\n",
      "Loss =  tensor([29.4563])\n",
      "Loss =  tensor([31.7073])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.61(best:0.78)\n",
      "F1:[0.45, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.79(best:0.81)\n",
      "Training F1:[0.87, 0.9](best:0.89 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Loss =  tensor([28.4958])\n",
      "Loss =  tensor([29.0336])\n",
      "Loss =  tensor([28.8489])\n",
      "Loss =  tensor([28.2257])\n",
      "Loss =  tensor([29.6364])\n",
      "Loss =  tensor([28.0080])\n",
      "Loss =  tensor([28.6490])\n",
      "Loss =  tensor([29.0455])\n",
      "Loss =  tensor([28.8160])\n",
      "Loss =  tensor([27.4397])\n",
      "Loss =  tensor([28.7717])\n",
      "Loss =  tensor([29.0816])\n",
      "Loss =  tensor([30.6841])\n",
      "Loss =  tensor([28.8119])\n",
      "Loss =  tensor([27.4672])\n",
      "Loss =  tensor([28.3378])\n",
      "Loss =  tensor([30.3214])\n",
      "Loss =  tensor([30.3790])\n",
      "Loss =  tensor([30.8461])\n",
      "Loss =  tensor([29.5489])\n",
      "Loss =  tensor([30.8036])\n",
      "Loss =  tensor([31.2890])\n",
      "Loss =  tensor([32.4465])\n",
      "Loss =  tensor([30.1271])\n",
      "Loss =  tensor([28.6172])\n",
      "Loss =  tensor([29.7673])\n",
      "Loss =  tensor([28.2065])\n",
      "Loss =  tensor([30.5220])\n",
      "Loss =  tensor([31.6109])\n",
      "Loss =  tensor([32.6514])\n",
      "Loss =  tensor([29.1753])\n",
      "Loss =  tensor([30.8289])\n",
      "Loss =  tensor([30.1940])\n",
      "Loss =  tensor([28.5832])\n",
      "Loss =  tensor([28.6037])\n",
      "Loss =  tensor([29.9319])\n",
      "Loss =  tensor([29.1615])\n",
      "Loss =  tensor([27.8877])\n",
      "Loss =  tensor([27.4197])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.51, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.83(best:0.83)\n",
      "Training F1:[0.91, 0.9](best:0.91 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Loss =  tensor([29.6461])\n",
      "Loss =  tensor([29.4004])\n",
      "Loss =  tensor([28.6571])\n",
      "Loss =  tensor([29.4929])\n",
      "Loss =  tensor([27.3289])\n",
      "Loss =  tensor([29.0300])\n",
      "Loss =  tensor([29.0604])\n",
      "Loss =  tensor([27.9141])\n",
      "Loss =  tensor([28.3532])\n",
      "Loss =  tensor([28.4287])\n",
      "Loss =  tensor([28.6977])\n",
      "Loss =  tensor([30.7406])\n",
      "Loss =  tensor([27.7834])\n",
      "Loss =  tensor([29.4902])\n",
      "Loss =  tensor([31.3809])\n",
      "Loss =  tensor([30.3247])\n",
      "Loss =  tensor([28.6520])\n",
      "Loss =  tensor([32.0424])\n",
      "Loss =  tensor([31.9138])\n",
      "Loss =  tensor([28.7021])\n",
      "Loss =  tensor([31.4990])\n",
      "Loss =  tensor([32.3040])\n",
      "Loss =  tensor([32.7340])\n",
      "Loss =  tensor([29.2501])\n",
      "Loss =  tensor([30.0744])\n",
      "Loss =  tensor([30.0908])\n",
      "Loss =  tensor([30.9059])\n",
      "Loss =  tensor([27.8521])\n",
      "Loss =  tensor([28.8778])\n",
      "Loss =  tensor([30.4030])\n",
      "Loss =  tensor([28.1124])\n",
      "Loss =  tensor([31.0009])\n",
      "Loss =  tensor([29.7974])\n",
      "Loss =  tensor([27.9714])\n",
      "Loss =  tensor([28.1121])\n",
      "Loss =  tensor([28.7694])\n",
      "Loss =  tensor([31.0455])\n",
      "Loss =  tensor([28.8422])\n",
      "Loss =  tensor([29.3573])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.66(best:0.78)\n",
      "F1:[0.49, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.81(best:0.83)\n",
      "Training F1:[0.89, 0.9](best:0.91 , 0.9)\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Loss =  tensor([27.9770])\n",
      "Loss =  tensor([28.3363])\n",
      "Loss =  tensor([28.3845])\n",
      "Loss =  tensor([28.2843])\n",
      "Loss =  tensor([27.8370])\n",
      "Loss =  tensor([28.7788])\n",
      "Loss =  tensor([28.6938])\n",
      "Loss =  tensor([28.5524])\n",
      "Loss =  tensor([27.4961])\n",
      "Loss =  tensor([27.8433])\n",
      "Loss =  tensor([28.6705])\n",
      "Loss =  tensor([29.4876])\n",
      "Loss =  tensor([31.0207])\n",
      "Loss =  tensor([29.6282])\n",
      "Loss =  tensor([29.4444])\n",
      "Loss =  tensor([33.9358])\n",
      "Loss =  tensor([31.8142])\n",
      "Loss =  tensor([32.6803])\n",
      "Loss =  tensor([30.8029])\n",
      "Loss =  tensor([31.0696])\n",
      "Loss =  tensor([35.5808])\n",
      "Loss =  tensor([33.7477])\n",
      "Loss =  tensor([33.0227])\n",
      "Loss =  tensor([32.8943])\n",
      "Loss =  tensor([28.8581])\n",
      "Loss =  tensor([30.9955])\n",
      "Loss =  tensor([31.1575])\n",
      "Loss =  tensor([30.1326])\n",
      "Loss =  tensor([28.7010])\n",
      "Loss =  tensor([28.5314])\n",
      "Loss =  tensor([29.8751])\n",
      "Loss =  tensor([29.9295])\n",
      "Loss =  tensor([27.5452])\n",
      "Loss =  tensor([30.3737])\n",
      "Loss =  tensor([31.2450])\n",
      "Loss =  tensor([32.7883])\n",
      "Loss =  tensor([29.3454])\n",
      "Loss =  tensor([27.7386])\n",
      "Loss =  tensor([30.4635])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.69(best:0.79)\n",
      "Validation Root accuracy:0.64(best:0.78)\n",
      "F1:[0.46, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.61(best:0.61)\n",
      "Training Root// accuracy:0.81(best:0.83)\n",
      "Training F1:[0.88, 0.92](best:0.91 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Loss =  tensor([26.9189])\n",
      "Loss =  tensor([29.3016])\n",
      "Loss =  tensor([28.7953])\n",
      "Loss =  tensor([28.1232])\n",
      "Loss =  tensor([28.5999])\n",
      "Loss =  tensor([31.1360])\n",
      "Loss =  tensor([30.7238])\n",
      "Loss =  tensor([29.9563])\n",
      "Loss =  tensor([29.1546])\n",
      "Loss =  tensor([31.1674])\n",
      "Loss =  tensor([28.2817])\n",
      "Loss =  tensor([32.2107])\n",
      "Loss =  tensor([27.8125])\n",
      "Loss =  tensor([28.4119])\n",
      "Loss =  tensor([28.9610])\n",
      "Loss =  tensor([28.4159])\n",
      "Loss =  tensor([27.5619])\n",
      "Loss =  tensor([31.8253])\n",
      "Loss =  tensor([31.1945])\n",
      "Loss =  tensor([27.8392])\n",
      "Loss =  tensor([28.2844])\n",
      "Loss =  tensor([28.9801])\n",
      "Loss =  tensor([28.1826])\n",
      "Loss =  tensor([30.2361])\n",
      "Loss =  tensor([28.0601])\n",
      "Loss =  tensor([28.1565])\n",
      "Loss =  tensor([28.2162])\n",
      "Loss =  tensor([26.7173])\n",
      "Loss =  tensor([30.7430])\n",
      "Loss =  tensor([28.8730])\n",
      "Loss =  tensor([29.8414])\n",
      "Loss =  tensor([29.4856])\n",
      "Loss =  tensor([28.3934])\n",
      "Loss =  tensor([30.1367])\n",
      "Loss =  tensor([28.1852])\n",
      "Loss =  tensor([29.7676])\n",
      "Loss =  tensor([27.8028])\n",
      "Loss =  tensor([31.5496])\n",
      "Loss =  tensor([32.4396])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.83(best:0.83)\n",
      "Training F1:[0.92, 0.89](best:0.92 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Loss =  tensor([28.7425])\n",
      "Loss =  tensor([28.9145])\n",
      "Loss =  tensor([27.2962])\n",
      "Loss =  tensor([27.9033])\n",
      "Loss =  tensor([28.3940])\n",
      "Loss =  tensor([28.9146])\n",
      "Loss =  tensor([28.3226])\n",
      "Loss =  tensor([28.8327])\n",
      "Loss =  tensor([27.9203])\n",
      "Loss =  tensor([29.3935])\n",
      "Loss =  tensor([27.8860])\n",
      "Loss =  tensor([27.8391])\n",
      "Loss =  tensor([27.5022])\n",
      "Loss =  tensor([29.1731])\n",
      "Loss =  tensor([27.5516])\n",
      "Loss =  tensor([28.3703])\n",
      "Loss =  tensor([29.7169])\n",
      "Loss =  tensor([30.3145])\n",
      "Loss =  tensor([28.7120])\n",
      "Loss =  tensor([27.7391])\n",
      "Loss =  tensor([27.5006])\n",
      "Loss =  tensor([27.1340])\n",
      "Loss =  tensor([28.4405])\n",
      "Loss =  tensor([27.9382])\n",
      "Loss =  tensor([28.7989])\n",
      "Loss =  tensor([28.5081])\n",
      "Loss =  tensor([29.4738])\n",
      "Loss =  tensor([28.3468])\n",
      "Loss =  tensor([29.3190])\n",
      "Loss =  tensor([29.7911])\n",
      "Loss =  tensor([30.0304])\n",
      "Loss =  tensor([29.8657])\n",
      "Loss =  tensor([29.7649])\n",
      "Loss =  tensor([28.8797])\n",
      "Loss =  tensor([29.9450])\n",
      "Loss =  tensor([27.1763])\n",
      "Loss =  tensor([28.3531])\n",
      "Loss =  tensor([28.6517])\n",
      "Loss =  tensor([29.8854])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.67(best:0.78)\n",
      "F1:[0.45, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.62(best:0.62)\n",
      "Training Root// accuracy:0.84(best:0.84)\n",
      "Training F1:[0.91, 0.91](best:0.92 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Loss =  tensor([26.6671])\n",
      "Loss =  tensor([27.5893])\n",
      "Loss =  tensor([29.8185])\n",
      "Loss =  tensor([26.8690])\n",
      "Loss =  tensor([29.4007])\n",
      "Loss =  tensor([27.9530])\n",
      "Loss =  tensor([28.3046])\n",
      "Loss =  tensor([30.3450])\n",
      "Loss =  tensor([28.8062])\n",
      "Loss =  tensor([27.6795])\n",
      "Loss =  tensor([27.1016])\n",
      "Loss =  tensor([27.2572])\n",
      "Loss =  tensor([27.8933])\n",
      "Loss =  tensor([28.7043])\n",
      "Loss =  tensor([26.9947])\n",
      "Loss =  tensor([27.5058])\n",
      "Loss =  tensor([27.6907])\n",
      "Loss =  tensor([28.3752])\n",
      "Loss =  tensor([30.1541])\n",
      "Loss =  tensor([27.1996])\n",
      "Loss =  tensor([29.3338])\n",
      "Loss =  tensor([27.4669])\n",
      "Loss =  tensor([27.8451])\n",
      "Loss =  tensor([27.2623])\n",
      "Loss =  tensor([27.5187])\n",
      "Loss =  tensor([27.0306])\n",
      "Loss =  tensor([30.1895])\n",
      "Loss =  tensor([29.9741])\n",
      "Loss =  tensor([30.4084])\n",
      "Loss =  tensor([27.4617])\n",
      "Loss =  tensor([27.7717])\n",
      "Loss =  tensor([28.5730])\n",
      "Loss =  tensor([28.7193])\n",
      "Loss =  tensor([29.6679])\n",
      "Loss =  tensor([29.7304])\n",
      "Loss =  tensor([30.7564])\n",
      "Loss =  tensor([29.3971])\n",
      "Loss =  tensor([28.1906])\n",
      "Loss =  tensor([29.9690])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.86(best:0.86)\n",
      "Training F1:[0.93, 0.92](best:0.93 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Loss =  tensor([26.6913])\n",
      "Loss =  tensor([28.7128])\n",
      "Loss =  tensor([27.4086])\n",
      "Loss =  tensor([28.7450])\n",
      "Loss =  tensor([26.8943])\n",
      "Loss =  tensor([27.4104])\n",
      "Loss =  tensor([26.8508])\n",
      "Loss =  tensor([28.9666])\n",
      "Loss =  tensor([27.8586])\n",
      "Loss =  tensor([27.9024])\n",
      "Loss =  tensor([27.9848])\n",
      "Loss =  tensor([27.7628])\n",
      "Loss =  tensor([27.4438])\n",
      "Loss =  tensor([30.1265])\n",
      "Loss =  tensor([30.0521])\n",
      "Loss =  tensor([28.4981])\n",
      "Loss =  tensor([29.6675])\n",
      "Loss =  tensor([28.2760])\n",
      "Loss =  tensor([27.5671])\n",
      "Loss =  tensor([27.0128])\n",
      "Loss =  tensor([27.2109])\n",
      "Loss =  tensor([28.6425])\n",
      "Loss =  tensor([29.1178])\n",
      "Loss =  tensor([29.3939])\n",
      "Loss =  tensor([27.1758])\n",
      "Loss =  tensor([27.8682])\n",
      "Loss =  tensor([28.2810])\n",
      "Loss =  tensor([27.8552])\n",
      "Loss =  tensor([29.1687])\n",
      "Loss =  tensor([28.8660])\n",
      "Loss =  tensor([28.2037])\n",
      "Loss =  tensor([29.5002])\n",
      "Loss =  tensor([29.0908])\n",
      "Loss =  tensor([26.6274])\n",
      "Loss =  tensor([27.8737])\n",
      "Loss =  tensor([27.4431])\n",
      "Loss =  tensor([28.9528])\n",
      "Loss =  tensor([28.8509])\n",
      "Loss =  tensor([28.7066])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.57(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.86(best:0.86)\n",
      "Training F1:[0.93, 0.91](best:0.93 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Loss =  tensor([26.3342])\n",
      "Loss =  tensor([27.3906])\n",
      "Loss =  tensor([28.1194])\n",
      "Loss =  tensor([29.0137])\n",
      "Loss =  tensor([27.5147])\n",
      "Loss =  tensor([24.8855])\n",
      "Loss =  tensor([27.8816])\n",
      "Loss =  tensor([27.9443])\n",
      "Loss =  tensor([27.1817])\n",
      "Loss =  tensor([26.9666])\n",
      "Loss =  tensor([27.1681])\n",
      "Loss =  tensor([27.2799])\n",
      "Loss =  tensor([25.6501])\n",
      "Loss =  tensor([28.9696])\n",
      "Loss =  tensor([30.9506])\n",
      "Loss =  tensor([29.1216])\n",
      "Loss =  tensor([27.3370])\n",
      "Loss =  tensor([26.2286])\n",
      "Loss =  tensor([29.6448])\n",
      "Loss =  tensor([28.5820])\n",
      "Loss =  tensor([31.1694])\n",
      "Loss =  tensor([28.3459])\n",
      "Loss =  tensor([30.0666])\n",
      "Loss =  tensor([28.1942])\n",
      "Loss =  tensor([28.3665])\n",
      "Loss =  tensor([28.1719])\n",
      "Loss =  tensor([28.1233])\n",
      "Loss =  tensor([28.2856])\n",
      "Loss =  tensor([30.4454])\n",
      "Loss =  tensor([30.0780])\n",
      "Loss =  tensor([27.5553])\n",
      "Loss =  tensor([29.5915])\n",
      "Loss =  tensor([27.1939])\n",
      "Loss =  tensor([29.5481])\n",
      "Loss =  tensor([30.2591])\n",
      "Loss =  tensor([29.4044])\n",
      "Loss =  tensor([29.0884])\n",
      "Loss =  tensor([27.9772])\n",
      "Loss =  tensor([29.8147])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.63)\n",
      "Training Root// accuracy:0.86(best:0.86)\n",
      "Training F1:[0.93, 0.92](best:0.93 , 0.92)\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Loss =  tensor([27.9756])\n",
      "Loss =  tensor([28.2627])\n",
      "Loss =  tensor([28.7377])\n",
      "Loss =  tensor([27.8237])\n",
      "Loss =  tensor([28.0142])\n",
      "Loss =  tensor([29.8569])\n",
      "Loss =  tensor([27.3543])\n",
      "Loss =  tensor([28.2907])\n",
      "Loss =  tensor([27.0566])\n",
      "Loss =  tensor([28.7756])\n",
      "Loss =  tensor([26.8797])\n",
      "Loss =  tensor([28.6416])\n",
      "Loss =  tensor([28.0492])\n",
      "Loss =  tensor([31.5880])\n",
      "Loss =  tensor([31.0626])\n",
      "Loss =  tensor([29.7279])\n",
      "Loss =  tensor([27.4885])\n",
      "Loss =  tensor([27.0218])\n",
      "Loss =  tensor([30.6645])\n",
      "Loss =  tensor([29.3911])\n",
      "Loss =  tensor([28.5439])\n",
      "Loss =  tensor([29.0336])\n",
      "Loss =  tensor([25.8517])\n",
      "Loss =  tensor([29.4295])\n",
      "Loss =  tensor([27.7623])\n",
      "Loss =  tensor([27.3271])\n",
      "Loss =  tensor([28.5717])\n",
      "Loss =  tensor([27.5677])\n",
      "Loss =  tensor([28.4998])\n",
      "Loss =  tensor([27.5427])\n",
      "Loss =  tensor([27.2057])\n",
      "Loss =  tensor([27.9243])\n",
      "Loss =  tensor([27.0526])\n",
      "Loss =  tensor([25.8751])\n",
      "Loss =  tensor([28.3279])\n",
      "Loss =  tensor([28.6052])\n",
      "Loss =  tensor([26.9430])\n",
      "Loss =  tensor([26.0891])\n",
      "Loss =  tensor([27.3695])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.88(best:0.88)\n",
      "Training F1:[0.94, 0.93](best:0.94 , 0.93)\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Loss =  tensor([27.1661])\n",
      "Loss =  tensor([25.1234])\n",
      "Loss =  tensor([26.8307])\n",
      "Loss =  tensor([28.4915])\n",
      "Loss =  tensor([28.3913])\n",
      "Loss =  tensor([29.5594])\n",
      "Loss =  tensor([33.9097])\n",
      "Loss =  tensor([29.9232])\n",
      "Loss =  tensor([28.0147])\n",
      "Loss =  tensor([31.9344])\n",
      "Loss =  tensor([34.4768])\n",
      "Loss =  tensor([33.8641])\n",
      "Loss =  tensor([29.2717])\n",
      "Loss =  tensor([25.8845])\n",
      "Loss =  tensor([29.5767])\n",
      "Loss =  tensor([31.2699])\n",
      "Loss =  tensor([32.8345])\n",
      "Loss =  tensor([30.7659])\n",
      "Loss =  tensor([29.0247])\n",
      "Loss =  tensor([28.4159])\n",
      "Loss =  tensor([31.5184])\n",
      "Loss =  tensor([30.6841])\n",
      "Loss =  tensor([29.8223])\n",
      "Loss =  tensor([28.3065])\n",
      "Loss =  tensor([29.7457])\n",
      "Loss =  tensor([27.9836])\n",
      "Loss =  tensor([27.6235])\n",
      "Loss =  tensor([29.4527])\n",
      "Loss =  tensor([29.3173])\n",
      "Loss =  tensor([28.6174])\n",
      "Loss =  tensor([29.0094])\n",
      "Loss =  tensor([28.2004])\n",
      "Loss =  tensor([28.7966])\n",
      "Loss =  tensor([27.6770])\n",
      "Loss =  tensor([27.1759])\n",
      "Loss =  tensor([27.4354])\n",
      "Loss =  tensor([27.6639])\n",
      "Loss =  tensor([29.5358])\n",
      "Loss =  tensor([29.9565])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.68(best:0.78)\n",
      "F1:[0.5, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.63(best:0.64)\n",
      "Training Root// accuracy:0.85(best:0.88)\n",
      "Training F1:[0.91, 0.92](best:0.94 , 0.93)\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Loss =  tensor([26.8294])\n",
      "Loss =  tensor([27.6820])\n",
      "Loss =  tensor([27.3613])\n",
      "Loss =  tensor([27.1484])\n",
      "Loss =  tensor([28.0704])\n",
      "Loss =  tensor([29.1147])\n",
      "Loss =  tensor([27.2691])\n",
      "Loss =  tensor([25.3400])\n",
      "Loss =  tensor([27.4280])\n",
      "Loss =  tensor([27.2250])\n",
      "Loss =  tensor([27.9062])\n",
      "Loss =  tensor([27.5921])\n",
      "Loss =  tensor([27.0318])\n",
      "Loss =  tensor([27.1291])\n",
      "Loss =  tensor([25.9269])\n",
      "Loss =  tensor([25.3527])\n",
      "Loss =  tensor([26.8267])\n",
      "Loss =  tensor([28.0553])\n",
      "Loss =  tensor([27.7143])\n",
      "Loss =  tensor([29.1281])\n",
      "Loss =  tensor([28.3358])\n",
      "Loss =  tensor([28.3072])\n",
      "Loss =  tensor([27.6931])\n",
      "Loss =  tensor([27.0817])\n",
      "Loss =  tensor([28.7502])\n",
      "Loss =  tensor([28.0420])\n",
      "Loss =  tensor([26.9262])\n",
      "Loss =  tensor([27.0063])\n",
      "Loss =  tensor([27.6699])\n",
      "Loss =  tensor([28.0888])\n",
      "Loss =  tensor([28.0087])\n",
      "Loss =  tensor([29.7903])\n",
      "Loss =  tensor([29.3002])\n",
      "Loss =  tensor([28.1739])\n",
      "Loss =  tensor([27.2855])\n",
      "Loss =  tensor([30.1846])\n",
      "Loss =  tensor([28.3963])\n",
      "Loss =  tensor([28.6689])\n",
      "Loss =  tensor([28.5429])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.88(best:0.88)\n",
      "Training F1:[0.94, 0.93](best:0.94 , 0.93)\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Loss =  tensor([26.1855])\n",
      "Loss =  tensor([26.4822])\n",
      "Loss =  tensor([27.1813])\n",
      "Loss =  tensor([29.1968])\n",
      "Loss =  tensor([28.3867])\n",
      "Loss =  tensor([26.4238])\n",
      "Loss =  tensor([27.8473])\n",
      "Loss =  tensor([26.6405])\n",
      "Loss =  tensor([26.9481])\n",
      "Loss =  tensor([28.9146])\n",
      "Loss =  tensor([28.0736])\n",
      "Loss =  tensor([28.8205])\n",
      "Loss =  tensor([27.7111])\n",
      "Loss =  tensor([28.3072])\n",
      "Loss =  tensor([26.9236])\n",
      "Loss =  tensor([28.2569])\n",
      "Loss =  tensor([25.9969])\n",
      "Loss =  tensor([25.1748])\n",
      "Loss =  tensor([27.2673])\n",
      "Loss =  tensor([27.6592])\n",
      "Loss =  tensor([26.2345])\n",
      "Loss =  tensor([24.9502])\n",
      "Loss =  tensor([28.6189])\n",
      "Loss =  tensor([27.1390])\n",
      "Loss =  tensor([28.6974])\n",
      "Loss =  tensor([27.1371])\n",
      "Loss =  tensor([28.3629])\n",
      "Loss =  tensor([25.7573])\n",
      "Loss =  tensor([27.7156])\n",
      "Loss =  tensor([27.0409])\n",
      "Loss =  tensor([26.8547])\n",
      "Loss =  tensor([27.6465])\n",
      "Loss =  tensor([26.3330])\n",
      "Loss =  tensor([29.0817])\n",
      "Loss =  tensor([27.2944])\n",
      "Loss =  tensor([27.6175])\n",
      "Loss =  tensor([27.2847])\n",
      "Loss =  tensor([27.4038])\n",
      "Loss =  tensor([26.6157])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.89(best:0.89)\n",
      "Training F1:[0.95, 0.94](best:0.95 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Loss =  tensor([26.1946])\n",
      "Loss =  tensor([27.3001])\n",
      "Loss =  tensor([27.6859])\n",
      "Loss =  tensor([27.2108])\n",
      "Loss =  tensor([27.8034])\n",
      "Loss =  tensor([28.5645])\n",
      "Loss =  tensor([29.2752])\n",
      "Loss =  tensor([28.0275])\n",
      "Loss =  tensor([26.6769])\n",
      "Loss =  tensor([26.5298])\n",
      "Loss =  tensor([27.5987])\n",
      "Loss =  tensor([27.1587])\n",
      "Loss =  tensor([28.3402])\n",
      "Loss =  tensor([27.6576])\n",
      "Loss =  tensor([28.0431])\n",
      "Loss =  tensor([24.1296])\n",
      "Loss =  tensor([27.6976])\n",
      "Loss =  tensor([25.9986])\n",
      "Loss =  tensor([30.8473])\n",
      "Loss =  tensor([26.2435])\n",
      "Loss =  tensor([26.8322])\n",
      "Loss =  tensor([25.6839])\n",
      "Loss =  tensor([26.8182])\n",
      "Loss =  tensor([26.3371])\n",
      "Loss =  tensor([29.7568])\n",
      "Loss =  tensor([27.9346])\n",
      "Loss =  tensor([27.3410])\n",
      "Loss =  tensor([32.8788])\n",
      "Loss =  tensor([30.0773])\n",
      "Loss =  tensor([27.1504])\n",
      "Loss =  tensor([28.6752])\n",
      "Loss =  tensor([32.5306])\n",
      "Loss =  tensor([31.7121])\n",
      "Loss =  tensor([29.2892])\n",
      "Loss =  tensor([26.9317])\n",
      "Loss =  tensor([29.7715])\n",
      "Loss =  tensor([28.3940])\n",
      "Loss =  tensor([27.2786])\n",
      "Loss =  tensor([28.6677])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.54(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.89(best:0.89)\n",
      "Training F1:[0.95, 0.94](best:0.95 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Loss =  tensor([28.3699])\n",
      "Loss =  tensor([25.7494])\n",
      "Loss =  tensor([25.3773])\n",
      "Loss =  tensor([27.0956])\n",
      "Loss =  tensor([25.8609])\n",
      "Loss =  tensor([26.8870])\n",
      "Loss =  tensor([27.3737])\n",
      "Loss =  tensor([26.5060])\n",
      "Loss =  tensor([30.7009])\n",
      "Loss =  tensor([31.2575])\n",
      "Loss =  tensor([26.8127])\n",
      "Loss =  tensor([27.2735])\n",
      "Loss =  tensor([27.7811])\n",
      "Loss =  tensor([29.7336])\n",
      "Loss =  tensor([28.1708])\n",
      "Loss =  tensor([26.5828])\n",
      "Loss =  tensor([28.3158])\n",
      "Loss =  tensor([29.0574])\n",
      "Loss =  tensor([30.0373])\n",
      "Loss =  tensor([27.0649])\n",
      "Loss =  tensor([27.8778])\n",
      "Loss =  tensor([27.8778])\n",
      "Loss =  tensor([26.9945])\n",
      "Loss =  tensor([28.7439])\n",
      "Loss =  tensor([30.0083])\n",
      "Loss =  tensor([26.5299])\n",
      "Loss =  tensor([27.4950])\n",
      "Loss =  tensor([32.0140])\n",
      "Loss =  tensor([26.9418])\n",
      "Loss =  tensor([28.0599])\n",
      "Loss =  tensor([28.5792])\n",
      "Loss =  tensor([27.7772])\n",
      "Loss =  tensor([27.3522])\n",
      "Loss =  tensor([28.4968])\n",
      "Loss =  tensor([30.1766])\n",
      "Loss =  tensor([32.4013])\n",
      "Loss =  tensor([28.5664])\n",
      "Loss =  tensor([28.4327])\n",
      "Loss =  tensor([30.0886])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.88(best:0.89)\n",
      "Training F1:[0.94, 0.93](best:0.95 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Loss =  tensor([25.2469])\n",
      "Loss =  tensor([24.8419])\n",
      "Loss =  tensor([26.1314])\n",
      "Loss =  tensor([24.9166])\n",
      "Loss =  tensor([25.7411])\n",
      "Loss =  tensor([26.2792])\n",
      "Loss =  tensor([27.4742])\n",
      "Loss =  tensor([29.4641])\n",
      "Loss =  tensor([28.2449])\n",
      "Loss =  tensor([27.3828])\n",
      "Loss =  tensor([27.5089])\n",
      "Loss =  tensor([28.2956])\n",
      "Loss =  tensor([26.9245])\n",
      "Loss =  tensor([31.0318])\n",
      "Loss =  tensor([30.8512])\n",
      "Loss =  tensor([27.7651])\n",
      "Loss =  tensor([26.1671])\n",
      "Loss =  tensor([28.8988])\n",
      "Loss =  tensor([29.4102])\n",
      "Loss =  tensor([25.8784])\n",
      "Loss =  tensor([26.7275])\n",
      "Loss =  tensor([29.0717])\n",
      "Loss =  tensor([27.9196])\n",
      "Loss =  tensor([26.1772])\n",
      "Loss =  tensor([27.2393])\n",
      "Loss =  tensor([26.4065])\n",
      "Loss =  tensor([27.7867])\n",
      "Loss =  tensor([29.7115])\n",
      "Loss =  tensor([28.5446])\n",
      "Loss =  tensor([25.1238])\n",
      "Loss =  tensor([27.1486])\n",
      "Loss =  tensor([27.3355])\n",
      "Loss =  tensor([26.9284])\n",
      "Loss =  tensor([28.4899])\n",
      "Loss =  tensor([29.9106])\n",
      "Loss =  tensor([26.6339])\n",
      "Loss =  tensor([27.4413])\n",
      "Loss =  tensor([27.3536])\n",
      "Loss =  tensor([25.8578])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.89(best:0.89)\n",
      "Training F1:[0.95, 0.94](best:0.95 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Loss =  tensor([27.1776])\n",
      "Loss =  tensor([27.9570])\n",
      "Loss =  tensor([28.0008])\n",
      "Loss =  tensor([26.2278])\n",
      "Loss =  tensor([26.2979])\n",
      "Loss =  tensor([27.3055])\n",
      "Loss =  tensor([26.5612])\n",
      "Loss =  tensor([28.1427])\n",
      "Loss =  tensor([29.2843])\n",
      "Loss =  tensor([27.5758])\n",
      "Loss =  tensor([28.1413])\n",
      "Loss =  tensor([27.1236])\n",
      "Loss =  tensor([26.0121])\n",
      "Loss =  tensor([25.0696])\n",
      "Loss =  tensor([26.9164])\n",
      "Loss =  tensor([27.9594])\n",
      "Loss =  tensor([27.5505])\n",
      "Loss =  tensor([27.7688])\n",
      "Loss =  tensor([25.6321])\n",
      "Loss =  tensor([28.9472])\n",
      "Loss =  tensor([28.3650])\n",
      "Loss =  tensor([28.6963])\n",
      "Loss =  tensor([28.0113])\n",
      "Loss =  tensor([28.9211])\n",
      "Loss =  tensor([26.3093])\n",
      "Loss =  tensor([26.0762])\n",
      "Loss =  tensor([30.3096])\n",
      "Loss =  tensor([27.7862])\n",
      "Loss =  tensor([28.4091])\n",
      "Loss =  tensor([28.4887])\n",
      "Loss =  tensor([31.4491])\n",
      "Loss =  tensor([29.4894])\n",
      "Loss =  tensor([26.5296])\n",
      "Loss =  tensor([27.3575])\n",
      "Loss =  tensor([27.0634])\n",
      "Loss =  tensor([27.0108])\n",
      "Loss =  tensor([27.0643])\n",
      "Loss =  tensor([27.3980])\n",
      "Loss =  tensor([26.4769])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.52, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.64(best:0.64)\n",
      "Training Root// accuracy:0.89(best:0.89)\n",
      "Training F1:[0.95, 0.94](best:0.95 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Loss =  tensor([26.5321])\n",
      "Loss =  tensor([29.7620])\n",
      "Loss =  tensor([29.7175])\n",
      "Loss =  tensor([28.9978])\n",
      "Loss =  tensor([27.9442])\n",
      "Loss =  tensor([27.0607])\n",
      "Loss =  tensor([30.4861])\n",
      "Loss =  tensor([27.8001])\n",
      "Loss =  tensor([28.4866])\n",
      "Loss =  tensor([28.5360])\n",
      "Loss =  tensor([27.0333])\n",
      "Loss =  tensor([28.6005])\n",
      "Loss =  tensor([27.7443])\n",
      "Loss =  tensor([27.9403])\n",
      "Loss =  tensor([29.0736])\n",
      "Loss =  tensor([26.8595])\n",
      "Loss =  tensor([27.7133])\n",
      "Loss =  tensor([26.7887])\n",
      "Loss =  tensor([25.8925])\n",
      "Loss =  tensor([27.7279])\n",
      "Loss =  tensor([28.4929])\n",
      "Loss =  tensor([28.3684])\n",
      "Loss =  tensor([27.6682])\n",
      "Loss =  tensor([29.7196])\n",
      "Loss =  tensor([26.3788])\n",
      "Loss =  tensor([27.8346])\n",
      "Loss =  tensor([27.9263])\n",
      "Loss =  tensor([29.7560])\n",
      "Loss =  tensor([27.2390])\n",
      "Loss =  tensor([26.8267])\n",
      "Loss =  tensor([26.4138])\n",
      "Loss =  tensor([28.0484])\n",
      "Loss =  tensor([26.6058])\n",
      "Loss =  tensor([26.6796])\n",
      "Loss =  tensor([27.4456])\n",
      "Loss =  tensor([28.0619])\n",
      "Loss =  tensor([27.2470])\n",
      "Loss =  tensor([27.0004])\n",
      "Loss =  tensor([26.6297])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.89(best:0.89)\n",
      "Training F1:[0.94, 0.94](best:0.95 , 0.94)\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Loss =  tensor([26.5989])\n",
      "Loss =  tensor([26.1204])\n",
      "Loss =  tensor([27.3644])\n",
      "Loss =  tensor([26.4053])\n",
      "Loss =  tensor([29.4904])\n",
      "Loss =  tensor([26.6433])\n",
      "Loss =  tensor([27.0404])\n",
      "Loss =  tensor([27.8212])\n",
      "Loss =  tensor([26.1079])\n",
      "Loss =  tensor([28.2522])\n",
      "Loss =  tensor([27.3834])\n",
      "Loss =  tensor([26.5496])\n",
      "Loss =  tensor([28.0736])\n",
      "Loss =  tensor([27.2122])\n",
      "Loss =  tensor([27.9557])\n",
      "Loss =  tensor([29.4215])\n",
      "Loss =  tensor([25.6902])\n",
      "Loss =  tensor([26.8265])\n",
      "Loss =  tensor([29.6215])\n",
      "Loss =  tensor([29.3129])\n",
      "Loss =  tensor([27.0791])\n",
      "Loss =  tensor([28.5099])\n",
      "Loss =  tensor([28.8530])\n",
      "Loss =  tensor([27.3876])\n",
      "Loss =  tensor([27.1622])\n",
      "Loss =  tensor([29.7842])\n",
      "Loss =  tensor([26.3632])\n",
      "Loss =  tensor([25.4722])\n",
      "Loss =  tensor([27.0773])\n",
      "Loss =  tensor([28.2336])\n",
      "Loss =  tensor([26.9741])\n",
      "Loss =  tensor([27.4794])\n",
      "Loss =  tensor([27.4880])\n",
      "Loss =  tensor([29.4590])\n",
      "Loss =  tensor([26.6714])\n",
      "Loss =  tensor([27.5295])\n",
      "Loss =  tensor([28.6330])\n",
      "Loss =  tensor([28.2629])\n",
      "Loss =  tensor([24.8665])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.48, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.9(best:0.9)\n",
      "Training F1:[0.95, 0.95](best:0.95 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Loss =  tensor([28.1738])\n",
      "Loss =  tensor([24.3617])\n",
      "Loss =  tensor([25.8256])\n",
      "Loss =  tensor([28.1935])\n",
      "Loss =  tensor([28.0224])\n",
      "Loss =  tensor([26.1716])\n",
      "Loss =  tensor([25.8936])\n",
      "Loss =  tensor([27.2071])\n",
      "Loss =  tensor([25.8557])\n",
      "Loss =  tensor([26.2948])\n",
      "Loss =  tensor([28.2952])\n",
      "Loss =  tensor([27.2150])\n",
      "Loss =  tensor([25.4596])\n",
      "Loss =  tensor([28.5937])\n",
      "Loss =  tensor([30.8242])\n",
      "Loss =  tensor([27.8591])\n",
      "Loss =  tensor([26.7641])\n",
      "Loss =  tensor([30.8911])\n",
      "Loss =  tensor([30.9601])\n",
      "Loss =  tensor([30.3067])\n",
      "Loss =  tensor([28.2669])\n",
      "Loss =  tensor([27.8900])\n",
      "Loss =  tensor([31.1045])\n",
      "Loss =  tensor([28.2757])\n",
      "Loss =  tensor([27.5057])\n",
      "Loss =  tensor([26.0302])\n",
      "Loss =  tensor([27.1482])\n",
      "Loss =  tensor([28.8126])\n",
      "Loss =  tensor([25.6996])\n",
      "Loss =  tensor([27.6734])\n",
      "Loss =  tensor([27.3651])\n",
      "Loss =  tensor([27.2737])\n",
      "Loss =  tensor([28.8956])\n",
      "Loss =  tensor([27.7346])\n",
      "Loss =  tensor([28.7262])\n",
      "Loss =  tensor([26.3951])\n",
      "Loss =  tensor([27.0161])\n",
      "Loss =  tensor([27.2740])\n",
      "Loss =  tensor([25.6572])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.48, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.9(best:0.9)\n",
      "Training F1:[0.95, 0.95](best:0.95 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Loss =  tensor([24.9633])\n",
      "Loss =  tensor([26.9914])\n",
      "Loss =  tensor([27.3948])\n",
      "Loss =  tensor([27.8016])\n",
      "Loss =  tensor([27.9799])\n",
      "Loss =  tensor([24.9396])\n",
      "Loss =  tensor([27.0512])\n",
      "Loss =  tensor([26.1951])\n",
      "Loss =  tensor([26.4212])\n",
      "Loss =  tensor([26.8706])\n",
      "Loss =  tensor([26.3708])\n",
      "Loss =  tensor([28.1603])\n",
      "Loss =  tensor([25.7102])\n",
      "Loss =  tensor([27.9595])\n",
      "Loss =  tensor([26.4282])\n",
      "Loss =  tensor([26.9577])\n",
      "Loss =  tensor([28.4784])\n",
      "Loss =  tensor([29.2481])\n",
      "Loss =  tensor([28.6873])\n",
      "Loss =  tensor([27.2104])\n",
      "Loss =  tensor([26.0473])\n",
      "Loss =  tensor([29.1485])\n",
      "Loss =  tensor([27.6929])\n",
      "Loss =  tensor([25.6917])\n",
      "Loss =  tensor([26.8347])\n",
      "Loss =  tensor([27.0802])\n",
      "Loss =  tensor([26.2863])\n",
      "Loss =  tensor([27.3881])\n",
      "Loss =  tensor([26.9789])\n",
      "Loss =  tensor([25.2337])\n",
      "Loss =  tensor([27.1261])\n",
      "Loss =  tensor([27.3562])\n",
      "Loss =  tensor([27.1898])\n",
      "Loss =  tensor([26.5060])\n",
      "Loss =  tensor([27.4923])\n",
      "Loss =  tensor([26.1039])\n",
      "Loss =  tensor([27.6187])\n",
      "Loss =  tensor([26.4092])\n",
      "Loss =  tensor([29.6729])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.91(best:0.91)\n",
      "Training F1:[0.96, 0.94](best:0.96 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Loss =  tensor([27.0291])\n",
      "Loss =  tensor([25.5609])\n",
      "Loss =  tensor([27.4005])\n",
      "Loss =  tensor([27.0926])\n",
      "Loss =  tensor([26.3780])\n",
      "Loss =  tensor([26.6419])\n",
      "Loss =  tensor([27.8816])\n",
      "Loss =  tensor([23.9122])\n",
      "Loss =  tensor([30.2243])\n",
      "Loss =  tensor([30.8202])\n",
      "Loss =  tensor([31.3759])\n",
      "Loss =  tensor([25.7544])\n",
      "Loss =  tensor([28.7390])\n",
      "Loss =  tensor([31.7936])\n",
      "Loss =  tensor([33.6778])\n",
      "Loss =  tensor([29.8652])\n",
      "Loss =  tensor([27.4021])\n",
      "Loss =  tensor([27.6829])\n",
      "Loss =  tensor([26.5949])\n",
      "Loss =  tensor([27.9847])\n",
      "Loss =  tensor([29.6132])\n",
      "Loss =  tensor([27.3528])\n",
      "Loss =  tensor([27.2631])\n",
      "Loss =  tensor([25.8731])\n",
      "Loss =  tensor([26.8659])\n",
      "Loss =  tensor([27.9947])\n",
      "Loss =  tensor([26.5454])\n",
      "Loss =  tensor([25.0808])\n",
      "Loss =  tensor([25.9617])\n",
      "Loss =  tensor([27.6335])\n",
      "Loss =  tensor([28.0459])\n",
      "Loss =  tensor([26.7879])\n",
      "Loss =  tensor([25.7179])\n",
      "Loss =  tensor([28.7285])\n",
      "Loss =  tensor([26.9064])\n",
      "Loss =  tensor([27.2001])\n",
      "Loss =  tensor([27.9765])\n",
      "Loss =  tensor([26.4599])\n",
      "Loss =  tensor([26.1188])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.91(best:0.91)\n",
      "Training F1:[0.95, 0.95](best:0.96 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Loss =  tensor([26.4196])\n",
      "Loss =  tensor([27.2089])\n",
      "Loss =  tensor([27.9240])\n",
      "Loss =  tensor([27.1223])\n",
      "Loss =  tensor([26.9629])\n",
      "Loss =  tensor([26.1347])\n",
      "Loss =  tensor([24.6577])\n",
      "Loss =  tensor([27.8896])\n",
      "Loss =  tensor([25.3604])\n",
      "Loss =  tensor([27.6258])\n",
      "Loss =  tensor([27.0491])\n",
      "Loss =  tensor([26.2975])\n",
      "Loss =  tensor([28.1020])\n",
      "Loss =  tensor([31.7742])\n",
      "Loss =  tensor([26.8682])\n",
      "Loss =  tensor([26.6910])\n",
      "Loss =  tensor([31.1915])\n",
      "Loss =  tensor([37.2062])\n",
      "Loss =  tensor([36.1004])\n",
      "Loss =  tensor([30.2927])\n",
      "Loss =  tensor([27.7884])\n",
      "Loss =  tensor([30.7759])\n",
      "Loss =  tensor([28.1589])\n",
      "Loss =  tensor([25.6535])\n",
      "Loss =  tensor([27.1384])\n",
      "Loss =  tensor([29.9194])\n",
      "Loss =  tensor([27.3724])\n",
      "Loss =  tensor([26.1753])\n",
      "Loss =  tensor([31.4492])\n",
      "Loss =  tensor([29.8067])\n",
      "Loss =  tensor([29.7905])\n",
      "Loss =  tensor([28.7509])\n",
      "Loss =  tensor([25.3754])\n",
      "Loss =  tensor([31.0180])\n",
      "Loss =  tensor([27.5285])\n",
      "Loss =  tensor([26.4226])\n",
      "Loss =  tensor([26.9285])\n",
      "Loss =  tensor([27.7542])\n",
      "Loss =  tensor([29.3348])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.69(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.91(best:0.91)\n",
      "Training F1:[0.95, 0.95](best:0.96 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Loss =  tensor([26.9397])\n",
      "Loss =  tensor([30.5495])\n",
      "Loss =  tensor([36.5237])\n",
      "Loss =  tensor([32.7693])\n",
      "Loss =  tensor([29.5282])\n",
      "Loss =  tensor([26.9293])\n",
      "Loss =  tensor([29.4778])\n",
      "Loss =  tensor([27.3536])\n",
      "Loss =  tensor([26.8499])\n",
      "Loss =  tensor([26.2493])\n",
      "Loss =  tensor([27.3991])\n",
      "Loss =  tensor([27.6711])\n",
      "Loss =  tensor([25.3913])\n",
      "Loss =  tensor([26.6745])\n",
      "Loss =  tensor([26.7602])\n",
      "Loss =  tensor([26.2800])\n",
      "Loss =  tensor([25.4801])\n",
      "Loss =  tensor([27.2515])\n",
      "Loss =  tensor([26.8316])\n",
      "Loss =  tensor([28.8108])\n",
      "Loss =  tensor([27.8754])\n",
      "Loss =  tensor([27.1325])\n",
      "Loss =  tensor([27.1412])\n",
      "Loss =  tensor([28.9831])\n",
      "Loss =  tensor([28.0268])\n",
      "Loss =  tensor([26.1073])\n",
      "Loss =  tensor([26.4434])\n",
      "Loss =  tensor([25.3446])\n",
      "Loss =  tensor([25.8503])\n",
      "Loss =  tensor([25.1609])\n",
      "Loss =  tensor([26.5413])\n",
      "Loss =  tensor([27.9235])\n",
      "Loss =  tensor([25.6514])\n",
      "Loss =  tensor([27.4459])\n",
      "Loss =  tensor([25.9501])\n",
      "Loss =  tensor([28.7845])\n",
      "Loss =  tensor([27.0464])\n",
      "Loss =  tensor([27.2318])\n",
      "Loss =  tensor([26.5151])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.91(best:0.91)\n",
      "Training F1:[0.96, 0.95](best:0.96 , 0.95)\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Loss =  tensor([26.8353])\n",
      "Loss =  tensor([25.5930])\n",
      "Loss =  tensor([27.3079])\n",
      "Loss =  tensor([27.0825])\n",
      "Loss =  tensor([27.1624])\n",
      "Loss =  tensor([25.6477])\n",
      "Loss =  tensor([28.0679])\n",
      "Loss =  tensor([27.8744])\n",
      "Loss =  tensor([25.2136])\n",
      "Loss =  tensor([27.5517])\n",
      "Loss =  tensor([27.0304])\n",
      "Loss =  tensor([25.3256])\n",
      "Loss =  tensor([26.7211])\n",
      "Loss =  tensor([26.6295])\n",
      "Loss =  tensor([24.5047])\n",
      "Loss =  tensor([25.7435])\n",
      "Loss =  tensor([26.2804])\n",
      "Loss =  tensor([27.3081])\n",
      "Loss =  tensor([27.2141])\n",
      "Loss =  tensor([25.4261])\n",
      "Loss =  tensor([28.1725])\n",
      "Loss =  tensor([27.8687])\n",
      "Loss =  tensor([25.3482])\n",
      "Loss =  tensor([28.1577])\n",
      "Loss =  tensor([27.9212])\n",
      "Loss =  tensor([25.7462])\n",
      "Loss =  tensor([26.9979])\n",
      "Loss =  tensor([25.3568])\n",
      "Loss =  tensor([24.2981])\n",
      "Loss =  tensor([28.4761])\n",
      "Loss =  tensor([26.6411])\n",
      "Loss =  tensor([26.7801])\n",
      "Loss =  tensor([26.5272])\n",
      "Loss =  tensor([26.8576])\n",
      "Loss =  tensor([25.9871])\n",
      "Loss =  tensor([26.9439])\n",
      "Loss =  tensor([27.9932])\n",
      "Loss =  tensor([26.3592])\n",
      "Loss =  tensor([26.7035])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.92(best:0.92)\n",
      "Training F1:[0.96, 0.96](best:0.96 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Loss =  tensor([26.4376])\n",
      "Loss =  tensor([26.4083])\n",
      "Loss =  tensor([26.2790])\n",
      "Loss =  tensor([27.9884])\n",
      "Loss =  tensor([26.7732])\n",
      "Loss =  tensor([25.6308])\n",
      "Loss =  tensor([25.7742])\n",
      "Loss =  tensor([26.3793])\n",
      "Loss =  tensor([24.6792])\n",
      "Loss =  tensor([25.6837])\n",
      "Loss =  tensor([26.4557])\n",
      "Loss =  tensor([28.2972])\n",
      "Loss =  tensor([28.4095])\n",
      "Loss =  tensor([24.6726])\n",
      "Loss =  tensor([26.0986])\n",
      "Loss =  tensor([26.0752])\n",
      "Loss =  tensor([25.4596])\n",
      "Loss =  tensor([27.6539])\n",
      "Loss =  tensor([27.1970])\n",
      "Loss =  tensor([29.4686])\n",
      "Loss =  tensor([27.1824])\n",
      "Loss =  tensor([28.5787])\n",
      "Loss =  tensor([28.4918])\n",
      "Loss =  tensor([28.2995])\n",
      "Loss =  tensor([26.3507])\n",
      "Loss =  tensor([28.8249])\n",
      "Loss =  tensor([27.9843])\n",
      "Loss =  tensor([27.4206])\n",
      "Loss =  tensor([27.0467])\n",
      "Loss =  tensor([26.6627])\n",
      "Loss =  tensor([24.7356])\n",
      "Loss =  tensor([27.4691])\n",
      "Loss =  tensor([27.0242])\n",
      "Loss =  tensor([26.0734])\n",
      "Loss =  tensor([25.3491])\n",
      "Loss =  tensor([23.5926])\n",
      "Loss =  tensor([24.3641])\n",
      "Loss =  tensor([26.8932])\n",
      "Loss =  tensor([28.1170])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.58(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.65(best:0.65)\n",
      "Training Root// accuracy:0.92(best:0.92)\n",
      "Training F1:[0.96, 0.96](best:0.96 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Loss =  tensor([26.6659])\n",
      "Loss =  tensor([26.6941])\n",
      "Loss =  tensor([24.7708])\n",
      "Loss =  tensor([25.4678])\n",
      "Loss =  tensor([27.0081])\n",
      "Loss =  tensor([27.8473])\n",
      "Loss =  tensor([27.6390])\n",
      "Loss =  tensor([27.9258])\n",
      "Loss =  tensor([26.1224])\n",
      "Loss =  tensor([26.2540])\n",
      "Loss =  tensor([25.4783])\n",
      "Loss =  tensor([24.9612])\n",
      "Loss =  tensor([27.0998])\n",
      "Loss =  tensor([27.5542])\n",
      "Loss =  tensor([27.0773])\n",
      "Loss =  tensor([26.4247])\n",
      "Loss =  tensor([26.9329])\n",
      "Loss =  tensor([27.8310])\n",
      "Loss =  tensor([27.6266])\n",
      "Loss =  tensor([26.3846])\n",
      "Loss =  tensor([26.6270])\n",
      "Loss =  tensor([25.6730])\n",
      "Loss =  tensor([29.2752])\n",
      "Loss =  tensor([25.0754])\n",
      "Loss =  tensor([25.4213])\n",
      "Loss =  tensor([27.0820])\n",
      "Loss =  tensor([24.7963])\n",
      "Loss =  tensor([29.7700])\n",
      "Loss =  tensor([29.9434])\n",
      "Loss =  tensor([28.0542])\n",
      "Loss =  tensor([27.7758])\n",
      "Loss =  tensor([28.7452])\n",
      "Loss =  tensor([28.3787])\n",
      "Loss =  tensor([26.3446])\n",
      "Loss =  tensor([26.0053])\n",
      "Loss =  tensor([25.9315])\n",
      "Loss =  tensor([27.3882])\n",
      "Loss =  tensor([27.7332])\n",
      "Loss =  tensor([27.2117])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Loss =  tensor([25.2726])\n",
      "Loss =  tensor([28.5354])\n",
      "Loss =  tensor([26.4833])\n",
      "Loss =  tensor([25.9714])\n",
      "Loss =  tensor([25.8763])\n",
      "Loss =  tensor([30.0226])\n",
      "Loss =  tensor([26.7982])\n",
      "Loss =  tensor([25.7083])\n",
      "Loss =  tensor([25.6923])\n",
      "Loss =  tensor([27.6310])\n",
      "Loss =  tensor([25.2042])\n",
      "Loss =  tensor([27.2211])\n",
      "Loss =  tensor([25.8000])\n",
      "Loss =  tensor([28.8193])\n",
      "Loss =  tensor([26.6661])\n",
      "Loss =  tensor([27.9762])\n",
      "Loss =  tensor([28.6838])\n",
      "Loss =  tensor([26.1742])\n",
      "Loss =  tensor([26.2751])\n",
      "Loss =  tensor([27.1360])\n",
      "Loss =  tensor([28.4741])\n",
      "Loss =  tensor([26.1242])\n",
      "Loss =  tensor([27.8066])\n",
      "Loss =  tensor([24.1874])\n",
      "Loss =  tensor([25.5687])\n",
      "Loss =  tensor([28.3286])\n",
      "Loss =  tensor([25.6002])\n",
      "Loss =  tensor([27.0191])\n",
      "Loss =  tensor([26.9267])\n",
      "Loss =  tensor([26.7938])\n",
      "Loss =  tensor([27.1350])\n",
      "Loss =  tensor([25.3791])\n",
      "Loss =  tensor([26.8350])\n",
      "Loss =  tensor([25.1306])\n",
      "Loss =  tensor([25.8394])\n",
      "Loss =  tensor([26.9324])\n",
      "Loss =  tensor([25.6858])\n",
      "Loss =  tensor([26.2584])\n",
      "Loss =  tensor([27.5407])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Loss =  tensor([24.1943])\n",
      "Loss =  tensor([27.1690])\n",
      "Loss =  tensor([25.8154])\n",
      "Loss =  tensor([25.4771])\n",
      "Loss =  tensor([25.3516])\n",
      "Loss =  tensor([28.7951])\n",
      "Loss =  tensor([24.5760])\n",
      "Loss =  tensor([25.3562])\n",
      "Loss =  tensor([27.1986])\n",
      "Loss =  tensor([27.0202])\n",
      "Loss =  tensor([26.0009])\n",
      "Loss =  tensor([26.8345])\n",
      "Loss =  tensor([25.7897])\n",
      "Loss =  tensor([26.8852])\n",
      "Loss =  tensor([27.9526])\n",
      "Loss =  tensor([24.9977])\n",
      "Loss =  tensor([26.8782])\n",
      "Loss =  tensor([27.1115])\n",
      "Loss =  tensor([27.6116])\n",
      "Loss =  tensor([25.9404])\n",
      "Loss =  tensor([26.7392])\n",
      "Loss =  tensor([25.7941])\n",
      "Loss =  tensor([27.3377])\n",
      "Loss =  tensor([27.9458])\n",
      "Loss =  tensor([26.3514])\n",
      "Loss =  tensor([29.3056])\n",
      "Loss =  tensor([28.8105])\n",
      "Loss =  tensor([26.1459])\n",
      "Loss =  tensor([25.3879])\n",
      "Loss =  tensor([26.1874])\n",
      "Loss =  tensor([28.8771])\n",
      "Loss =  tensor([25.8868])\n",
      "Loss =  tensor([24.5065])\n",
      "Loss =  tensor([27.0527])\n",
      "Loss =  tensor([25.9303])\n",
      "Loss =  tensor([26.4762])\n",
      "Loss =  tensor([25.4117])\n",
      "Loss =  tensor([26.6705])\n",
      "Loss =  tensor([26.9289])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.68(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Loss =  tensor([25.8339])\n",
      "Loss =  tensor([25.6949])\n",
      "Loss =  tensor([27.4933])\n",
      "Loss =  tensor([25.9383])\n",
      "Loss =  tensor([28.1237])\n",
      "Loss =  tensor([26.5984])\n",
      "Loss =  tensor([24.9504])\n",
      "Loss =  tensor([24.8596])\n",
      "Loss =  tensor([25.8540])\n",
      "Loss =  tensor([24.9057])\n",
      "Loss =  tensor([24.4495])\n",
      "Loss =  tensor([26.3198])\n",
      "Loss =  tensor([26.5522])\n",
      "Loss =  tensor([26.2383])\n",
      "Loss =  tensor([26.3671])\n",
      "Loss =  tensor([26.2399])\n",
      "Loss =  tensor([25.4246])\n",
      "Loss =  tensor([28.5009])\n",
      "Loss =  tensor([24.3729])\n",
      "Loss =  tensor([26.2710])\n",
      "Loss =  tensor([30.7362])\n",
      "Loss =  tensor([26.2656])\n",
      "Loss =  tensor([25.8173])\n",
      "Loss =  tensor([25.8340])\n",
      "Loss =  tensor([26.3657])\n",
      "Loss =  tensor([26.9685])\n",
      "Loss =  tensor([28.7988])\n",
      "Loss =  tensor([26.1232])\n",
      "Loss =  tensor([29.7825])\n",
      "Loss =  tensor([30.9591])\n",
      "Loss =  tensor([28.3076])\n",
      "Loss =  tensor([27.8065])\n",
      "Loss =  tensor([26.1264])\n",
      "Loss =  tensor([26.3279])\n",
      "Loss =  tensor([27.5179])\n",
      "Loss =  tensor([29.8187])\n",
      "Loss =  tensor([28.3495])\n",
      "Loss =  tensor([26.2220])\n",
      "Loss =  tensor([27.2398])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.96)\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Loss =  tensor([24.6528])\n",
      "Loss =  tensor([25.6474])\n",
      "Loss =  tensor([26.7402])\n",
      "Loss =  tensor([25.4618])\n",
      "Loss =  tensor([29.6764])\n",
      "Loss =  tensor([30.2458])\n",
      "Loss =  tensor([28.2573])\n",
      "Loss =  tensor([27.4351])\n",
      "Loss =  tensor([24.7716])\n",
      "Loss =  tensor([26.2675])\n",
      "Loss =  tensor([28.0520])\n",
      "Loss =  tensor([28.2084])\n",
      "Loss =  tensor([24.9622])\n",
      "Loss =  tensor([28.0060])\n",
      "Loss =  tensor([24.4755])\n",
      "Loss =  tensor([29.8190])\n",
      "Loss =  tensor([28.7675])\n",
      "Loss =  tensor([26.4428])\n",
      "Loss =  tensor([25.8014])\n",
      "Loss =  tensor([26.5470])\n",
      "Loss =  tensor([25.3425])\n",
      "Loss =  tensor([25.5923])\n",
      "Loss =  tensor([25.3734])\n",
      "Loss =  tensor([24.2287])\n",
      "Loss =  tensor([25.2183])\n",
      "Loss =  tensor([26.8062])\n",
      "Loss =  tensor([24.8542])\n",
      "Loss =  tensor([26.9613])\n",
      "Loss =  tensor([28.6087])\n",
      "Loss =  tensor([28.4687])\n",
      "Loss =  tensor([24.0783])\n",
      "Loss =  tensor([25.7318])\n",
      "Loss =  tensor([26.5946])\n",
      "Loss =  tensor([27.6546])\n",
      "Loss =  tensor([26.8182])\n",
      "Loss =  tensor([27.3128])\n",
      "Loss =  tensor([26.8239])\n",
      "Loss =  tensor([27.2432])\n",
      "Loss =  tensor([26.1956])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.61(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.56, 0.91](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Loss =  tensor([27.1762])\n",
      "Loss =  tensor([28.3907])\n",
      "Loss =  tensor([27.6496])\n",
      "Loss =  tensor([24.8496])\n",
      "Loss =  tensor([27.1421])\n",
      "Loss =  tensor([27.2918])\n",
      "Loss =  tensor([25.4202])\n",
      "Loss =  tensor([26.8047])\n",
      "Loss =  tensor([27.7039])\n",
      "Loss =  tensor([24.3995])\n",
      "Loss =  tensor([26.5795])\n",
      "Loss =  tensor([25.4303])\n",
      "Loss =  tensor([26.2402])\n",
      "Loss =  tensor([26.3857])\n",
      "Loss =  tensor([25.0373])\n",
      "Loss =  tensor([27.2741])\n",
      "Loss =  tensor([28.1794])\n",
      "Loss =  tensor([26.6469])\n",
      "Loss =  tensor([24.3290])\n",
      "Loss =  tensor([25.0209])\n",
      "Loss =  tensor([27.2285])\n",
      "Loss =  tensor([24.6677])\n",
      "Loss =  tensor([26.4854])\n",
      "Loss =  tensor([29.4560])\n",
      "Loss =  tensor([25.8785])\n",
      "Loss =  tensor([28.6898])\n",
      "Loss =  tensor([27.5438])\n",
      "Loss =  tensor([26.7114])\n",
      "Loss =  tensor([26.2916])\n",
      "Loss =  tensor([28.4011])\n",
      "Loss =  tensor([27.9954])\n",
      "Loss =  tensor([29.2549])\n",
      "Loss =  tensor([27.0977])\n",
      "Loss =  tensor([26.6565])\n",
      "Loss =  tensor([24.2560])\n",
      "Loss =  tensor([28.6079])\n",
      "Loss =  tensor([27.8716])\n",
      "Loss =  tensor([26.9967])\n",
      "Loss =  tensor([26.0891])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.55, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.96](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Loss =  tensor([25.2548])\n",
      "Loss =  tensor([29.0342])\n",
      "Loss =  tensor([29.9687])\n",
      "Loss =  tensor([27.6113])\n",
      "Loss =  tensor([25.0604])\n",
      "Loss =  tensor([28.2891])\n",
      "Loss =  tensor([32.0149])\n",
      "Loss =  tensor([31.2596])\n",
      "Loss =  tensor([26.1004])\n",
      "Loss =  tensor([26.7451])\n",
      "Loss =  tensor([27.7946])\n",
      "Loss =  tensor([27.9350])\n",
      "Loss =  tensor([24.4219])\n",
      "Loss =  tensor([27.1277])\n",
      "Loss =  tensor([25.9862])\n",
      "Loss =  tensor([26.7574])\n",
      "Loss =  tensor([25.2517])\n",
      "Loss =  tensor([27.3216])\n",
      "Loss =  tensor([25.7383])\n",
      "Loss =  tensor([24.7764])\n",
      "Loss =  tensor([26.0799])\n",
      "Loss =  tensor([26.6768])\n",
      "Loss =  tensor([27.4494])\n",
      "Loss =  tensor([26.5646])\n",
      "Loss =  tensor([26.8086])\n",
      "Loss =  tensor([24.8573])\n",
      "Loss =  tensor([24.9408])\n",
      "Loss =  tensor([25.6880])\n",
      "Loss =  tensor([27.9596])\n",
      "Loss =  tensor([25.3552])\n",
      "Loss =  tensor([24.8980])\n",
      "Loss =  tensor([28.5005])\n",
      "Loss =  tensor([26.2659])\n",
      "Loss =  tensor([26.4092])\n",
      "Loss =  tensor([27.1367])\n",
      "Loss =  tensor([27.5269])\n",
      "Loss =  tensor([27.2266])\n",
      "Loss =  tensor([28.0409])\n",
      "Loss =  tensor([28.1706])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Loss =  tensor([24.8153])\n",
      "Loss =  tensor([26.6844])\n",
      "Loss =  tensor([32.6285])\n",
      "Loss =  tensor([34.2004])\n",
      "Loss =  tensor([26.6189])\n",
      "Loss =  tensor([26.7558])\n",
      "Loss =  tensor([27.5737])\n",
      "Loss =  tensor([29.2455])\n",
      "Loss =  tensor([25.9122])\n",
      "Loss =  tensor([24.5413])\n",
      "Loss =  tensor([29.0503])\n",
      "Loss =  tensor([27.7063])\n",
      "Loss =  tensor([25.1360])\n",
      "Loss =  tensor([26.9047])\n",
      "Loss =  tensor([28.0000])\n",
      "Loss =  tensor([26.8318])\n",
      "Loss =  tensor([25.0477])\n",
      "Loss =  tensor([31.0101])\n",
      "Loss =  tensor([32.2470])\n",
      "Loss =  tensor([33.2527])\n",
      "Loss =  tensor([29.8804])\n",
      "Loss =  tensor([26.2433])\n",
      "Loss =  tensor([28.3474])\n",
      "Loss =  tensor([32.1059])\n",
      "Loss =  tensor([29.4643])\n",
      "Loss =  tensor([29.2049])\n",
      "Loss =  tensor([25.6639])\n",
      "Loss =  tensor([27.1164])\n",
      "Loss =  tensor([29.0191])\n",
      "Loss =  tensor([32.0814])\n",
      "Loss =  tensor([26.2184])\n",
      "Loss =  tensor([26.1749])\n",
      "Loss =  tensor([25.8323])\n",
      "Loss =  tensor([25.5105])\n",
      "Loss =  tensor([26.2861])\n",
      "Loss =  tensor([23.8681])\n",
      "Loss =  tensor([26.9370])\n",
      "Loss =  tensor([25.5595])\n",
      "Loss =  tensor([26.1466])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.92(best:0.93)\n",
      "Training F1:[0.96, 0.95](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Loss =  tensor([24.9331])\n",
      "Loss =  tensor([25.9448])\n",
      "Loss =  tensor([25.2020])\n",
      "Loss =  tensor([23.6450])\n",
      "Loss =  tensor([25.3332])\n",
      "Loss =  tensor([26.2705])\n",
      "Loss =  tensor([25.9674])\n",
      "Loss =  tensor([25.9225])\n",
      "Loss =  tensor([24.8972])\n",
      "Loss =  tensor([26.5198])\n",
      "Loss =  tensor([26.6323])\n",
      "Loss =  tensor([28.2050])\n",
      "Loss =  tensor([30.4803])\n",
      "Loss =  tensor([26.9788])\n",
      "Loss =  tensor([27.1640])\n",
      "Loss =  tensor([28.3585])\n",
      "Loss =  tensor([26.3658])\n",
      "Loss =  tensor([25.9519])\n",
      "Loss =  tensor([25.9338])\n",
      "Loss =  tensor([25.9248])\n",
      "Loss =  tensor([24.0910])\n",
      "Loss =  tensor([26.2467])\n",
      "Loss =  tensor([25.6650])\n",
      "Loss =  tensor([25.9190])\n",
      "Loss =  tensor([25.6713])\n",
      "Loss =  tensor([26.3013])\n",
      "Loss =  tensor([26.9466])\n",
      "Loss =  tensor([26.2268])\n",
      "Loss =  tensor([24.4903])\n",
      "Loss =  tensor([26.7851])\n",
      "Loss =  tensor([24.7909])\n",
      "Loss =  tensor([24.9576])\n",
      "Loss =  tensor([25.1511])\n",
      "Loss =  tensor([25.8890])\n",
      "Loss =  tensor([25.4035])\n",
      "Loss =  tensor([26.6622])\n",
      "Loss =  tensor([26.6678])\n",
      "Loss =  tensor([26.7113])\n",
      "Loss =  tensor([28.2861])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.93)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Loss =  tensor([23.9055])\n",
      "Loss =  tensor([25.6669])\n",
      "Loss =  tensor([26.3828])\n",
      "Loss =  tensor([26.7550])\n",
      "Loss =  tensor([25.1180])\n",
      "Loss =  tensor([25.6418])\n",
      "Loss =  tensor([27.6841])\n",
      "Loss =  tensor([26.3906])\n",
      "Loss =  tensor([24.5014])\n",
      "Loss =  tensor([24.5515])\n",
      "Loss =  tensor([28.0329])\n",
      "Loss =  tensor([25.8479])\n",
      "Loss =  tensor([26.1144])\n",
      "Loss =  tensor([25.5539])\n",
      "Loss =  tensor([26.5270])\n",
      "Loss =  tensor([27.2937])\n",
      "Loss =  tensor([26.0614])\n",
      "Loss =  tensor([25.1072])\n",
      "Loss =  tensor([26.4078])\n",
      "Loss =  tensor([26.8643])\n",
      "Loss =  tensor([25.7781])\n",
      "Loss =  tensor([26.7464])\n",
      "Loss =  tensor([25.9682])\n",
      "Loss =  tensor([24.6822])\n",
      "Loss =  tensor([26.8557])\n",
      "Loss =  tensor([28.4482])\n",
      "Loss =  tensor([29.2936])\n",
      "Loss =  tensor([27.3349])\n",
      "Loss =  tensor([25.6527])\n",
      "Loss =  tensor([27.8625])\n",
      "Loss =  tensor([27.6637])\n",
      "Loss =  tensor([26.7294])\n",
      "Loss =  tensor([26.1693])\n",
      "Loss =  tensor([24.2935])\n",
      "Loss =  tensor([24.9613])\n",
      "Loss =  tensor([25.3015])\n",
      "Loss =  tensor([25.5453])\n",
      "Loss =  tensor([27.7747])\n",
      "Loss =  tensor([26.8493])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Loss =  tensor([25.0847])\n",
      "Loss =  tensor([24.7533])\n",
      "Loss =  tensor([27.2556])\n",
      "Loss =  tensor([26.1127])\n",
      "Loss =  tensor([27.2901])\n",
      "Loss =  tensor([25.8055])\n",
      "Loss =  tensor([26.0849])\n",
      "Loss =  tensor([24.9853])\n",
      "Loss =  tensor([26.6276])\n",
      "Loss =  tensor([23.9207])\n",
      "Loss =  tensor([25.5031])\n",
      "Loss =  tensor([25.5845])\n",
      "Loss =  tensor([25.8330])\n",
      "Loss =  tensor([24.7920])\n",
      "Loss =  tensor([25.6160])\n",
      "Loss =  tensor([24.5830])\n",
      "Loss =  tensor([28.1545])\n",
      "Loss =  tensor([28.5156])\n",
      "Loss =  tensor([26.4999])\n",
      "Loss =  tensor([26.1990])\n",
      "Loss =  tensor([27.9331])\n",
      "Loss =  tensor([27.0745])\n",
      "Loss =  tensor([26.0257])\n",
      "Loss =  tensor([25.2227])\n",
      "Loss =  tensor([30.1585])\n",
      "Loss =  tensor([28.4728])\n",
      "Loss =  tensor([25.8742])\n",
      "Loss =  tensor([27.0686])\n",
      "Loss =  tensor([30.1825])\n",
      "Loss =  tensor([30.5208])\n",
      "Loss =  tensor([25.6499])\n",
      "Loss =  tensor([26.7207])\n",
      "Loss =  tensor([27.9805])\n",
      "Loss =  tensor([27.1812])\n",
      "Loss =  tensor([25.6359])\n",
      "Loss =  tensor([25.8586])\n",
      "Loss =  tensor([26.2816])\n",
      "Loss =  tensor([26.0285])\n",
      "Loss =  tensor([25.9556])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Loss =  tensor([25.0273])\n",
      "Loss =  tensor([27.8300])\n",
      "Loss =  tensor([24.9020])\n",
      "Loss =  tensor([24.7518])\n",
      "Loss =  tensor([25.4793])\n",
      "Loss =  tensor([23.8788])\n",
      "Loss =  tensor([25.1724])\n",
      "Loss =  tensor([26.7424])\n",
      "Loss =  tensor([25.2094])\n",
      "Loss =  tensor([24.6717])\n",
      "Loss =  tensor([24.9308])\n",
      "Loss =  tensor([26.4423])\n",
      "Loss =  tensor([26.5000])\n",
      "Loss =  tensor([25.5691])\n",
      "Loss =  tensor([24.9201])\n",
      "Loss =  tensor([25.2238])\n",
      "Loss =  tensor([25.7077])\n",
      "Loss =  tensor([26.3759])\n",
      "Loss =  tensor([28.6658])\n",
      "Loss =  tensor([28.9419])\n",
      "Loss =  tensor([26.8396])\n",
      "Loss =  tensor([26.7500])\n",
      "Loss =  tensor([26.5611])\n",
      "Loss =  tensor([24.8715])\n",
      "Loss =  tensor([26.7826])\n",
      "Loss =  tensor([27.5390])\n",
      "Loss =  tensor([26.8003])\n",
      "Loss =  tensor([25.8606])\n",
      "Loss =  tensor([26.3643])\n",
      "Loss =  tensor([29.4537])\n",
      "Loss =  tensor([26.5862])\n",
      "Loss =  tensor([25.1640])\n",
      "Loss =  tensor([30.7407])\n",
      "Loss =  tensor([30.5149])\n",
      "Loss =  tensor([29.7016])\n",
      "Loss =  tensor([25.4126])\n",
      "Loss =  tensor([27.6548])\n",
      "Loss =  tensor([29.0802])\n",
      "Loss =  tensor([30.2386])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Loss =  tensor([23.5628])\n",
      "Loss =  tensor([27.2891])\n",
      "Loss =  tensor([23.2420])\n",
      "Loss =  tensor([24.1215])\n",
      "Loss =  tensor([26.2068])\n",
      "Loss =  tensor([26.3340])\n",
      "Loss =  tensor([29.9096])\n",
      "Loss =  tensor([33.5884])\n",
      "Loss =  tensor([27.5343])\n",
      "Loss =  tensor([27.5225])\n",
      "Loss =  tensor([27.4798])\n",
      "Loss =  tensor([26.2302])\n",
      "Loss =  tensor([29.4161])\n",
      "Loss =  tensor([26.1770])\n",
      "Loss =  tensor([24.7976])\n",
      "Loss =  tensor([25.6937])\n",
      "Loss =  tensor([27.2764])\n",
      "Loss =  tensor([25.5783])\n",
      "Loss =  tensor([28.7835])\n",
      "Loss =  tensor([29.6479])\n",
      "Loss =  tensor([29.2213])\n",
      "Loss =  tensor([26.2724])\n",
      "Loss =  tensor([25.9402])\n",
      "Loss =  tensor([25.7523])\n",
      "Loss =  tensor([26.2611])\n",
      "Loss =  tensor([27.2124])\n",
      "Loss =  tensor([27.4397])\n",
      "Loss =  tensor([24.6258])\n",
      "Loss =  tensor([26.7374])\n",
      "Loss =  tensor([27.8750])\n",
      "Loss =  tensor([26.4096])\n",
      "Loss =  tensor([25.5600])\n",
      "Loss =  tensor([25.7052])\n",
      "Loss =  tensor([26.3743])\n",
      "Loss =  tensor([24.9017])\n",
      "Loss =  tensor([25.2395])\n",
      "Loss =  tensor([29.9941])\n",
      "Loss =  tensor([27.6571])\n",
      "Loss =  tensor([27.6562])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.94)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Loss =  tensor([25.6498])\n",
      "Loss =  tensor([27.7598])\n",
      "Loss =  tensor([25.9429])\n",
      "Loss =  tensor([26.4073])\n",
      "Loss =  tensor([25.0420])\n",
      "Loss =  tensor([27.8840])\n",
      "Loss =  tensor([29.1792])\n",
      "Loss =  tensor([27.5513])\n",
      "Loss =  tensor([27.2678])\n",
      "Loss =  tensor([25.6931])\n",
      "Loss =  tensor([25.1550])\n",
      "Loss =  tensor([26.6199])\n",
      "Loss =  tensor([25.9745])\n",
      "Loss =  tensor([24.2851])\n",
      "Loss =  tensor([25.9008])\n",
      "Loss =  tensor([28.0190])\n",
      "Loss =  tensor([28.4488])\n",
      "Loss =  tensor([26.5661])\n",
      "Loss =  tensor([26.6368])\n",
      "Loss =  tensor([29.0494])\n",
      "Loss =  tensor([28.3208])\n",
      "Loss =  tensor([24.6589])\n",
      "Loss =  tensor([26.7949])\n",
      "Loss =  tensor([28.1305])\n",
      "Loss =  tensor([30.7733])\n",
      "Loss =  tensor([26.3966])\n",
      "Loss =  tensor([27.8663])\n",
      "Loss =  tensor([30.8258])\n",
      "Loss =  tensor([29.5850])\n",
      "Loss =  tensor([26.0864])\n",
      "Loss =  tensor([25.5819])\n",
      "Loss =  tensor([28.7452])\n",
      "Loss =  tensor([28.7172])\n",
      "Loss =  tensor([26.2885])\n",
      "Loss =  tensor([26.2623])\n",
      "Loss =  tensor([25.5074])\n",
      "Loss =  tensor([25.8680])\n",
      "Loss =  tensor([26.6957])\n",
      "Loss =  tensor([27.1219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.94)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 51\n",
      "Loss =  tensor([26.4323])\n",
      "Loss =  tensor([27.0197])\n",
      "Loss =  tensor([25.3585])\n",
      "Loss =  tensor([25.4497])\n",
      "Loss =  tensor([28.7230])\n",
      "Loss =  tensor([25.5366])\n",
      "Loss =  tensor([25.6248])\n",
      "Loss =  tensor([26.2623])\n",
      "Loss =  tensor([26.7440])\n",
      "Loss =  tensor([26.3966])\n",
      "Loss =  tensor([23.7841])\n",
      "Loss =  tensor([28.2543])\n",
      "Loss =  tensor([28.4751])\n",
      "Loss =  tensor([25.5023])\n",
      "Loss =  tensor([26.0810])\n",
      "Loss =  tensor([24.9678])\n",
      "Loss =  tensor([26.8710])\n",
      "Loss =  tensor([25.9559])\n",
      "Loss =  tensor([25.6667])\n",
      "Loss =  tensor([24.7264])\n",
      "Loss =  tensor([28.5005])\n",
      "Loss =  tensor([29.5279])\n",
      "Loss =  tensor([27.5318])\n",
      "Loss =  tensor([26.6435])\n",
      "Loss =  tensor([26.1269])\n",
      "Loss =  tensor([26.9586])\n",
      "Loss =  tensor([26.2092])\n",
      "Loss =  tensor([25.2236])\n",
      "Loss =  tensor([26.2991])\n",
      "Loss =  tensor([26.7728])\n",
      "Loss =  tensor([25.3853])\n",
      "Loss =  tensor([27.5840])\n",
      "Loss =  tensor([28.0995])\n",
      "Loss =  tensor([24.8909])\n",
      "Loss =  tensor([28.0949])\n",
      "Loss =  tensor([29.2765])\n",
      "Loss =  tensor([28.1983])\n",
      "Loss =  tensor([27.8334])\n",
      "Loss =  tensor([27.4951])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 52\n",
      "Loss =  tensor([26.2053])\n",
      "Loss =  tensor([24.1959])\n",
      "Loss =  tensor([24.3975])\n",
      "Loss =  tensor([25.6921])\n",
      "Loss =  tensor([26.1394])\n",
      "Loss =  tensor([25.0626])\n",
      "Loss =  tensor([24.4839])\n",
      "Loss =  tensor([23.7699])\n",
      "Loss =  tensor([25.4800])\n",
      "Loss =  tensor([24.6978])\n",
      "Loss =  tensor([26.4021])\n",
      "Loss =  tensor([23.8238])\n",
      "Loss =  tensor([26.6626])\n",
      "Loss =  tensor([26.2295])\n",
      "Loss =  tensor([26.0678])\n",
      "Loss =  tensor([24.9219])\n",
      "Loss =  tensor([26.1332])\n",
      "Loss =  tensor([25.1393])\n",
      "Loss =  tensor([24.9688])\n",
      "Loss =  tensor([26.7031])\n",
      "Loss =  tensor([26.2833])\n",
      "Loss =  tensor([25.4958])\n",
      "Loss =  tensor([25.6456])\n",
      "Loss =  tensor([25.1526])\n",
      "Loss =  tensor([25.1800])\n",
      "Loss =  tensor([24.8784])\n",
      "Loss =  tensor([26.4132])\n",
      "Loss =  tensor([27.4164])\n",
      "Loss =  tensor([26.0683])\n",
      "Loss =  tensor([28.1578])\n",
      "Loss =  tensor([27.7728])\n",
      "Loss =  tensor([28.4286])\n",
      "Loss =  tensor([25.6078])\n",
      "Loss =  tensor([25.7934])\n",
      "Loss =  tensor([28.9299])\n",
      "Loss =  tensor([25.9078])\n",
      "Loss =  tensor([24.7510])\n",
      "Loss =  tensor([27.8443])\n",
      "Loss =  tensor([27.5941])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.94)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 53\n",
      "Loss =  tensor([24.8878])\n",
      "Loss =  tensor([24.4929])\n",
      "Loss =  tensor([26.2401])\n",
      "Loss =  tensor([26.2509])\n",
      "Loss =  tensor([23.7770])\n",
      "Loss =  tensor([26.8673])\n",
      "Loss =  tensor([24.1244])\n",
      "Loss =  tensor([26.5838])\n",
      "Loss =  tensor([26.5546])\n",
      "Loss =  tensor([24.6220])\n",
      "Loss =  tensor([25.1109])\n",
      "Loss =  tensor([24.4137])\n",
      "Loss =  tensor([24.2419])\n",
      "Loss =  tensor([25.1884])\n",
      "Loss =  tensor([26.6552])\n",
      "Loss =  tensor([24.7345])\n",
      "Loss =  tensor([26.3164])\n",
      "Loss =  tensor([25.1158])\n",
      "Loss =  tensor([26.3950])\n",
      "Loss =  tensor([26.4812])\n",
      "Loss =  tensor([24.7101])\n",
      "Loss =  tensor([26.3117])\n",
      "Loss =  tensor([25.1863])\n",
      "Loss =  tensor([27.4617])\n",
      "Loss =  tensor([23.5838])\n",
      "Loss =  tensor([26.3993])\n",
      "Loss =  tensor([26.5334])\n",
      "Loss =  tensor([24.8771])\n",
      "Loss =  tensor([25.1185])\n",
      "Loss =  tensor([25.7763])\n",
      "Loss =  tensor([25.2314])\n",
      "Loss =  tensor([25.9716])\n",
      "Loss =  tensor([26.9023])\n",
      "Loss =  tensor([27.0376])\n",
      "Loss =  tensor([26.0431])\n",
      "Loss =  tensor([25.5974])\n",
      "Loss =  tensor([25.1254])\n",
      "Loss =  tensor([26.1608])\n",
      "Loss =  tensor([27.8207])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 54\n",
      "Loss =  tensor([25.2544])\n",
      "Loss =  tensor([24.5387])\n",
      "Loss =  tensor([23.5811])\n",
      "Loss =  tensor([25.0527])\n",
      "Loss =  tensor([26.3602])\n",
      "Loss =  tensor([25.4573])\n",
      "Loss =  tensor([25.6165])\n",
      "Loss =  tensor([26.5507])\n",
      "Loss =  tensor([26.7268])\n",
      "Loss =  tensor([28.9656])\n",
      "Loss =  tensor([27.0046])\n",
      "Loss =  tensor([25.9300])\n",
      "Loss =  tensor([27.6182])\n",
      "Loss =  tensor([25.3233])\n",
      "Loss =  tensor([27.0181])\n",
      "Loss =  tensor([26.4205])\n",
      "Loss =  tensor([31.0745])\n",
      "Loss =  tensor([34.4231])\n",
      "Loss =  tensor([34.8588])\n",
      "Loss =  tensor([30.0650])\n",
      "Loss =  tensor([26.3557])\n",
      "Loss =  tensor([29.3031])\n",
      "Loss =  tensor([32.1708])\n",
      "Loss =  tensor([30.1263])\n",
      "Loss =  tensor([28.9863])\n",
      "Loss =  tensor([26.7066])\n",
      "Loss =  tensor([28.6979])\n",
      "Loss =  tensor([31.0713])\n",
      "Loss =  tensor([32.8275])\n",
      "Loss =  tensor([31.7930])\n",
      "Loss =  tensor([25.6896])\n",
      "Loss =  tensor([27.4300])\n",
      "Loss =  tensor([30.5578])\n",
      "Loss =  tensor([29.6098])\n",
      "Loss =  tensor([27.0069])\n",
      "Loss =  tensor([27.7789])\n",
      "Loss =  tensor([27.6820])\n",
      "Loss =  tensor([28.5599])\n",
      "Loss =  tensor([27.9193])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.93(best:0.95)\n",
      "Training F1:[0.97, 0.96](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 55\n",
      "Loss =  tensor([24.2351])\n",
      "Loss =  tensor([27.8106])\n",
      "Loss =  tensor([28.2909])\n",
      "Loss =  tensor([28.3039])\n",
      "Loss =  tensor([26.2608])\n",
      "Loss =  tensor([26.9226])\n",
      "Loss =  tensor([29.5109])\n",
      "Loss =  tensor([28.3584])\n",
      "Loss =  tensor([25.9379])\n",
      "Loss =  tensor([26.1240])\n",
      "Loss =  tensor([27.3023])\n",
      "Loss =  tensor([26.9509])\n",
      "Loss =  tensor([24.6712])\n",
      "Loss =  tensor([28.2708])\n",
      "Loss =  tensor([28.5043])\n",
      "Loss =  tensor([28.5726])\n",
      "Loss =  tensor([27.6837])\n",
      "Loss =  tensor([26.1181])\n",
      "Loss =  tensor([28.1242])\n",
      "Loss =  tensor([28.6662])\n",
      "Loss =  tensor([25.5228])\n",
      "Loss =  tensor([25.0789])\n",
      "Loss =  tensor([27.4625])\n",
      "Loss =  tensor([30.1126])\n",
      "Loss =  tensor([32.1662])\n",
      "Loss =  tensor([28.6417])\n",
      "Loss =  tensor([24.6944])\n",
      "Loss =  tensor([25.1306])\n",
      "Loss =  tensor([26.7752])\n",
      "Loss =  tensor([27.6737])\n",
      "Loss =  tensor([25.8775])\n",
      "Loss =  tensor([26.9227])\n",
      "Loss =  tensor([29.5571])\n",
      "Loss =  tensor([27.7321])\n",
      "Loss =  tensor([26.0960])\n",
      "Loss =  tensor([24.6340])\n",
      "Loss =  tensor([25.8046])\n",
      "Loss =  tensor([28.4510])\n",
      "Loss =  tensor([25.8992])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:12\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.48, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.95)\n",
      "Training F1:[0.96, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 56\n",
      "Loss =  tensor([26.2043])\n",
      "Loss =  tensor([26.4337])\n",
      "Loss =  tensor([27.7904])\n",
      "Loss =  tensor([25.5594])\n",
      "Loss =  tensor([27.4765])\n",
      "Loss =  tensor([26.4522])\n",
      "Loss =  tensor([26.6578])\n",
      "Loss =  tensor([28.4368])\n",
      "Loss =  tensor([25.5087])\n",
      "Loss =  tensor([25.7361])\n",
      "Loss =  tensor([25.3671])\n",
      "Loss =  tensor([27.5391])\n",
      "Loss =  tensor([25.5287])\n",
      "Loss =  tensor([26.8463])\n",
      "Loss =  tensor([26.9190])\n",
      "Loss =  tensor([28.6923])\n",
      "Loss =  tensor([25.1310])\n",
      "Loss =  tensor([25.4345])\n",
      "Loss =  tensor([25.8504])\n",
      "Loss =  tensor([25.1864])\n",
      "Loss =  tensor([25.0270])\n",
      "Loss =  tensor([26.7455])\n",
      "Loss =  tensor([27.0438])\n",
      "Loss =  tensor([27.1077])\n",
      "Loss =  tensor([26.4928])\n",
      "Loss =  tensor([27.4158])\n",
      "Loss =  tensor([28.7026])\n",
      "Loss =  tensor([26.3493])\n",
      "Loss =  tensor([28.0842])\n",
      "Loss =  tensor([25.4665])\n",
      "Loss =  tensor([27.4701])\n",
      "Loss =  tensor([29.8113])\n",
      "Loss =  tensor([25.9054])\n",
      "Loss =  tensor([26.7042])\n",
      "Loss =  tensor([25.9200])\n",
      "Loss =  tensor([25.7439])\n",
      "Loss =  tensor([25.3620])\n",
      "Loss =  tensor([24.5730])\n",
      "Loss =  tensor([24.4238])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:13\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 57\n",
      "Loss =  tensor([25.2076])\n",
      "Loss =  tensor([24.6321])\n",
      "Loss =  tensor([25.2482])\n",
      "Loss =  tensor([24.5035])\n",
      "Loss =  tensor([25.9740])\n",
      "Loss =  tensor([24.6469])\n",
      "Loss =  tensor([25.8651])\n",
      "Loss =  tensor([25.4737])\n",
      "Loss =  tensor([24.8108])\n",
      "Loss =  tensor([25.2183])\n",
      "Loss =  tensor([26.7698])\n",
      "Loss =  tensor([25.6841])\n",
      "Loss =  tensor([25.2594])\n",
      "Loss =  tensor([24.3002])\n",
      "Loss =  tensor([26.1554])\n",
      "Loss =  tensor([25.3326])\n",
      "Loss =  tensor([25.4778])\n",
      "Loss =  tensor([25.8304])\n",
      "Loss =  tensor([26.3845])\n",
      "Loss =  tensor([24.9297])\n",
      "Loss =  tensor([26.9475])\n",
      "Loss =  tensor([25.1523])\n",
      "Loss =  tensor([27.8829])\n",
      "Loss =  tensor([25.5170])\n",
      "Loss =  tensor([25.1277])\n",
      "Loss =  tensor([26.0093])\n",
      "Loss =  tensor([24.9433])\n",
      "Loss =  tensor([26.4907])\n",
      "Loss =  tensor([25.3731])\n",
      "Loss =  tensor([25.7800])\n",
      "Loss =  tensor([27.0121])\n",
      "Loss =  tensor([26.1183])\n",
      "Loss =  tensor([24.8315])\n",
      "Loss =  tensor([25.1117])\n",
      "Loss =  tensor([27.9715])\n",
      "Loss =  tensor([27.5712])\n",
      "Loss =  tensor([27.0549])\n",
      "Loss =  tensor([26.5220])\n",
      "Loss =  tensor([28.5585])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.94(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 58\n",
      "Loss =  tensor([24.8115])\n",
      "Loss =  tensor([26.4092])\n",
      "Loss =  tensor([24.6460])\n",
      "Loss =  tensor([24.6099])\n",
      "Loss =  tensor([24.5722])\n",
      "Loss =  tensor([25.7716])\n",
      "Loss =  tensor([25.0655])\n",
      "Loss =  tensor([26.4642])\n",
      "Loss =  tensor([25.4451])\n",
      "Loss =  tensor([25.5911])\n",
      "Loss =  tensor([27.0586])\n",
      "Loss =  tensor([26.0219])\n",
      "Loss =  tensor([24.9742])\n",
      "Loss =  tensor([25.1384])\n",
      "Loss =  tensor([25.2485])\n",
      "Loss =  tensor([25.8322])\n",
      "Loss =  tensor([25.5574])\n",
      "Loss =  tensor([26.1553])\n",
      "Loss =  tensor([27.9613])\n",
      "Loss =  tensor([25.8230])\n",
      "Loss =  tensor([26.2243])\n",
      "Loss =  tensor([25.3917])\n",
      "Loss =  tensor([28.1115])\n",
      "Loss =  tensor([28.0716])\n",
      "Loss =  tensor([23.8703])\n",
      "Loss =  tensor([27.0209])\n",
      "Loss =  tensor([33.8672])\n",
      "Loss =  tensor([33.9909])\n",
      "Loss =  tensor([28.2192])\n",
      "Loss =  tensor([26.2415])\n",
      "Loss =  tensor([31.0720])\n",
      "Loss =  tensor([33.8880])\n",
      "Loss =  tensor([32.1952])\n",
      "Loss =  tensor([29.4481])\n",
      "Loss =  tensor([27.4047])\n",
      "Loss =  tensor([26.1917])\n",
      "Loss =  tensor([25.2070])\n",
      "Loss =  tensor([30.3022])\n",
      "Loss =  tensor([27.7716])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.97)\n",
      "\n",
      "\n",
      "Epoch 59\n",
      "Loss =  tensor([25.2280])\n",
      "Loss =  tensor([25.2576])\n",
      "Loss =  tensor([25.1001])\n",
      "Loss =  tensor([26.7496])\n",
      "Loss =  tensor([25.1161])\n",
      "Loss =  tensor([25.5913])\n",
      "Loss =  tensor([26.4532])\n",
      "Loss =  tensor([23.6560])\n",
      "Loss =  tensor([25.9679])\n",
      "Loss =  tensor([25.2293])\n",
      "Loss =  tensor([24.1899])\n",
      "Loss =  tensor([26.7666])\n",
      "Loss =  tensor([26.1628])\n",
      "Loss =  tensor([26.1126])\n",
      "Loss =  tensor([27.4314])\n",
      "Loss =  tensor([24.7281])\n",
      "Loss =  tensor([26.7353])\n",
      "Loss =  tensor([24.7800])\n",
      "Loss =  tensor([24.9092])\n",
      "Loss =  tensor([26.0514])\n",
      "Loss =  tensor([26.1043])\n",
      "Loss =  tensor([24.9583])\n",
      "Loss =  tensor([24.6238])\n",
      "Loss =  tensor([25.1051])\n",
      "Loss =  tensor([25.1970])\n",
      "Loss =  tensor([26.8723])\n",
      "Loss =  tensor([25.6217])\n",
      "Loss =  tensor([25.4934])\n",
      "Loss =  tensor([25.3567])\n",
      "Loss =  tensor([24.5179])\n",
      "Loss =  tensor([25.6002])\n",
      "Loss =  tensor([24.2927])\n",
      "Loss =  tensor([27.2417])\n",
      "Loss =  tensor([24.6605])\n",
      "Loss =  tensor([25.3497])\n",
      "Loss =  tensor([26.9081])\n",
      "Loss =  tensor([26.4118])\n",
      "Loss =  tensor([24.2562])\n",
      "Loss =  tensor([24.7852])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.98](best:0.97 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 60\n",
      "Loss =  tensor([24.5538])\n",
      "Loss =  tensor([25.0071])\n",
      "Loss =  tensor([24.7559])\n",
      "Loss =  tensor([24.4649])\n",
      "Loss =  tensor([26.6691])\n",
      "Loss =  tensor([25.1759])\n",
      "Loss =  tensor([25.3054])\n",
      "Loss =  tensor([26.6207])\n",
      "Loss =  tensor([26.9817])\n",
      "Loss =  tensor([26.7752])\n",
      "Loss =  tensor([27.1569])\n",
      "Loss =  tensor([26.2079])\n",
      "Loss =  tensor([23.8016])\n",
      "Loss =  tensor([25.7057])\n",
      "Loss =  tensor([28.1543])\n",
      "Loss =  tensor([26.0051])\n",
      "Loss =  tensor([24.6526])\n",
      "Loss =  tensor([26.5408])\n",
      "Loss =  tensor([26.7838])\n",
      "Loss =  tensor([26.2791])\n",
      "Loss =  tensor([26.2611])\n",
      "Loss =  tensor([25.1759])\n",
      "Loss =  tensor([26.6959])\n",
      "Loss =  tensor([26.1402])\n",
      "Loss =  tensor([24.7788])\n",
      "Loss =  tensor([24.7588])\n",
      "Loss =  tensor([26.2971])\n",
      "Loss =  tensor([28.4500])\n",
      "Loss =  tensor([25.0309])\n",
      "Loss =  tensor([25.9847])\n",
      "Loss =  tensor([26.8535])\n",
      "Loss =  tensor([26.0354])\n",
      "Loss =  tensor([25.6870])\n",
      "Loss =  tensor([25.4482])\n",
      "Loss =  tensor([25.8189])\n",
      "Loss =  tensor([25.5402])\n",
      "Loss =  tensor([26.5887])\n",
      "Loss =  tensor([26.0120])\n",
      "Loss =  tensor([26.1474])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.97](best:0.97 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 61\n",
      "Loss =  tensor([26.7180])\n",
      "Loss =  tensor([25.5601])\n",
      "Loss =  tensor([23.2675])\n",
      "Loss =  tensor([25.4497])\n",
      "Loss =  tensor([25.7476])\n",
      "Loss =  tensor([26.0896])\n",
      "Loss =  tensor([25.1613])\n",
      "Loss =  tensor([25.7803])\n",
      "Loss =  tensor([23.8138])\n",
      "Loss =  tensor([25.4013])\n",
      "Loss =  tensor([23.7882])\n",
      "Loss =  tensor([26.4504])\n",
      "Loss =  tensor([27.7347])\n",
      "Loss =  tensor([24.2369])\n",
      "Loss =  tensor([24.8530])\n",
      "Loss =  tensor([26.2356])\n",
      "Loss =  tensor([25.8198])\n",
      "Loss =  tensor([26.5113])\n",
      "Loss =  tensor([24.8722])\n",
      "Loss =  tensor([26.5457])\n",
      "Loss =  tensor([27.2615])\n",
      "Loss =  tensor([26.3969])\n",
      "Loss =  tensor([29.4647])\n",
      "Loss =  tensor([26.7139])\n",
      "Loss =  tensor([25.1902])\n",
      "Loss =  tensor([25.1586])\n",
      "Loss =  tensor([26.5057])\n",
      "Loss =  tensor([25.9164])\n",
      "Loss =  tensor([25.2321])\n",
      "Loss =  tensor([25.1408])\n",
      "Loss =  tensor([24.6014])\n",
      "Loss =  tensor([26.9857])\n",
      "Loss =  tensor([28.9885])\n",
      "Loss =  tensor([26.4260])\n",
      "Loss =  tensor([27.2194])\n",
      "Loss =  tensor([25.3585])\n",
      "Loss =  tensor([29.5774])\n",
      "Loss =  tensor([25.1815])\n",
      "Loss =  tensor([25.0444])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.48, 0.89](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.66(best:0.66)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.98](best:0.97 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 62\n",
      "Loss =  tensor([23.5439])\n",
      "Loss =  tensor([26.1113])\n",
      "Loss =  tensor([24.8044])\n",
      "Loss =  tensor([24.2524])\n",
      "Loss =  tensor([25.1885])\n",
      "Loss =  tensor([24.6961])\n",
      "Loss =  tensor([22.9375])\n",
      "Loss =  tensor([25.2652])\n",
      "Loss =  tensor([23.6871])\n",
      "Loss =  tensor([25.7321])\n",
      "Loss =  tensor([24.9456])\n",
      "Loss =  tensor([27.6606])\n",
      "Loss =  tensor([24.9303])\n",
      "Loss =  tensor([24.8838])\n",
      "Loss =  tensor([25.1827])\n",
      "Loss =  tensor([25.1132])\n",
      "Loss =  tensor([26.0763])\n",
      "Loss =  tensor([23.2700])\n",
      "Loss =  tensor([25.5748])\n",
      "Loss =  tensor([23.4225])\n",
      "Loss =  tensor([26.3199])\n",
      "Loss =  tensor([25.2407])\n",
      "Loss =  tensor([26.1539])\n",
      "Loss =  tensor([24.6252])\n",
      "Loss =  tensor([26.5788])\n",
      "Loss =  tensor([25.7406])\n",
      "Loss =  tensor([27.0778])\n",
      "Loss =  tensor([23.7938])\n",
      "Loss =  tensor([24.4018])\n",
      "Loss =  tensor([24.9043])\n",
      "Loss =  tensor([27.8330])\n",
      "Loss =  tensor([24.3803])\n",
      "Loss =  tensor([26.3670])\n",
      "Loss =  tensor([25.3948])\n",
      "Loss =  tensor([24.8739])\n",
      "Loss =  tensor([27.4371])\n",
      "Loss =  tensor([24.5769])\n",
      "Loss =  tensor([28.0255])\n",
      "Loss =  tensor([26.7001])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.98](best:0.97 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 63\n",
      "Loss =  tensor([23.3998])\n",
      "Loss =  tensor([25.4532])\n",
      "Loss =  tensor([23.5745])\n",
      "Loss =  tensor([26.2310])\n",
      "Loss =  tensor([27.4597])\n",
      "Loss =  tensor([27.0048])\n",
      "Loss =  tensor([24.6258])\n",
      "Loss =  tensor([27.9255])\n",
      "Loss =  tensor([27.8641])\n",
      "Loss =  tensor([26.5779])\n",
      "Loss =  tensor([25.4128])\n",
      "Loss =  tensor([27.2459])\n",
      "Loss =  tensor([26.1185])\n",
      "Loss =  tensor([24.9714])\n",
      "Loss =  tensor([24.3562])\n",
      "Loss =  tensor([24.1892])\n",
      "Loss =  tensor([24.7773])\n",
      "Loss =  tensor([25.5898])\n",
      "Loss =  tensor([25.7066])\n",
      "Loss =  tensor([23.8919])\n",
      "Loss =  tensor([25.7123])\n",
      "Loss =  tensor([24.4875])\n",
      "Loss =  tensor([25.0221])\n",
      "Loss =  tensor([24.8043])\n",
      "Loss =  tensor([26.7575])\n",
      "Loss =  tensor([28.9650])\n",
      "Loss =  tensor([29.5349])\n",
      "Loss =  tensor([26.3861])\n",
      "Loss =  tensor([23.7450])\n",
      "Loss =  tensor([26.4935])\n",
      "Loss =  tensor([29.0624])\n",
      "Loss =  tensor([25.2448])\n",
      "Loss =  tensor([23.4419])\n",
      "Loss =  tensor([25.5748])\n",
      "Loss =  tensor([25.3120])\n",
      "Loss =  tensor([27.4207])\n",
      "Loss =  tensor([27.4590])\n",
      "Loss =  tensor([27.2563])\n",
      "Loss =  tensor([24.1587])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.98](best:0.97 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 64\n",
      "Loss =  tensor([24.0138])\n",
      "Loss =  tensor([27.3841])\n",
      "Loss =  tensor([25.3763])\n",
      "Loss =  tensor([25.8373])\n",
      "Loss =  tensor([25.3250])\n",
      "Loss =  tensor([24.4083])\n",
      "Loss =  tensor([23.6060])\n",
      "Loss =  tensor([24.9262])\n",
      "Loss =  tensor([24.4421])\n",
      "Loss =  tensor([24.6418])\n",
      "Loss =  tensor([25.7549])\n",
      "Loss =  tensor([26.9807])\n",
      "Loss =  tensor([26.1910])\n",
      "Loss =  tensor([24.7745])\n",
      "Loss =  tensor([23.7007])\n",
      "Loss =  tensor([24.1392])\n",
      "Loss =  tensor([26.5991])\n",
      "Loss =  tensor([23.4707])\n",
      "Loss =  tensor([25.5530])\n",
      "Loss =  tensor([27.2882])\n",
      "Loss =  tensor([24.7866])\n",
      "Loss =  tensor([25.6435])\n",
      "Loss =  tensor([26.9940])\n",
      "Loss =  tensor([26.3911])\n",
      "Loss =  tensor([26.3890])\n",
      "Loss =  tensor([26.6034])\n",
      "Loss =  tensor([25.3951])\n",
      "Loss =  tensor([25.7779])\n",
      "Loss =  tensor([25.8934])\n",
      "Loss =  tensor([25.6001])\n",
      "Loss =  tensor([25.1758])\n",
      "Loss =  tensor([25.8986])\n",
      "Loss =  tensor([25.7715])\n",
      "Loss =  tensor([25.4303])\n",
      "Loss =  tensor([27.4575])\n",
      "Loss =  tensor([26.9267])\n",
      "Loss =  tensor([27.1767])\n",
      "Loss =  tensor([26.8960])\n",
      "Loss =  tensor([23.2126])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.95)\n",
      "Training F1:[0.97, 0.98](best:0.97 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 65\n",
      "Loss =  tensor([26.2823])\n",
      "Loss =  tensor([25.2748])\n",
      "Loss =  tensor([26.8589])\n",
      "Loss =  tensor([25.1127])\n",
      "Loss =  tensor([23.9492])\n",
      "Loss =  tensor([25.2698])\n",
      "Loss =  tensor([23.7706])\n",
      "Loss =  tensor([23.7970])\n",
      "Loss =  tensor([23.9661])\n",
      "Loss =  tensor([25.3746])\n",
      "Loss =  tensor([25.2117])\n",
      "Loss =  tensor([23.6439])\n",
      "Loss =  tensor([26.9638])\n",
      "Loss =  tensor([25.4531])\n",
      "Loss =  tensor([26.5035])\n",
      "Loss =  tensor([25.1546])\n",
      "Loss =  tensor([24.7031])\n",
      "Loss =  tensor([25.5605])\n",
      "Loss =  tensor([24.2107])\n",
      "Loss =  tensor([26.1609])\n",
      "Loss =  tensor([24.9043])\n",
      "Loss =  tensor([28.3644])\n",
      "Loss =  tensor([27.0641])\n",
      "Loss =  tensor([24.8074])\n",
      "Loss =  tensor([25.3966])\n",
      "Loss =  tensor([25.5904])\n",
      "Loss =  tensor([24.3546])\n",
      "Loss =  tensor([26.6699])\n",
      "Loss =  tensor([26.5914])\n",
      "Loss =  tensor([26.1834])\n",
      "Loss =  tensor([24.7011])\n",
      "Loss =  tensor([25.8434])\n",
      "Loss =  tensor([27.8127])\n",
      "Loss =  tensor([25.9474])\n",
      "Loss =  tensor([26.7211])\n",
      "Loss =  tensor([25.3857])\n",
      "Loss =  tensor([26.3396])\n",
      "Loss =  tensor([25.5850])\n",
      "Loss =  tensor([25.8294])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:12:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 66\n",
      "Loss =  tensor([24.8865])\n",
      "Loss =  tensor([24.6664])\n",
      "Loss =  tensor([24.8408])\n",
      "Loss =  tensor([26.7314])\n",
      "Loss =  tensor([27.4093])\n",
      "Loss =  tensor([25.7095])\n",
      "Loss =  tensor([23.9311])\n",
      "Loss =  tensor([25.4664])\n",
      "Loss =  tensor([24.5033])\n",
      "Loss =  tensor([23.6193])\n",
      "Loss =  tensor([24.4653])\n",
      "Loss =  tensor([25.6069])\n",
      "Loss =  tensor([24.1527])\n",
      "Loss =  tensor([26.0256])\n",
      "Loss =  tensor([24.0902])\n",
      "Loss =  tensor([26.7907])\n",
      "Loss =  tensor([25.4102])\n",
      "Loss =  tensor([24.8185])\n",
      "Loss =  tensor([24.1362])\n",
      "Loss =  tensor([26.0523])\n",
      "Loss =  tensor([26.5200])\n",
      "Loss =  tensor([25.9887])\n",
      "Loss =  tensor([26.0366])\n",
      "Loss =  tensor([28.9717])\n",
      "Loss =  tensor([25.3930])\n",
      "Loss =  tensor([25.0947])\n",
      "Loss =  tensor([29.1389])\n",
      "Loss =  tensor([30.5131])\n",
      "Loss =  tensor([31.9063])\n",
      "Loss =  tensor([28.5311])\n",
      "Loss =  tensor([27.3092])\n",
      "Loss =  tensor([30.4421])\n",
      "Loss =  tensor([29.4389])\n",
      "Loss =  tensor([25.1286])\n",
      "Loss =  tensor([25.2424])\n",
      "Loss =  tensor([26.1447])\n",
      "Loss =  tensor([26.2772])\n",
      "Loss =  tensor([26.0498])\n",
      "Loss =  tensor([26.5666])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.96)\n",
      "Training F1:[0.97, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 67\n",
      "Loss =  tensor([24.6096])\n",
      "Loss =  tensor([26.9739])\n",
      "Loss =  tensor([25.8703])\n",
      "Loss =  tensor([23.5727])\n",
      "Loss =  tensor([26.1355])\n",
      "Loss =  tensor([27.5512])\n",
      "Loss =  tensor([25.0646])\n",
      "Loss =  tensor([24.0418])\n",
      "Loss =  tensor([24.0273])\n",
      "Loss =  tensor([25.3692])\n",
      "Loss =  tensor([24.5223])\n",
      "Loss =  tensor([24.2989])\n",
      "Loss =  tensor([23.1507])\n",
      "Loss =  tensor([26.2597])\n",
      "Loss =  tensor([25.5811])\n",
      "Loss =  tensor([25.6054])\n",
      "Loss =  tensor([27.1546])\n",
      "Loss =  tensor([27.2175])\n",
      "Loss =  tensor([23.6856])\n",
      "Loss =  tensor([26.9721])\n",
      "Loss =  tensor([27.3923])\n",
      "Loss =  tensor([26.2971])\n",
      "Loss =  tensor([26.1493])\n",
      "Loss =  tensor([27.7633])\n",
      "Loss =  tensor([28.5457])\n",
      "Loss =  tensor([25.4267])\n",
      "Loss =  tensor([24.8072])\n",
      "Loss =  tensor([25.3084])\n",
      "Loss =  tensor([27.2484])\n",
      "Loss =  tensor([25.4278])\n",
      "Loss =  tensor([23.7975])\n",
      "Loss =  tensor([27.5667])\n",
      "Loss =  tensor([27.9619])\n",
      "Loss =  tensor([27.9613])\n",
      "Loss =  tensor([25.0334])\n",
      "Loss =  tensor([25.8957])\n",
      "Loss =  tensor([28.1798])\n",
      "Loss =  tensor([27.7331])\n",
      "Loss =  tensor([26.1654])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:43\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.49, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.96)\n",
      "Training F1:[0.97, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 68\n",
      "Loss =  tensor([25.8377])\n",
      "Loss =  tensor([31.5810])\n",
      "Loss =  tensor([34.1068])\n",
      "Loss =  tensor([34.4236])\n",
      "Loss =  tensor([30.5206])\n",
      "Loss =  tensor([27.2117])\n",
      "Loss =  tensor([27.6107])\n",
      "Loss =  tensor([29.4800])\n",
      "Loss =  tensor([33.8306])\n",
      "Loss =  tensor([30.1757])\n",
      "Loss =  tensor([26.2599])\n",
      "Loss =  tensor([25.9742])\n",
      "Loss =  tensor([30.1670])\n",
      "Loss =  tensor([26.9538])\n",
      "Loss =  tensor([26.4683])\n",
      "Loss =  tensor([25.8855])\n",
      "Loss =  tensor([26.0612])\n",
      "Loss =  tensor([26.3054])\n",
      "Loss =  tensor([26.0612])\n",
      "Loss =  tensor([27.0625])\n",
      "Loss =  tensor([23.0845])\n",
      "Loss =  tensor([26.1162])\n",
      "Loss =  tensor([24.0078])\n",
      "Loss =  tensor([25.9545])\n",
      "Loss =  tensor([25.4516])\n",
      "Loss =  tensor([24.4826])\n",
      "Loss =  tensor([23.9609])\n",
      "Loss =  tensor([22.9758])\n",
      "Loss =  tensor([24.8334])\n",
      "Loss =  tensor([25.5811])\n",
      "Loss =  tensor([24.5519])\n",
      "Loss =  tensor([25.5721])\n",
      "Loss =  tensor([25.2670])\n",
      "Loss =  tensor([25.0519])\n",
      "Loss =  tensor([26.4220])\n",
      "Loss =  tensor([25.1555])\n",
      "Loss =  tensor([26.7653])\n",
      "Loss =  tensor([24.1029])\n",
      "Loss =  tensor([25.2384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:12\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.49, 0.89](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 69\n",
      "Loss =  tensor([23.7170])\n",
      "Loss =  tensor([25.3584])\n",
      "Loss =  tensor([25.6074])\n",
      "Loss =  tensor([25.0171])\n",
      "Loss =  tensor([26.2818])\n",
      "Loss =  tensor([26.2166])\n",
      "Loss =  tensor([25.9268])\n",
      "Loss =  tensor([25.9327])\n",
      "Loss =  tensor([24.1690])\n",
      "Loss =  tensor([24.0714])\n",
      "Loss =  tensor([25.3974])\n",
      "Loss =  tensor([24.8568])\n",
      "Loss =  tensor([25.5555])\n",
      "Loss =  tensor([24.5177])\n",
      "Loss =  tensor([24.4823])\n",
      "Loss =  tensor([28.4260])\n",
      "Loss =  tensor([25.8013])\n",
      "Loss =  tensor([26.2172])\n",
      "Loss =  tensor([24.2185])\n",
      "Loss =  tensor([24.1700])\n",
      "Loss =  tensor([23.9428])\n",
      "Loss =  tensor([24.7189])\n",
      "Loss =  tensor([24.9904])\n",
      "Loss =  tensor([25.4656])\n",
      "Loss =  tensor([25.1989])\n",
      "Loss =  tensor([23.6536])\n",
      "Loss =  tensor([25.9615])\n",
      "Loss =  tensor([25.2015])\n",
      "Loss =  tensor([25.2621])\n",
      "Loss =  tensor([25.6492])\n",
      "Loss =  tensor([25.5851])\n",
      "Loss =  tensor([25.8832])\n",
      "Loss =  tensor([24.0102])\n",
      "Loss =  tensor([25.6068])\n",
      "Loss =  tensor([25.2985])\n",
      "Loss =  tensor([25.4534])\n",
      "Loss =  tensor([26.8260])\n",
      "Loss =  tensor([28.3353])\n",
      "Loss =  tensor([25.2283])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 70\n",
      "Loss =  tensor([23.9139])\n",
      "Loss =  tensor([26.4605])\n",
      "Loss =  tensor([27.8240])\n",
      "Loss =  tensor([26.6598])\n",
      "Loss =  tensor([24.1317])\n",
      "Loss =  tensor([28.0011])\n",
      "Loss =  tensor([26.4925])\n",
      "Loss =  tensor([25.3025])\n",
      "Loss =  tensor([23.6106])\n",
      "Loss =  tensor([25.2319])\n",
      "Loss =  tensor([24.2958])\n",
      "Loss =  tensor([25.0973])\n",
      "Loss =  tensor([25.2335])\n",
      "Loss =  tensor([26.6813])\n",
      "Loss =  tensor([24.3512])\n",
      "Loss =  tensor([25.1834])\n",
      "Loss =  tensor([24.9724])\n",
      "Loss =  tensor([24.5236])\n",
      "Loss =  tensor([24.2166])\n",
      "Loss =  tensor([25.1677])\n",
      "Loss =  tensor([24.9757])\n",
      "Loss =  tensor([24.5169])\n",
      "Loss =  tensor([25.2745])\n",
      "Loss =  tensor([26.3297])\n",
      "Loss =  tensor([24.0558])\n",
      "Loss =  tensor([27.2021])\n",
      "Loss =  tensor([27.3451])\n",
      "Loss =  tensor([25.7147])\n",
      "Loss =  tensor([24.8984])\n",
      "Loss =  tensor([24.3444])\n",
      "Loss =  tensor([24.9292])\n",
      "Loss =  tensor([24.4791])\n",
      "Loss =  tensor([26.4973])\n",
      "Loss =  tensor([24.9889])\n",
      "Loss =  tensor([25.5521])\n",
      "Loss =  tensor([24.2313])\n",
      "Loss =  tensor([25.1495])\n",
      "Loss =  tensor([27.0021])\n",
      "Loss =  tensor([24.5669])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 71\n",
      "Loss =  tensor([23.5221])\n",
      "Loss =  tensor([25.0466])\n",
      "Loss =  tensor([23.6526])\n",
      "Loss =  tensor([24.4135])\n",
      "Loss =  tensor([26.2876])\n",
      "Loss =  tensor([23.7513])\n",
      "Loss =  tensor([25.5184])\n",
      "Loss =  tensor([23.8397])\n",
      "Loss =  tensor([24.3013])\n",
      "Loss =  tensor([24.9048])\n",
      "Loss =  tensor([24.8122])\n",
      "Loss =  tensor([22.9995])\n",
      "Loss =  tensor([25.6374])\n",
      "Loss =  tensor([24.7921])\n",
      "Loss =  tensor([25.5361])\n",
      "Loss =  tensor([26.6411])\n",
      "Loss =  tensor([23.8579])\n",
      "Loss =  tensor([25.3820])\n",
      "Loss =  tensor([27.1593])\n",
      "Loss =  tensor([26.3411])\n",
      "Loss =  tensor([27.2847])\n",
      "Loss =  tensor([28.4796])\n",
      "Loss =  tensor([27.7429])\n",
      "Loss =  tensor([24.0727])\n",
      "Loss =  tensor([28.4616])\n",
      "Loss =  tensor([30.4004])\n",
      "Loss =  tensor([29.1520])\n",
      "Loss =  tensor([26.3070])\n",
      "Loss =  tensor([25.1004])\n",
      "Loss =  tensor([27.7651])\n",
      "Loss =  tensor([28.0585])\n",
      "Loss =  tensor([25.1301])\n",
      "Loss =  tensor([27.5387])\n",
      "Loss =  tensor([29.2131])\n",
      "Loss =  tensor([26.8364])\n",
      "Loss =  tensor([26.1894])\n",
      "Loss =  tensor([26.0399])\n",
      "Loss =  tensor([24.1961])\n",
      "Loss =  tensor([26.0280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.59(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 72\n",
      "Loss =  tensor([23.7344])\n",
      "Loss =  tensor([28.2998])\n",
      "Loss =  tensor([26.8945])\n",
      "Loss =  tensor([25.3518])\n",
      "Loss =  tensor([25.6282])\n",
      "Loss =  tensor([28.5261])\n",
      "Loss =  tensor([28.1849])\n",
      "Loss =  tensor([30.0225])\n",
      "Loss =  tensor([25.3331])\n",
      "Loss =  tensor([26.4059])\n",
      "Loss =  tensor([29.6479])\n",
      "Loss =  tensor([27.3137])\n",
      "Loss =  tensor([26.8753])\n",
      "Loss =  tensor([24.1975])\n",
      "Loss =  tensor([26.8392])\n",
      "Loss =  tensor([25.7509])\n",
      "Loss =  tensor([25.4083])\n",
      "Loss =  tensor([26.9865])\n",
      "Loss =  tensor([28.5029])\n",
      "Loss =  tensor([26.0585])\n",
      "Loss =  tensor([25.2971])\n",
      "Loss =  tensor([26.1827])\n",
      "Loss =  tensor([28.9375])\n",
      "Loss =  tensor([27.2443])\n",
      "Loss =  tensor([25.9193])\n",
      "Loss =  tensor([25.0440])\n",
      "Loss =  tensor([25.7928])\n",
      "Loss =  tensor([27.1050])\n",
      "Loss =  tensor([23.0937])\n",
      "Loss =  tensor([25.2378])\n",
      "Loss =  tensor([28.3012])\n",
      "Loss =  tensor([27.7942])\n",
      "Loss =  tensor([26.5545])\n",
      "Loss =  tensor([26.1081])\n",
      "Loss =  tensor([31.8756])\n",
      "Loss =  tensor([28.1175])\n",
      "Loss =  tensor([25.5085])\n",
      "Loss =  tensor([25.1197])\n",
      "Loss =  tensor([25.5263])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.7(best:0.78)\n",
      "F1:[0.48, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.95(best:0.96)\n",
      "Training F1:[0.97, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 73\n",
      "Loss =  tensor([25.4868])\n",
      "Loss =  tensor([26.1734])\n",
      "Loss =  tensor([24.5779])\n",
      "Loss =  tensor([24.4555])\n",
      "Loss =  tensor([24.6773])\n",
      "Loss =  tensor([25.1275])\n",
      "Loss =  tensor([26.0919])\n",
      "Loss =  tensor([24.3552])\n",
      "Loss =  tensor([23.3408])\n",
      "Loss =  tensor([24.8583])\n",
      "Loss =  tensor([24.9314])\n",
      "Loss =  tensor([24.5733])\n",
      "Loss =  tensor([25.1810])\n",
      "Loss =  tensor([22.7378])\n",
      "Loss =  tensor([24.6981])\n",
      "Loss =  tensor([23.7463])\n",
      "Loss =  tensor([28.0374])\n",
      "Loss =  tensor([24.3330])\n",
      "Loss =  tensor([26.2847])\n",
      "Loss =  tensor([24.5283])\n",
      "Loss =  tensor([24.3139])\n",
      "Loss =  tensor([25.4061])\n",
      "Loss =  tensor([23.9672])\n",
      "Loss =  tensor([24.1076])\n",
      "Loss =  tensor([25.6440])\n",
      "Loss =  tensor([24.3954])\n",
      "Loss =  tensor([25.6759])\n",
      "Loss =  tensor([24.3507])\n",
      "Loss =  tensor([27.4500])\n",
      "Loss =  tensor([24.3849])\n",
      "Loss =  tensor([26.0921])\n",
      "Loss =  tensor([24.2429])\n",
      "Loss =  tensor([25.0701])\n",
      "Loss =  tensor([24.5036])\n",
      "Loss =  tensor([24.8225])\n",
      "Loss =  tensor([25.3332])\n",
      "Loss =  tensor([24.8096])\n",
      "Loss =  tensor([24.0232])\n",
      "Loss =  tensor([25.9545])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 74\n",
      "Loss =  tensor([24.3826])\n",
      "Loss =  tensor([24.8988])\n",
      "Loss =  tensor([22.8300])\n",
      "Loss =  tensor([25.4185])\n",
      "Loss =  tensor([25.7183])\n",
      "Loss =  tensor([25.7736])\n",
      "Loss =  tensor([23.4618])\n",
      "Loss =  tensor([27.3287])\n",
      "Loss =  tensor([25.4868])\n",
      "Loss =  tensor([23.7419])\n",
      "Loss =  tensor([25.4998])\n",
      "Loss =  tensor([24.5029])\n",
      "Loss =  tensor([25.7046])\n",
      "Loss =  tensor([24.8825])\n",
      "Loss =  tensor([24.2139])\n",
      "Loss =  tensor([24.2926])\n",
      "Loss =  tensor([26.5864])\n",
      "Loss =  tensor([23.3935])\n",
      "Loss =  tensor([24.2802])\n",
      "Loss =  tensor([25.1148])\n",
      "Loss =  tensor([25.6465])\n",
      "Loss =  tensor([24.8683])\n",
      "Loss =  tensor([25.3877])\n",
      "Loss =  tensor([26.7922])\n",
      "Loss =  tensor([25.7438])\n",
      "Loss =  tensor([26.3748])\n",
      "Loss =  tensor([25.1774])\n",
      "Loss =  tensor([26.1903])\n",
      "Loss =  tensor([27.0664])\n",
      "Loss =  tensor([25.5973])\n",
      "Loss =  tensor([27.5785])\n",
      "Loss =  tensor([30.7956])\n",
      "Loss =  tensor([25.6668])\n",
      "Loss =  tensor([24.6827])\n",
      "Loss =  tensor([25.0617])\n",
      "Loss =  tensor([26.0065])\n",
      "Loss =  tensor([25.4385])\n",
      "Loss =  tensor([25.8627])\n",
      "Loss =  tensor([24.3468])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 75\n",
      "Loss =  tensor([24.5115])\n",
      "Loss =  tensor([24.2726])\n",
      "Loss =  tensor([23.5470])\n",
      "Loss =  tensor([25.7176])\n",
      "Loss =  tensor([26.1575])\n",
      "Loss =  tensor([25.6872])\n",
      "Loss =  tensor([24.6923])\n",
      "Loss =  tensor([25.1896])\n",
      "Loss =  tensor([27.1460])\n",
      "Loss =  tensor([25.3559])\n",
      "Loss =  tensor([27.2000])\n",
      "Loss =  tensor([25.2312])\n",
      "Loss =  tensor([24.9490])\n",
      "Loss =  tensor([24.5532])\n",
      "Loss =  tensor([24.3532])\n",
      "Loss =  tensor([23.0409])\n",
      "Loss =  tensor([24.3857])\n",
      "Loss =  tensor([27.4131])\n",
      "Loss =  tensor([25.3679])\n",
      "Loss =  tensor([24.4411])\n",
      "Loss =  tensor([25.3508])\n",
      "Loss =  tensor([25.3086])\n",
      "Loss =  tensor([26.6772])\n",
      "Loss =  tensor([25.1146])\n",
      "Loss =  tensor([25.7300])\n",
      "Loss =  tensor([24.1137])\n",
      "Loss =  tensor([22.9122])\n",
      "Loss =  tensor([26.5827])\n",
      "Loss =  tensor([26.6727])\n",
      "Loss =  tensor([25.9896])\n",
      "Loss =  tensor([24.2596])\n",
      "Loss =  tensor([25.5862])\n",
      "Loss =  tensor([25.1921])\n",
      "Loss =  tensor([26.2143])\n",
      "Loss =  tensor([26.9552])\n",
      "Loss =  tensor([26.6463])\n",
      "Loss =  tensor([27.3710])\n",
      "Loss =  tensor([25.5904])\n",
      "Loss =  tensor([25.7932])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 76\n",
      "Loss =  tensor([24.7942])\n",
      "Loss =  tensor([27.0132])\n",
      "Loss =  tensor([25.7709])\n",
      "Loss =  tensor([25.3088])\n",
      "Loss =  tensor([25.3961])\n",
      "Loss =  tensor([26.0320])\n",
      "Loss =  tensor([25.6252])\n",
      "Loss =  tensor([25.4561])\n",
      "Loss =  tensor([24.5672])\n",
      "Loss =  tensor([25.5018])\n",
      "Loss =  tensor([25.1460])\n",
      "Loss =  tensor([25.5891])\n",
      "Loss =  tensor([25.4951])\n",
      "Loss =  tensor([24.5781])\n",
      "Loss =  tensor([26.3248])\n",
      "Loss =  tensor([27.3521])\n",
      "Loss =  tensor([25.8037])\n",
      "Loss =  tensor([24.0950])\n",
      "Loss =  tensor([26.5317])\n",
      "Loss =  tensor([24.3927])\n",
      "Loss =  tensor([25.3178])\n",
      "Loss =  tensor([26.5968])\n",
      "Loss =  tensor([25.7667])\n",
      "Loss =  tensor([25.3548])\n",
      "Loss =  tensor([23.0992])\n",
      "Loss =  tensor([26.2559])\n",
      "Loss =  tensor([23.5345])\n",
      "Loss =  tensor([25.4102])\n",
      "Loss =  tensor([26.2164])\n",
      "Loss =  tensor([25.4634])\n",
      "Loss =  tensor([24.1055])\n",
      "Loss =  tensor([24.7106])\n",
      "Loss =  tensor([24.2666])\n",
      "Loss =  tensor([24.6220])\n",
      "Loss =  tensor([24.9584])\n",
      "Loss =  tensor([25.2880])\n",
      "Loss =  tensor([24.5523])\n",
      "Loss =  tensor([25.9078])\n",
      "Loss =  tensor([25.2104])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:32\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.54, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:03:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 77\n",
      "Loss =  tensor([25.1098])\n",
      "Loss =  tensor([24.6072])\n",
      "Loss =  tensor([24.7475])\n",
      "Loss =  tensor([25.5680])\n",
      "Loss =  tensor([26.5016])\n",
      "Loss =  tensor([27.7581])\n",
      "Loss =  tensor([24.6234])\n",
      "Loss =  tensor([23.1017])\n",
      "Loss =  tensor([25.1803])\n",
      "Loss =  tensor([25.0820])\n",
      "Loss =  tensor([22.9677])\n",
      "Loss =  tensor([24.1977])\n",
      "Loss =  tensor([25.1534])\n",
      "Loss =  tensor([26.0609])\n",
      "Loss =  tensor([24.4730])\n",
      "Loss =  tensor([26.9949])\n",
      "Loss =  tensor([27.0735])\n",
      "Loss =  tensor([27.5455])\n",
      "Loss =  tensor([27.4933])\n",
      "Loss =  tensor([26.5152])\n",
      "Loss =  tensor([29.5857])\n",
      "Loss =  tensor([31.5349])\n",
      "Loss =  tensor([30.1098])\n",
      "Loss =  tensor([26.4156])\n",
      "Loss =  tensor([25.3848])\n",
      "Loss =  tensor([24.8989])\n",
      "Loss =  tensor([29.9252])\n",
      "Loss =  tensor([28.0556])\n",
      "Loss =  tensor([23.2213])\n",
      "Loss =  tensor([27.1580])\n",
      "Loss =  tensor([28.0184])\n",
      "Loss =  tensor([27.8192])\n",
      "Loss =  tensor([26.3852])\n",
      "Loss =  tensor([25.5659])\n",
      "Loss =  tensor([27.0401])\n",
      "Loss =  tensor([28.7703])\n",
      "Loss =  tensor([24.7116])\n",
      "Loss =  tensor([22.6223])\n",
      "Loss =  tensor([27.0250])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:21\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.97, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 78\n",
      "Loss =  tensor([25.4524])\n",
      "Loss =  tensor([24.7001])\n",
      "Loss =  tensor([27.1462])\n",
      "Loss =  tensor([24.0609])\n",
      "Loss =  tensor([24.2434])\n",
      "Loss =  tensor([26.8531])\n",
      "Loss =  tensor([25.2965])\n",
      "Loss =  tensor([24.7756])\n",
      "Loss =  tensor([24.3244])\n",
      "Loss =  tensor([24.9111])\n",
      "Loss =  tensor([26.5651])\n",
      "Loss =  tensor([24.6681])\n",
      "Loss =  tensor([24.6415])\n",
      "Loss =  tensor([23.2229])\n",
      "Loss =  tensor([25.7229])\n",
      "Loss =  tensor([25.7124])\n",
      "Loss =  tensor([25.7480])\n",
      "Loss =  tensor([24.2200])\n",
      "Loss =  tensor([25.1369])\n",
      "Loss =  tensor([26.7224])\n",
      "Loss =  tensor([24.2899])\n",
      "Loss =  tensor([24.0336])\n",
      "Loss =  tensor([26.0945])\n",
      "Loss =  tensor([29.1701])\n",
      "Loss =  tensor([26.5065])\n",
      "Loss =  tensor([25.5037])\n",
      "Loss =  tensor([27.1104])\n",
      "Loss =  tensor([27.0343])\n",
      "Loss =  tensor([25.1502])\n",
      "Loss =  tensor([25.9705])\n",
      "Loss =  tensor([24.2821])\n",
      "Loss =  tensor([26.6118])\n",
      "Loss =  tensor([23.1789])\n",
      "Loss =  tensor([25.5599])\n",
      "Loss =  tensor([24.8930])\n",
      "Loss =  tensor([25.2949])\n",
      "Loss =  tensor([24.0789])\n",
      "Loss =  tensor([24.5926])\n",
      "Loss =  tensor([25.2043])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 79\n",
      "Loss =  tensor([25.7481])\n",
      "Loss =  tensor([25.3107])\n",
      "Loss =  tensor([25.1364])\n",
      "Loss =  tensor([24.5481])\n",
      "Loss =  tensor([23.3320])\n",
      "Loss =  tensor([24.8286])\n",
      "Loss =  tensor([25.1508])\n",
      "Loss =  tensor([25.6595])\n",
      "Loss =  tensor([25.8263])\n",
      "Loss =  tensor([23.1480])\n",
      "Loss =  tensor([24.0112])\n",
      "Loss =  tensor([24.0605])\n",
      "Loss =  tensor([24.1872])\n",
      "Loss =  tensor([26.1542])\n",
      "Loss =  tensor([24.8543])\n",
      "Loss =  tensor([25.2103])\n",
      "Loss =  tensor([25.2847])\n",
      "Loss =  tensor([24.6605])\n",
      "Loss =  tensor([24.9547])\n",
      "Loss =  tensor([26.6774])\n",
      "Loss =  tensor([24.9746])\n",
      "Loss =  tensor([24.6481])\n",
      "Loss =  tensor([24.9559])\n",
      "Loss =  tensor([24.5817])\n",
      "Loss =  tensor([22.9825])\n",
      "Loss =  tensor([26.5376])\n",
      "Loss =  tensor([24.4833])\n",
      "Loss =  tensor([24.8493])\n",
      "Loss =  tensor([27.7695])\n",
      "Loss =  tensor([25.9939])\n",
      "Loss =  tensor([24.5273])\n",
      "Loss =  tensor([26.0065])\n",
      "Loss =  tensor([27.2443])\n",
      "Loss =  tensor([27.0306])\n",
      "Loss =  tensor([26.0174])\n",
      "Loss =  tensor([24.9933])\n",
      "Loss =  tensor([33.3825])\n",
      "Loss =  tensor([29.0220])\n",
      "Loss =  tensor([23.1242])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.61(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 80\n",
      "Loss =  tensor([24.6261])\n",
      "Loss =  tensor([29.2648])\n",
      "Loss =  tensor([33.1783])\n",
      "Loss =  tensor([41.5048])\n",
      "Loss =  tensor([32.7755])\n",
      "Loss =  tensor([28.7657])\n",
      "Loss =  tensor([24.4858])\n",
      "Loss =  tensor([24.3361])\n",
      "Loss =  tensor([26.7019])\n",
      "Loss =  tensor([29.0233])\n",
      "Loss =  tensor([24.9177])\n",
      "Loss =  tensor([25.4370])\n",
      "Loss =  tensor([30.0523])\n",
      "Loss =  tensor([24.6911])\n",
      "Loss =  tensor([26.4347])\n",
      "Loss =  tensor([24.5222])\n",
      "Loss =  tensor([27.9310])\n",
      "Loss =  tensor([23.8843])\n",
      "Loss =  tensor([26.1714])\n",
      "Loss =  tensor([23.9053])\n",
      "Loss =  tensor([25.7765])\n",
      "Loss =  tensor([24.8292])\n",
      "Loss =  tensor([23.3589])\n",
      "Loss =  tensor([26.8647])\n",
      "Loss =  tensor([26.9558])\n",
      "Loss =  tensor([25.7052])\n",
      "Loss =  tensor([23.8366])\n",
      "Loss =  tensor([23.4399])\n",
      "Loss =  tensor([26.3097])\n",
      "Loss =  tensor([24.4545])\n",
      "Loss =  tensor([26.3541])\n",
      "Loss =  tensor([26.1786])\n",
      "Loss =  tensor([26.1528])\n",
      "Loss =  tensor([24.5363])\n",
      "Loss =  tensor([24.2045])\n",
      "Loss =  tensor([24.8733])\n",
      "Loss =  tensor([24.2478])\n",
      "Loss =  tensor([25.5381])\n",
      "Loss =  tensor([24.2182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.47, 0.89](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 81\n",
      "Loss =  tensor([23.6323])\n",
      "Loss =  tensor([25.8610])\n",
      "Loss =  tensor([25.1821])\n",
      "Loss =  tensor([25.2718])\n",
      "Loss =  tensor([26.0296])\n",
      "Loss =  tensor([25.4484])\n",
      "Loss =  tensor([27.4636])\n",
      "Loss =  tensor([23.6519])\n",
      "Loss =  tensor([24.9528])\n",
      "Loss =  tensor([25.1358])\n",
      "Loss =  tensor([25.8572])\n",
      "Loss =  tensor([24.9295])\n",
      "Loss =  tensor([25.9570])\n",
      "Loss =  tensor([27.6824])\n",
      "Loss =  tensor([27.5942])\n",
      "Loss =  tensor([24.6970])\n",
      "Loss =  tensor([26.2818])\n",
      "Loss =  tensor([24.8615])\n",
      "Loss =  tensor([25.4744])\n",
      "Loss =  tensor([26.5195])\n",
      "Loss =  tensor([25.3858])\n",
      "Loss =  tensor([24.0664])\n",
      "Loss =  tensor([24.3924])\n",
      "Loss =  tensor([27.0045])\n",
      "Loss =  tensor([25.1738])\n",
      "Loss =  tensor([25.0245])\n",
      "Loss =  tensor([23.3962])\n",
      "Loss =  tensor([24.9671])\n",
      "Loss =  tensor([24.3782])\n",
      "Loss =  tensor([25.3448])\n",
      "Loss =  tensor([25.2192])\n",
      "Loss =  tensor([25.3785])\n",
      "Loss =  tensor([24.0768])\n",
      "Loss =  tensor([25.7619])\n",
      "Loss =  tensor([24.8926])\n",
      "Loss =  tensor([24.4129])\n",
      "Loss =  tensor([26.2170])\n",
      "Loss =  tensor([25.2614])\n",
      "Loss =  tensor([25.0323])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.5, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 82\n",
      "Loss =  tensor([24.9244])\n",
      "Loss =  tensor([23.2029])\n",
      "Loss =  tensor([26.3481])\n",
      "Loss =  tensor([26.0011])\n",
      "Loss =  tensor([26.1415])\n",
      "Loss =  tensor([25.7555])\n",
      "Loss =  tensor([22.9189])\n",
      "Loss =  tensor([26.0411])\n",
      "Loss =  tensor([25.2354])\n",
      "Loss =  tensor([26.2058])\n",
      "Loss =  tensor([25.9871])\n",
      "Loss =  tensor([24.3722])\n",
      "Loss =  tensor([24.0065])\n",
      "Loss =  tensor([25.2066])\n",
      "Loss =  tensor([24.4386])\n",
      "Loss =  tensor([26.2356])\n",
      "Loss =  tensor([23.8255])\n",
      "Loss =  tensor([25.1069])\n",
      "Loss =  tensor([23.7058])\n",
      "Loss =  tensor([25.7624])\n",
      "Loss =  tensor([26.1445])\n",
      "Loss =  tensor([24.7916])\n",
      "Loss =  tensor([24.8645])\n",
      "Loss =  tensor([24.1434])\n",
      "Loss =  tensor([24.8301])\n",
      "Loss =  tensor([25.4029])\n",
      "Loss =  tensor([24.6426])\n",
      "Loss =  tensor([24.9054])\n",
      "Loss =  tensor([23.4180])\n",
      "Loss =  tensor([23.7357])\n",
      "Loss =  tensor([26.3216])\n",
      "Loss =  tensor([24.2257])\n",
      "Loss =  tensor([25.0274])\n",
      "Loss =  tensor([24.5494])\n",
      "Loss =  tensor([24.8990])\n",
      "Loss =  tensor([25.0495])\n",
      "Loss =  tensor([25.1191])\n",
      "Loss =  tensor([24.9542])\n",
      "Loss =  tensor([24.9401])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:21\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.62(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 83\n",
      "Loss =  tensor([24.8397])\n",
      "Loss =  tensor([26.2381])\n",
      "Loss =  tensor([24.5979])\n",
      "Loss =  tensor([24.3999])\n",
      "Loss =  tensor([22.5791])\n",
      "Loss =  tensor([24.8457])\n",
      "Loss =  tensor([23.0486])\n",
      "Loss =  tensor([24.2730])\n",
      "Loss =  tensor([26.0520])\n",
      "Loss =  tensor([25.3395])\n",
      "Loss =  tensor([23.3211])\n",
      "Loss =  tensor([23.9496])\n",
      "Loss =  tensor([22.8844])\n",
      "Loss =  tensor([24.9493])\n",
      "Loss =  tensor([25.4621])\n",
      "Loss =  tensor([25.0913])\n",
      "Loss =  tensor([24.7335])\n",
      "Loss =  tensor([26.0132])\n",
      "Loss =  tensor([26.3337])\n",
      "Loss =  tensor([23.5028])\n",
      "Loss =  tensor([25.7232])\n",
      "Loss =  tensor([24.8857])\n",
      "Loss =  tensor([25.7886])\n",
      "Loss =  tensor([23.2998])\n",
      "Loss =  tensor([27.5489])\n",
      "Loss =  tensor([26.3164])\n",
      "Loss =  tensor([27.1665])\n",
      "Loss =  tensor([28.9282])\n",
      "Loss =  tensor([26.0029])\n",
      "Loss =  tensor([25.0947])\n",
      "Loss =  tensor([24.8086])\n",
      "Loss =  tensor([25.1133])\n",
      "Loss =  tensor([25.0284])\n",
      "Loss =  tensor([25.8198])\n",
      "Loss =  tensor([25.5516])\n",
      "Loss =  tensor([24.3366])\n",
      "Loss =  tensor([25.3631])\n",
      "Loss =  tensor([27.2883])\n",
      "Loss =  tensor([28.0717])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.98)\n",
      "\n",
      "\n",
      "Epoch 84\n",
      "Loss =  tensor([24.6054])\n",
      "Loss =  tensor([23.6702])\n",
      "Loss =  tensor([24.1319])\n",
      "Loss =  tensor([26.0098])\n",
      "Loss =  tensor([24.5039])\n",
      "Loss =  tensor([23.9010])\n",
      "Loss =  tensor([23.9713])\n",
      "Loss =  tensor([25.0791])\n",
      "Loss =  tensor([24.9113])\n",
      "Loss =  tensor([23.3684])\n",
      "Loss =  tensor([24.3970])\n",
      "Loss =  tensor([30.3696])\n",
      "Loss =  tensor([28.4899])\n",
      "Loss =  tensor([24.2978])\n",
      "Loss =  tensor([26.3669])\n",
      "Loss =  tensor([24.4088])\n",
      "Loss =  tensor([24.6069])\n",
      "Loss =  tensor([26.0604])\n",
      "Loss =  tensor([23.7457])\n",
      "Loss =  tensor([25.0982])\n",
      "Loss =  tensor([24.8821])\n",
      "Loss =  tensor([24.8941])\n",
      "Loss =  tensor([25.1273])\n",
      "Loss =  tensor([23.4593])\n",
      "Loss =  tensor([25.0518])\n",
      "Loss =  tensor([26.2271])\n",
      "Loss =  tensor([25.0912])\n",
      "Loss =  tensor([26.0129])\n",
      "Loss =  tensor([24.1419])\n",
      "Loss =  tensor([26.4793])\n",
      "Loss =  tensor([26.9564])\n",
      "Loss =  tensor([28.7893])\n",
      "Loss =  tensor([24.6349])\n",
      "Loss =  tensor([26.1004])\n",
      "Loss =  tensor([27.7115])\n",
      "Loss =  tensor([24.4069])\n",
      "Loss =  tensor([25.7458])\n",
      "Loss =  tensor([26.7676])\n",
      "Loss =  tensor([28.5749])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 85\n",
      "Loss =  tensor([24.4523])\n",
      "Loss =  tensor([23.9025])\n",
      "Loss =  tensor([25.3751])\n",
      "Loss =  tensor([25.0565])\n",
      "Loss =  tensor([24.1188])\n",
      "Loss =  tensor([23.6728])\n",
      "Loss =  tensor([24.7902])\n",
      "Loss =  tensor([24.8598])\n",
      "Loss =  tensor([24.4372])\n",
      "Loss =  tensor([23.3412])\n",
      "Loss =  tensor([24.9704])\n",
      "Loss =  tensor([25.1234])\n",
      "Loss =  tensor([23.8288])\n",
      "Loss =  tensor([24.1340])\n",
      "Loss =  tensor([24.3660])\n",
      "Loss =  tensor([26.5241])\n",
      "Loss =  tensor([24.6920])\n",
      "Loss =  tensor([24.6949])\n",
      "Loss =  tensor([24.0024])\n",
      "Loss =  tensor([23.7629])\n",
      "Loss =  tensor([23.9944])\n",
      "Loss =  tensor([25.0261])\n",
      "Loss =  tensor([24.9561])\n",
      "Loss =  tensor([24.6252])\n",
      "Loss =  tensor([24.3352])\n",
      "Loss =  tensor([24.0464])\n",
      "Loss =  tensor([25.0550])\n",
      "Loss =  tensor([23.8450])\n",
      "Loss =  tensor([24.8106])\n",
      "Loss =  tensor([25.1348])\n",
      "Loss =  tensor([24.6341])\n",
      "Loss =  tensor([23.7521])\n",
      "Loss =  tensor([24.7753])\n",
      "Loss =  tensor([26.7150])\n",
      "Loss =  tensor([22.7923])\n",
      "Loss =  tensor([25.5388])\n",
      "Loss =  tensor([26.2766])\n",
      "Loss =  tensor([28.0451])\n",
      "Loss =  tensor([23.9086])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 86\n",
      "Loss =  tensor([23.4910])\n",
      "Loss =  tensor([24.9247])\n",
      "Loss =  tensor([25.2214])\n",
      "Loss =  tensor([23.7772])\n",
      "Loss =  tensor([24.0239])\n",
      "Loss =  tensor([22.8489])\n",
      "Loss =  tensor([24.5108])\n",
      "Loss =  tensor([25.0283])\n",
      "Loss =  tensor([24.2967])\n",
      "Loss =  tensor([22.9357])\n",
      "Loss =  tensor([23.6157])\n",
      "Loss =  tensor([26.5257])\n",
      "Loss =  tensor([25.5540])\n",
      "Loss =  tensor([24.9287])\n",
      "Loss =  tensor([27.1324])\n",
      "Loss =  tensor([25.2036])\n",
      "Loss =  tensor([24.4899])\n",
      "Loss =  tensor([25.4188])\n",
      "Loss =  tensor([24.7396])\n",
      "Loss =  tensor([23.8090])\n",
      "Loss =  tensor([24.0987])\n",
      "Loss =  tensor([23.5633])\n",
      "Loss =  tensor([25.6186])\n",
      "Loss =  tensor([25.6612])\n",
      "Loss =  tensor([27.1380])\n",
      "Loss =  tensor([25.2528])\n",
      "Loss =  tensor([23.3046])\n",
      "Loss =  tensor([24.5915])\n",
      "Loss =  tensor([26.4205])\n",
      "Loss =  tensor([25.5294])\n",
      "Loss =  tensor([25.1408])\n",
      "Loss =  tensor([28.0217])\n",
      "Loss =  tensor([27.2487])\n",
      "Loss =  tensor([25.4148])\n",
      "Loss =  tensor([25.1350])\n",
      "Loss =  tensor([27.7198])\n",
      "Loss =  tensor([26.6432])\n",
      "Loss =  tensor([26.0534])\n",
      "Loss =  tensor([23.7869])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:11\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.96)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 87\n",
      "Loss =  tensor([24.6100])\n",
      "Loss =  tensor([26.5345])\n",
      "Loss =  tensor([28.6235])\n",
      "Loss =  tensor([24.0052])\n",
      "Loss =  tensor([24.7865])\n",
      "Loss =  tensor([24.8883])\n",
      "Loss =  tensor([25.6552])\n",
      "Loss =  tensor([23.6463])\n",
      "Loss =  tensor([25.6407])\n",
      "Loss =  tensor([24.7660])\n",
      "Loss =  tensor([24.0649])\n",
      "Loss =  tensor([24.9089])\n",
      "Loss =  tensor([24.4240])\n",
      "Loss =  tensor([25.1324])\n",
      "Loss =  tensor([25.0164])\n",
      "Loss =  tensor([25.0696])\n",
      "Loss =  tensor([25.0645])\n",
      "Loss =  tensor([24.0096])\n",
      "Loss =  tensor([24.2563])\n",
      "Loss =  tensor([24.8045])\n",
      "Loss =  tensor([25.4680])\n",
      "Loss =  tensor([24.5031])\n",
      "Loss =  tensor([23.1882])\n",
      "Loss =  tensor([24.5195])\n",
      "Loss =  tensor([25.4654])\n",
      "Loss =  tensor([25.1220])\n",
      "Loss =  tensor([24.2218])\n",
      "Loss =  tensor([24.0928])\n",
      "Loss =  tensor([24.3364])\n",
      "Loss =  tensor([24.6137])\n",
      "Loss =  tensor([26.0582])\n",
      "Loss =  tensor([24.7738])\n",
      "Loss =  tensor([24.8372])\n",
      "Loss =  tensor([24.7238])\n",
      "Loss =  tensor([25.1027])\n",
      "Loss =  tensor([24.9418])\n",
      "Loss =  tensor([25.3881])\n",
      "Loss =  tensor([24.6009])\n",
      "Loss =  tensor([26.5471])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:09\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.63(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.97(best:0.97)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 88\n",
      "Loss =  tensor([24.0220])\n",
      "Loss =  tensor([26.1803])\n",
      "Loss =  tensor([25.5692])\n",
      "Loss =  tensor([22.5488])\n",
      "Loss =  tensor([22.9381])\n",
      "Loss =  tensor([23.8236])\n",
      "Loss =  tensor([24.4159])\n",
      "Loss =  tensor([25.4360])\n",
      "Loss =  tensor([24.9801])\n",
      "Loss =  tensor([23.9676])\n",
      "Loss =  tensor([24.7000])\n",
      "Loss =  tensor([23.4572])\n",
      "Loss =  tensor([24.7261])\n",
      "Loss =  tensor([24.2639])\n",
      "Loss =  tensor([25.7053])\n",
      "Loss =  tensor([25.0975])\n",
      "Loss =  tensor([25.1588])\n",
      "Loss =  tensor([25.6743])\n",
      "Loss =  tensor([26.5966])\n",
      "Loss =  tensor([23.9156])\n",
      "Loss =  tensor([24.9352])\n",
      "Loss =  tensor([23.2441])\n",
      "Loss =  tensor([24.6115])\n",
      "Loss =  tensor([26.8161])\n",
      "Loss =  tensor([25.9078])\n",
      "Loss =  tensor([23.9235])\n",
      "Loss =  tensor([23.7279])\n",
      "Loss =  tensor([26.5467])\n",
      "Loss =  tensor([24.9468])\n",
      "Loss =  tensor([24.6857])\n",
      "Loss =  tensor([24.6082])\n",
      "Loss =  tensor([25.9571])\n",
      "Loss =  tensor([23.9145])\n",
      "Loss =  tensor([25.9024])\n",
      "Loss =  tensor([26.7980])\n",
      "Loss =  tensor([23.7738])\n",
      "Loss =  tensor([25.7590])\n",
      "Loss =  tensor([23.3556])\n",
      "Loss =  tensor([23.9100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:12\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.65(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 89\n",
      "Loss =  tensor([23.0942])\n",
      "Loss =  tensor([26.6857])\n",
      "Loss =  tensor([30.8354])\n",
      "Loss =  tensor([30.6755])\n",
      "Loss =  tensor([28.5507])\n",
      "Loss =  tensor([23.7194])\n",
      "Loss =  tensor([26.4978])\n",
      "Loss =  tensor([26.7902])\n",
      "Loss =  tensor([23.3941])\n",
      "Loss =  tensor([25.7293])\n",
      "Loss =  tensor([26.3336])\n",
      "Loss =  tensor([24.6882])\n",
      "Loss =  tensor([24.9365])\n",
      "Loss =  tensor([26.5961])\n",
      "Loss =  tensor([29.0577])\n",
      "Loss =  tensor([26.7232])\n",
      "Loss =  tensor([24.5825])\n",
      "Loss =  tensor([24.6996])\n",
      "Loss =  tensor([23.4462])\n",
      "Loss =  tensor([25.9859])\n",
      "Loss =  tensor([22.6754])\n",
      "Loss =  tensor([23.7503])\n",
      "Loss =  tensor([28.1502])\n",
      "Loss =  tensor([24.2711])\n",
      "Loss =  tensor([24.5127])\n",
      "Loss =  tensor([27.0498])\n",
      "Loss =  tensor([30.0733])\n",
      "Loss =  tensor([27.7333])\n",
      "Loss =  tensor([25.7600])\n",
      "Loss =  tensor([23.8702])\n",
      "Loss =  tensor([26.5910])\n",
      "Loss =  tensor([25.3780])\n",
      "Loss =  tensor([25.0082])\n",
      "Loss =  tensor([26.1496])\n",
      "Loss =  tensor([24.8064])\n",
      "Loss =  tensor([24.8201])\n",
      "Loss =  tensor([25.9132])\n",
      "Loss =  tensor([25.7996])\n",
      "Loss =  tensor([25.7729])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:19\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 90\n",
      "Loss =  tensor([24.1114])\n",
      "Loss =  tensor([25.0632])\n",
      "Loss =  tensor([25.3827])\n",
      "Loss =  tensor([23.1633])\n",
      "Loss =  tensor([26.1490])\n",
      "Loss =  tensor([23.2339])\n",
      "Loss =  tensor([25.4481])\n",
      "Loss =  tensor([23.5398])\n",
      "Loss =  tensor([23.1897])\n",
      "Loss =  tensor([23.7887])\n",
      "Loss =  tensor([25.1211])\n",
      "Loss =  tensor([24.9595])\n",
      "Loss =  tensor([25.8901])\n",
      "Loss =  tensor([24.4669])\n",
      "Loss =  tensor([25.3320])\n",
      "Loss =  tensor([25.0980])\n",
      "Loss =  tensor([24.7083])\n",
      "Loss =  tensor([23.7671])\n",
      "Loss =  tensor([24.3423])\n",
      "Loss =  tensor([25.7096])\n",
      "Loss =  tensor([25.4305])\n",
      "Loss =  tensor([24.2217])\n",
      "Loss =  tensor([24.6557])\n",
      "Loss =  tensor([25.8518])\n",
      "Loss =  tensor([25.2171])\n",
      "Loss =  tensor([25.1776])\n",
      "Loss =  tensor([25.6909])\n",
      "Loss =  tensor([25.2390])\n",
      "Loss =  tensor([24.7001])\n",
      "Loss =  tensor([24.3161])\n",
      "Loss =  tensor([24.6142])\n",
      "Loss =  tensor([26.7513])\n",
      "Loss =  tensor([24.4347])\n",
      "Loss =  tensor([24.1907])\n",
      "Loss =  tensor([24.0820])\n",
      "Loss =  tensor([23.7996])\n",
      "Loss =  tensor([25.7893])\n",
      "Loss =  tensor([25.9832])\n",
      "Loss =  tensor([24.0253])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:19\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:03:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 91\n",
      "Loss =  tensor([24.1309])\n",
      "Loss =  tensor([25.4904])\n",
      "Loss =  tensor([25.8019])\n",
      "Loss =  tensor([25.1558])\n",
      "Loss =  tensor([27.2502])\n",
      "Loss =  tensor([24.8526])\n",
      "Loss =  tensor([25.0110])\n",
      "Loss =  tensor([26.6730])\n",
      "Loss =  tensor([25.3814])\n",
      "Loss =  tensor([22.8839])\n",
      "Loss =  tensor([25.6996])\n",
      "Loss =  tensor([23.9559])\n",
      "Loss =  tensor([23.6513])\n",
      "Loss =  tensor([25.5070])\n",
      "Loss =  tensor([25.2723])\n",
      "Loss =  tensor([24.7003])\n",
      "Loss =  tensor([23.6422])\n",
      "Loss =  tensor([27.3539])\n",
      "Loss =  tensor([25.4810])\n",
      "Loss =  tensor([26.5901])\n",
      "Loss =  tensor([26.5746])\n",
      "Loss =  tensor([25.1494])\n",
      "Loss =  tensor([24.5930])\n",
      "Loss =  tensor([24.9679])\n",
      "Loss =  tensor([24.1781])\n",
      "Loss =  tensor([25.4985])\n",
      "Loss =  tensor([24.0670])\n",
      "Loss =  tensor([23.7951])\n",
      "Loss =  tensor([25.1734])\n",
      "Loss =  tensor([23.2659])\n",
      "Loss =  tensor([25.7853])\n",
      "Loss =  tensor([26.0250])\n",
      "Loss =  tensor([24.5601])\n",
      "Loss =  tensor([25.9811])\n",
      "Loss =  tensor([27.5096])\n",
      "Loss =  tensor([26.1871])\n",
      "Loss =  tensor([24.8449])\n",
      "Loss =  tensor([25.0259])\n",
      "Loss =  tensor([24.3767])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:13\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 92\n",
      "Loss =  tensor([25.3956])\n",
      "Loss =  tensor([24.6803])\n",
      "Loss =  tensor([25.1827])\n",
      "Loss =  tensor([23.9681])\n",
      "Loss =  tensor([24.8288])\n",
      "Loss =  tensor([26.0112])\n",
      "Loss =  tensor([24.0871])\n",
      "Loss =  tensor([24.7029])\n",
      "Loss =  tensor([25.8545])\n",
      "Loss =  tensor([23.6096])\n",
      "Loss =  tensor([23.4033])\n",
      "Loss =  tensor([24.1103])\n",
      "Loss =  tensor([25.3806])\n",
      "Loss =  tensor([30.2685])\n",
      "Loss =  tensor([35.7324])\n",
      "Loss =  tensor([30.8164])\n",
      "Loss =  tensor([26.7254])\n",
      "Loss =  tensor([24.2777])\n",
      "Loss =  tensor([25.7700])\n",
      "Loss =  tensor([26.6396])\n",
      "Loss =  tensor([23.8345])\n",
      "Loss =  tensor([24.9905])\n",
      "Loss =  tensor([24.6604])\n",
      "Loss =  tensor([26.5065])\n",
      "Loss =  tensor([25.3214])\n",
      "Loss =  tensor([25.4804])\n",
      "Loss =  tensor([26.5859])\n",
      "Loss =  tensor([25.1765])\n",
      "Loss =  tensor([24.8665])\n",
      "Loss =  tensor([26.7196])\n",
      "Loss =  tensor([24.2200])\n",
      "Loss =  tensor([24.7399])\n",
      "Loss =  tensor([24.6432])\n",
      "Loss =  tensor([24.8422])\n",
      "Loss =  tensor([25.3466])\n",
      "Loss =  tensor([23.2415])\n",
      "Loss =  tensor([23.3235])\n",
      "Loss =  tensor([25.2442])\n",
      "Loss =  tensor([27.3207])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:10\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.51, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 93\n",
      "Loss =  tensor([24.1182])\n",
      "Loss =  tensor([26.5839])\n",
      "Loss =  tensor([27.4766])\n",
      "Loss =  tensor([27.9070])\n",
      "Loss =  tensor([24.3535])\n",
      "Loss =  tensor([23.7480])\n",
      "Loss =  tensor([27.7896])\n",
      "Loss =  tensor([23.9578])\n",
      "Loss =  tensor([26.3720])\n",
      "Loss =  tensor([26.0762])\n",
      "Loss =  tensor([28.7520])\n",
      "Loss =  tensor([26.8788])\n",
      "Loss =  tensor([24.2681])\n",
      "Loss =  tensor([24.0711])\n",
      "Loss =  tensor([23.3324])\n",
      "Loss =  tensor([24.3116])\n",
      "Loss =  tensor([25.3244])\n",
      "Loss =  tensor([23.6322])\n",
      "Loss =  tensor([23.9075])\n",
      "Loss =  tensor([23.0140])\n",
      "Loss =  tensor([26.5403])\n",
      "Loss =  tensor([26.3691])\n",
      "Loss =  tensor([24.1445])\n",
      "Loss =  tensor([23.7277])\n",
      "Loss =  tensor([25.2836])\n",
      "Loss =  tensor([23.7178])\n",
      "Loss =  tensor([24.5226])\n",
      "Loss =  tensor([24.4349])\n",
      "Loss =  tensor([26.5796])\n",
      "Loss =  tensor([24.0092])\n",
      "Loss =  tensor([24.9399])\n",
      "Loss =  tensor([26.1395])\n",
      "Loss =  tensor([23.6599])\n",
      "Loss =  tensor([25.7316])\n",
      "Loss =  tensor([25.9538])\n",
      "Loss =  tensor([26.2539])\n",
      "Loss =  tensor([24.6271])\n",
      "Loss =  tensor([23.7160])\n",
      "Loss =  tensor([25.2960])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:14\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.71(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 94\n",
      "Loss =  tensor([25.0183])\n",
      "Loss =  tensor([24.1138])\n",
      "Loss =  tensor([25.1805])\n",
      "Loss =  tensor([27.3092])\n",
      "Loss =  tensor([24.2508])\n",
      "Loss =  tensor([25.2944])\n",
      "Loss =  tensor([24.2174])\n",
      "Loss =  tensor([25.8825])\n",
      "Loss =  tensor([23.9686])\n",
      "Loss =  tensor([23.8991])\n",
      "Loss =  tensor([24.4683])\n",
      "Loss =  tensor([23.7899])\n",
      "Loss =  tensor([25.5979])\n",
      "Loss =  tensor([22.2293])\n",
      "Loss =  tensor([23.6826])\n",
      "Loss =  tensor([27.3038])\n",
      "Loss =  tensor([25.6711])\n",
      "Loss =  tensor([25.1329])\n",
      "Loss =  tensor([28.1120])\n",
      "Loss =  tensor([26.3675])\n",
      "Loss =  tensor([24.2721])\n",
      "Loss =  tensor([24.9669])\n",
      "Loss =  tensor([27.1143])\n",
      "Loss =  tensor([25.5987])\n",
      "Loss =  tensor([25.1287])\n",
      "Loss =  tensor([26.3442])\n",
      "Loss =  tensor([30.8754])\n",
      "Loss =  tensor([26.6126])\n",
      "Loss =  tensor([23.3448])\n",
      "Loss =  tensor([25.7002])\n",
      "Loss =  tensor([25.2907])\n",
      "Loss =  tensor([25.7265])\n",
      "Loss =  tensor([24.5744])\n",
      "Loss =  tensor([25.1440])\n",
      "Loss =  tensor([27.0776])\n",
      "Loss =  tensor([26.2730])\n",
      "Loss =  tensor([23.4613])\n",
      "Loss =  tensor([25.5393])\n",
      "Loss =  tensor([25.8340])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:18\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.67)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 95\n",
      "Loss =  tensor([25.1235])\n",
      "Loss =  tensor([22.5376])\n",
      "Loss =  tensor([24.0690])\n",
      "Loss =  tensor([24.2191])\n",
      "Loss =  tensor([23.8840])\n",
      "Loss =  tensor([22.5794])\n",
      "Loss =  tensor([24.3047])\n",
      "Loss =  tensor([24.8466])\n",
      "Loss =  tensor([25.2418])\n",
      "Loss =  tensor([24.5315])\n",
      "Loss =  tensor([23.9721])\n",
      "Loss =  tensor([25.6658])\n",
      "Loss =  tensor([28.0273])\n",
      "Loss =  tensor([27.4484])\n",
      "Loss =  tensor([26.2462])\n",
      "Loss =  tensor([25.0892])\n",
      "Loss =  tensor([24.9847])\n",
      "Loss =  tensor([23.9604])\n",
      "Loss =  tensor([24.6113])\n",
      "Loss =  tensor([26.3621])\n",
      "Loss =  tensor([23.9793])\n",
      "Loss =  tensor([24.1882])\n",
      "Loss =  tensor([26.3243])\n",
      "Loss =  tensor([26.0043])\n",
      "Loss =  tensor([23.7205])\n",
      "Loss =  tensor([27.0962])\n",
      "Loss =  tensor([30.7084])\n",
      "Loss =  tensor([30.6337])\n",
      "Loss =  tensor([23.2867])\n",
      "Loss =  tensor([25.5397])\n",
      "Loss =  tensor([27.6254])\n",
      "Loss =  tensor([29.0239])\n",
      "Loss =  tensor([23.8967])\n",
      "Loss =  tensor([25.8587])\n",
      "Loss =  tensor([26.8794])\n",
      "Loss =  tensor([25.1613])\n",
      "Loss =  tensor([24.6022])\n",
      "Loss =  tensor([25.9710])\n",
      "Loss =  tensor([26.7138])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:24\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.68(best:0.68)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 96\n",
      "Loss =  tensor([24.1254])\n",
      "Loss =  tensor([25.9791])\n",
      "Loss =  tensor([23.8828])\n",
      "Loss =  tensor([25.6117])\n",
      "Loss =  tensor([24.3912])\n",
      "Loss =  tensor([23.7210])\n",
      "Loss =  tensor([25.7035])\n",
      "Loss =  tensor([23.7346])\n",
      "Loss =  tensor([24.0642])\n",
      "Loss =  tensor([23.7762])\n",
      "Loss =  tensor([24.7129])\n",
      "Loss =  tensor([24.1813])\n",
      "Loss =  tensor([25.7620])\n",
      "Loss =  tensor([24.1740])\n",
      "Loss =  tensor([25.2379])\n",
      "Loss =  tensor([23.1899])\n",
      "Loss =  tensor([28.1272])\n",
      "Loss =  tensor([24.6434])\n",
      "Loss =  tensor([23.0243])\n",
      "Loss =  tensor([25.1876])\n",
      "Loss =  tensor([26.6860])\n",
      "Loss =  tensor([24.4404])\n",
      "Loss =  tensor([24.7740])\n",
      "Loss =  tensor([26.1025])\n",
      "Loss =  tensor([23.9759])\n",
      "Loss =  tensor([25.9759])\n",
      "Loss =  tensor([24.5128])\n",
      "Loss =  tensor([24.0771])\n",
      "Loss =  tensor([25.0126])\n",
      "Loss =  tensor([27.0645])\n",
      "Loss =  tensor([27.0159])\n",
      "Loss =  tensor([25.2092])\n",
      "Loss =  tensor([24.9517])\n",
      "Loss =  tensor([24.2537])\n",
      "Loss =  tensor([21.8962])\n",
      "Loss =  tensor([24.9989])\n",
      "Loss =  tensor([24.4833])\n",
      "Loss =  tensor([26.5180])\n",
      "Loss =  tensor([24.7068])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:21\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.67(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:03:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.68(best:0.68)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 97\n",
      "Loss =  tensor([24.4335])\n",
      "Loss =  tensor([25.0538])\n",
      "Loss =  tensor([25.0251])\n",
      "Loss =  tensor([24.8677])\n",
      "Loss =  tensor([25.9697])\n",
      "Loss =  tensor([23.2376])\n",
      "Loss =  tensor([23.4384])\n",
      "Loss =  tensor([24.1034])\n",
      "Loss =  tensor([25.2670])\n",
      "Loss =  tensor([24.2136])\n",
      "Loss =  tensor([24.0844])\n",
      "Loss =  tensor([22.6514])\n",
      "Loss =  tensor([24.8140])\n",
      "Loss =  tensor([24.7901])\n",
      "Loss =  tensor([24.8273])\n",
      "Loss =  tensor([25.7645])\n",
      "Loss =  tensor([23.0705])\n",
      "Loss =  tensor([23.0776])\n",
      "Loss =  tensor([21.8265])\n",
      "Loss =  tensor([25.4413])\n",
      "Loss =  tensor([26.2599])\n",
      "Loss =  tensor([26.8774])\n",
      "Loss =  tensor([24.9737])\n",
      "Loss =  tensor([23.6079])\n",
      "Loss =  tensor([23.9836])\n",
      "Loss =  tensor([25.9665])\n",
      "Loss =  tensor([23.5220])\n",
      "Loss =  tensor([24.1963])\n",
      "Loss =  tensor([22.8935])\n",
      "Loss =  tensor([23.7106])\n",
      "Loss =  tensor([26.0235])\n",
      "Loss =  tensor([24.7606])\n",
      "Loss =  tensor([25.7369])\n",
      "Loss =  tensor([24.8342])\n",
      "Loss =  tensor([24.4165])\n",
      "Loss =  tensor([23.8224])\n",
      "Loss =  tensor([24.0194])\n",
      "Loss =  tensor([23.5439])\n",
      "Loss =  tensor([25.6814])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:14\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.66(best:0.79)\n",
      "Validation Root accuracy:0.74(best:0.78)\n",
      "F1:[0.55, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.68(best:0.68)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 98\n",
      "Loss =  tensor([25.2240])\n",
      "Loss =  tensor([25.3481])\n",
      "Loss =  tensor([22.9534])\n",
      "Loss =  tensor([23.7719])\n",
      "Loss =  tensor([23.0265])\n",
      "Loss =  tensor([25.2508])\n",
      "Loss =  tensor([24.1892])\n",
      "Loss =  tensor([22.9382])\n",
      "Loss =  tensor([25.7293])\n",
      "Loss =  tensor([25.9625])\n",
      "Loss =  tensor([24.2911])\n",
      "Loss =  tensor([23.4813])\n",
      "Loss =  tensor([27.8233])\n",
      "Loss =  tensor([32.7833])\n",
      "Loss =  tensor([29.1591])\n",
      "Loss =  tensor([25.4354])\n",
      "Loss =  tensor([25.2859])\n",
      "Loss =  tensor([26.5099])\n",
      "Loss =  tensor([25.3649])\n",
      "Loss =  tensor([23.7678])\n",
      "Loss =  tensor([25.2361])\n",
      "Loss =  tensor([26.6965])\n",
      "Loss =  tensor([24.6224])\n",
      "Loss =  tensor([25.9014])\n",
      "Loss =  tensor([23.8563])\n",
      "Loss =  tensor([24.2434])\n",
      "Loss =  tensor([25.4758])\n",
      "Loss =  tensor([25.3217])\n",
      "Loss =  tensor([23.6921])\n",
      "Loss =  tensor([24.1641])\n",
      "Loss =  tensor([25.7440])\n",
      "Loss =  tensor([25.6016])\n",
      "Loss =  tensor([25.1134])\n",
      "Loss =  tensor([24.6668])\n",
      "Loss =  tensor([26.3109])\n",
      "Loss =  tensor([22.7554])\n",
      "Loss =  tensor([26.2577])\n",
      "Loss =  tensor([24.9438])\n",
      "Loss =  tensor([23.7044])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:17\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.64(best:0.79)\n",
      "Validation Root accuracy:0.73(best:0.78)\n",
      "F1:[0.53, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:48:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.68(best:0.68)\n",
      "Training Root// accuracy:0.97(best:0.97)\n",
      "Training F1:[0.98, 0.99](best:0.98 , 0.99)\n",
      "\n",
      "\n",
      "Epoch 99\n",
      "Loss =  tensor([25.4558])\n",
      "Loss =  tensor([24.2827])\n",
      "Loss =  tensor([24.7652])\n",
      "Loss =  tensor([24.3899])\n",
      "Loss =  tensor([22.7827])\n",
      "Loss =  tensor([25.1076])\n",
      "Loss =  tensor([24.4994])\n",
      "Loss =  tensor([24.0252])\n",
      "Loss =  tensor([24.3932])\n",
      "Loss =  tensor([25.4431])\n",
      "Loss =  tensor([26.4102])\n",
      "Loss =  tensor([27.6541])\n",
      "Loss =  tensor([26.3919])\n",
      "Loss =  tensor([27.9224])\n",
      "Loss =  tensor([27.6269])\n",
      "Loss =  tensor([25.1957])\n",
      "Loss =  tensor([26.3181])\n",
      "Loss =  tensor([27.1791])\n",
      "Loss =  tensor([25.9519])\n",
      "Loss =  tensor([26.0863])\n",
      "Loss =  tensor([29.3138])\n",
      "Loss =  tensor([29.3795])\n",
      "Loss =  tensor([34.7202])\n",
      "Loss =  tensor([26.1059])\n",
      "Loss =  tensor([24.7189])\n",
      "Loss =  tensor([27.3054])\n",
      "Loss =  tensor([30.1232])\n",
      "Loss =  tensor([27.2698])\n",
      "Loss =  tensor([24.6604])\n",
      "Loss =  tensor([25.3965])\n",
      "Loss =  tensor([25.5247])\n",
      "Loss =  tensor([23.4060])\n",
      "Loss =  tensor([23.8448])\n",
      "Loss =  tensor([24.2165])\n",
      "Loss =  tensor([24.6872])\n",
      "Loss =  tensor([24.3971])\n",
      "Loss =  tensor([25.3532])\n",
      "Loss =  tensor([24.2708])\n",
      "Loss =  tensor([24.2625])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:16\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.6(best:0.79)\n",
      "Validation Root accuracy:0.72(best:0.78)\n",
      "F1:[0.52, 0.9](best:0.63 , 0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:02:09\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training All-nodes accuracy:0.67(best:0.68)\n",
      "Training Root// accuracy:0.96(best:0.97)\n",
      "Training F1:[0.98, 0.98](best:0.98 , 0.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "#     trn = get_trn()\n",
    "    print(\"\\n\\nEpoch %d\" % epoch)\n",
    "    logging.info('Epoch: '+str(epoch))\n",
    "#     pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trn)/BATCH_SIZE).start()\n",
    "    params = []\n",
    "    for i in range(0,len(trn),BATCH_SIZE):\n",
    "        count+=1\n",
    "        batch = trn[i:min(i+BATCH_SIZE,len(trn))]\n",
    "        def closure():\n",
    "            global count\n",
    "            optimizer.zero_grad()\n",
    "            _,total_loss = model.getLoss(trn[0].root)\n",
    "            for tree in batch:\n",
    "                _, loss = model.getLoss(tree.root)\n",
    "                total_loss += loss\n",
    "\n",
    "            total_loss = total_loss/len(batch)\n",
    "            #L2 reg\n",
    "            param_dict = dict()\n",
    "            for name, param in model.named_parameters():\n",
    "                param_dict[name] = param.data.clone()\n",
    "                if param.requires_grad:\n",
    "                        total_loss += 0.5*l2_reg[name]*(torch.norm(param)**2)\n",
    "            params.append(param_dict)\n",
    "            print('Loss = ',total_loss.data)\n",
    "            logging.info('Loss = '+str(total_loss.data))\n",
    "            logger.scalar_summary('loss', total_loss.data, count)\n",
    "            total_loss.backward()\n",
    "            clip_grad_norm_(model.parameters(),5,2)\n",
    "            return total_loss\n",
    "#         pbar.update(i/BATCH_SIZE)\n",
    "        optimizer.step(closure)\n",
    "\n",
    "#     pbar.finish()\n",
    "\n",
    "    avg_param = dict()\n",
    "    for name, param1 in model.named_parameters():\n",
    "            avg_param[name] = param1.data.clone()\n",
    "\n",
    "    for i in range(1,len(params)):\n",
    "        for name, param in params[i].items():\n",
    "            avg_param[name] += param.clone()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name == 'embedding.weight':\n",
    "            continue\n",
    "        param.data = avg_param[name]/len(params)\n",
    "\n",
    "    correctRoot, correctAll, f1 = model.evaluate(dev)\n",
    "    # correctRoot = model.eval_sent_lvl(dev,LR_clf)\n",
    "    if bestAll<correctAll: bestAll=correctAll\n",
    "    if bestRoot<correctRoot: bestRoot=correctRoot\n",
    "    if bestF1_0<f1[0]: bestF1_0=f1[0]\n",
    "    if bestF1_1<f1[1]: bestF1_1=f1[1]\n",
    "    print(\"\\nValidation All-nodes accuracy:\"+str(round(correctAll,2))+\"(best:\"+str(round(bestAll,2))+\")\")\n",
    "    print(\"Validation Root accuracy:\" + str(round(correctRoot,2))+\"(best:\"+str(round(bestRoot,2))+\")\")\n",
    "    print(\"F1:\"+str([round(x,2) for x in f1])+\"(best:\"+str(round(bestF1_0,2))+\" , \"+str(round(bestF1_1,2))+\")\")\n",
    "    logging.info(\"Validation All-nodes accuracy:\"+str(round(correctAll,2))+\"(best:\"+str(round(bestAll,2))+\")\")\n",
    "    logging.info(\"Validation Root accuracy:\" + str(round(correctRoot,2))+\"(best:\"+str(round(bestRoot,2))+\")\")\n",
    "    logging.info(\"F1:\"+str([round(x,2) for x in f1])+\"(best:\"+str(round(bestF1_0,2))+\" , \"+str(round(bestF1_1,2))+\")\")\n",
    "    correct_trn_Root, correct_trn_All, f1_trn = model.evaluate(trn)\n",
    "    # correctRoot = model.eval_sent_lvl(dev,LR_clf)\n",
    "    if best_trn_All<correct_trn_All: best_trn_All=correct_trn_All\n",
    "    if best_trn_Root<correct_trn_Root: best_trn_Root=correct_trn_Root\n",
    "    if best_trn_F1_0<f1_trn[0]: best_trn_F1_0=f1_trn[0]\n",
    "    if best_trn_F1_1<f1_trn[1]: best_trn_F1_1=f1_trn[1]\n",
    "    print(\"\\nTraining All-nodes accuracy:\"+str(round(correct_trn_All,2))+\"(best:\"+str(round(best_trn_All,2))+\")\")\n",
    "    print(\"Training Root// accuracy:\" + str(round(correct_trn_Root,2))+\"(best:\"+str(round(best_trn_Root,2))+\")\")\n",
    "    print(\"Training F1:\"+str([round(x,2) for x in f1_trn])+\"(best:\"+str(round(best_trn_F1_0,2))+\" , \"+str(round(best_trn_F1_1,2))+\")\")\n",
    "    logging.info(\"Training All-nodes accuracy:\"+str(round(correct_trn_All,2))+\"(best:\"+str(round(best_trn_All,2))+\")\")\n",
    "    logging.info(\"Training Root accuracy:\" + str(round(correct_trn_Root,2))+\"(best:\"+str(round(best_trn_Root,2))+\")\")\n",
    "    logging.info(\"Training F1:\"+str([round(x,2) for x in f1_trn])+\"(best:\"+str(round(best_trn_F1_0,2))+\" , \"+str(round(best_trn_F1_1,2))+\")\")\n",
    "    info = {'valid_root_acc':correctRoot, 'valid_tree_acc':correctAll, 'train_root_acc':correct_trn_Root, 'train_tree_acc':correct_trn_All}\n",
    "    for tag, value in info.items():\n",
    "        logger.scalar_summary(tag,value,epoch)\n",
    "    random.shuffle(trn)\n",
    "    if epoch>0 and epoch%10==0:\n",
    "        pickle.dump(model,open(\"./models/checkpoints/\"+namecode+'_epoch_'+str(epoch)+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic_w2v_0ProAnti_0General_1NER_0Blackout_1Balance_0Undersample_1Fixed'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open(\"./models/\"+namecode+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
