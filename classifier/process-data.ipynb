{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import progressbar\n",
    "import torch\n",
    "import pickle\n",
    "from mytree import *\n",
    "from utils import *\n",
    "from treeUtil import *\n",
    "import tqdm\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import functools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import string\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import nltk.tree\n",
    "from ast import literal_eval\n",
    "import pptree\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from spacy.pipeline import merge_entities\n",
    "nlp = en_core_web_sm.load()\n",
    "nlp.add_pipe(merge_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proanti = True # True if doing pro/anti (ideology classification); False if doing nuetral/non-neutral classification (Step1: Stance Detection)\n",
    "ner = True # if replacing named entities with their entity tags\n",
    "blackout = False # if blacking out the named entities\n",
    "balanced = True # if dataset has to be balanced or not\n",
    "undersample = True # True if undersampling, False if oversampling\n",
    "test = False # False if proccessing data for training, True otherwise\n",
    "two_step = True # True if two-step classification (pro/anti or neutral/non-neutral); false if three-label classification (pro/anti/neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set name of the pickle file where trees will be stored \n",
    "file_trees = 'trees.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '/Users/navreetkaur/MTP/data/'\n",
    "if not test:\n",
    "    if not two_step:\n",
    "        pro_file = os.path.join(corpus_path,'pro.txt')\n",
    "        anti_file = os.path.join(corpus_path,'anti.txt')\n",
    "        neutral_file = os.path.join(corpus_path,'neutral.txt')\n",
    "    else:\n",
    "        if proanti:\n",
    "            pro_file = os.path.join(corpus_path,'pro.txt')\n",
    "            anti_file = os.path.join(corpus_path,'anti.txt')\n",
    "        else:\n",
    "            neutral_file = os.path.join(corpus_path,'neutral.txt')\n",
    "            non_neutral_file = os.path.join(corpus_path,'non_neutral.txt')\n",
    "else:\n",
    "    policy_file = os.path.join(corpus_path,'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entity(sent):\n",
    "    doc = nlp(sent)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_=='PERSON':\n",
    "            sent = sent.replace(ent.text,ent.label_)\n",
    "    return sent\n",
    "\n",
    "def blackout_entity(sent):\n",
    "    doc = nlp(sent)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_=='PERSON':\n",
    "            sent = sent.replace(ent.text,\"\")\n",
    "    return sent\n",
    "\n",
    "def read_into_string(filename):\n",
    "    text_file = open(filename, 'r')\n",
    "    lines = text_file.read().split('\\n')\n",
    "    if ner:\n",
    "        lines = [replace_entity(sent) for sent in lines]\n",
    "    if blackout:\n",
    "        lines = [blackout_entity(sent) for sent in lines]\n",
    "    text_file.close()\n",
    "    return lines\n",
    "\n",
    "def process(file):\n",
    "    sents = read_into_string(file)\n",
    "    sents = [s for s in sents if len(s)>14 and len(s)<500]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = anti = neutral = non_neutral = policy = []\n",
    "if test:\n",
    "    policy = process(policy_file)\n",
    "else:\n",
    "    if not two_step:\n",
    "        pro = process(pro_file) #1\n",
    "        anti = process(anti_file) #0\n",
    "        neutral = process(neutral_file) #2\n",
    "    if proanti:\n",
    "        pro = process(pro_file) #1\n",
    "        anti = process(anti_file) #0\n",
    "    else:\n",
    "        neutral = process(neutral_file) #0\n",
    "        non_neutral = process(non_neutral_file) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 0, 0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pro), len(anti), len(neutral), len(non_neutral), len(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command on terminal in the stanford-corenlp-full-2018-10-05 directory\n",
    "\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost', port=9000,timeout=90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(text):\n",
    "#     print(text)\n",
    "    output = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,depparse,parse',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    output = literal_eval(output)\n",
    "    try:\n",
    "        tree = str(output['sentences'][0]['parse'])\n",
    "    except:\n",
    "        print(output,text)\n",
    "        return\n",
    "    # print (tree)\n",
    "    parse_string = ' '.join(str(tree).split())\n",
    "    # print(parse_string)\n",
    "    # print (\"\\n\\n\")\n",
    "    tree = nltk.tree.Tree.fromstring(parse_string)\n",
    "    tree.chomsky_normal_form()\n",
    "    tree.collapse_unary(collapseRoot=True,collapsePOS=True)\n",
    "    nt = convertNLTK_tree(tree)\n",
    "    return nt\n",
    "\n",
    "def printLabelTree(tree):\n",
    "    def inorder(node,nnode):\n",
    "        if node.isLeaf:\n",
    "            newnode = pptree.Node('H',nnode)\n",
    "            wnode = pptree.Node(node.word,newnode)\n",
    "        elif nnode is not None:\n",
    "            newnode = pptree.Node('H',nnode)\n",
    "            inorder(node.left,newnode)\n",
    "            inorder(node.right,newnode)\n",
    "        elif node.isRoot():\n",
    "            newnode = pptree.Node('H')\n",
    "            inorder(node.left,newnode)\n",
    "            inorder(node.right,newnode)\n",
    "            return newnode\n",
    "        return None\n",
    "    pptree.print_tree(inorder(tree.root,None))\n",
    "\n",
    "def create_trees_using_df(df):\n",
    "    tree = []\n",
    "    for tokens in list(df['tokens']):\n",
    "        if len(tokens)==0:\n",
    "            continue\n",
    "        line = ' '.join(tokens)\n",
    "        line += '\\n'\n",
    "        tree.append(make_tree(line))\n",
    "    return tree\n",
    "\n",
    "def printlabel(root,l):\n",
    "    if root:\n",
    "        l.append(root.label)\n",
    "#         print(root.label)\n",
    "        if root.left:\n",
    "            l+=printlabel(root.left,[])\n",
    "#             print(printlabel(root.left))\n",
    "        if root.right:\n",
    "            l+=printlabel(root.right,[])\n",
    "#             print(printlabel(root.right))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    df = pd.DataFrame({'statement':policy})\n",
    "    df['tokens'] = [word_tokenize(re.sub(r'[^\\w\\s]|[\\d]+',' ',sent)) for sent in df['statement']]\n",
    "    pickle.dump(df,open(\"./trees/test/df_test\",'wb'))\n",
    "    tree = create_trees_using_df(df)\n",
    "    fout = open(\"./trees/test\",'wb')\n",
    "    pickle.dump([tree],fout)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting and balancing dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset, label, train_test_split = 0.85):\n",
    "    random.shuffle(dataset)\n",
    "    idx = int(len(dataset) * train_test_split)\n",
    "    train = dataset[: idx]\n",
    "    test = dataset[idx + 1:]\n",
    "    y_train = [label for x in range(len(train))]\n",
    "    y_test = [label for x in range(len(test))]\n",
    "    return (train, y_train), (test, y_test)\n",
    "\n",
    "def balance_classes(X_train, y_train):\n",
    "    dic = {}\n",
    "    minm = 10000000\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if y in dic.keys():\n",
    "            dic[y] = (1 + dic[y][0], [x] + dic[y][1])\n",
    "        else:\n",
    "            dic[y] = (1, [x])\n",
    "    for k in dic.keys():\n",
    "        if dic[k][0] < minm:\n",
    "            minm = dic[k][0]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for k in dic.keys():\n",
    "        X_train += dic[k][1][: minm]\n",
    "        y_train += [k for x in range(minm)]\n",
    "    return shuffle(X_train, y_train)\n",
    "\n",
    "def upsample(X_train, y_train):\n",
    "    dic = {}\n",
    "    minm = 10000000\n",
    "    maxm = -minm\n",
    "    X_final = []\n",
    "    y_final = []\n",
    "    # create the dictionary\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if y in dic.keys():\n",
    "            dic[y] = (1 + dic[y][0], [x] + dic[y][1])\n",
    "        else:\n",
    "            dic[y] = (1, [x])\n",
    "    # find maximum and minimum\n",
    "    for k in dic.keys():\n",
    "        count = dic[k][0]\n",
    "        if dic[k][0] < minm:\n",
    "            minm = count\n",
    "        if dic[k][0] > maxm:\n",
    "            maxm = count\n",
    "    # Upsample all the non-majority classes\n",
    "    for k in dic.keys():\n",
    "        count = dic[k][0]\n",
    "        examples = dic[k][1]\n",
    "        if count < maxm:\n",
    "            examples = resample(examples, \n",
    "                                          replace=True, # sample with replacement\n",
    "                                          n_samples=maxm, # match number in majority class\n",
    "                                          random_state=27) # reproducible results\n",
    "            assert len(examples) == maxm\n",
    "        X_final += examples\n",
    "        y_final += [k for x in range(len(examples))]\n",
    "    return shuffle(X_final, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not two_step:\n",
    "    if proanti:\n",
    "        (pro_X_train, pro_y_train), (pro_X_test, pro_y_test) = split(copy.deepcopy(pro), 1, train_test_split=train_test_split)\n",
    "        (anti_X_train, anti_y_train), (anti_X_test, anti_y_test) = split(copy.deepcopy(anti), 0, train_test_split=train_test_split)\n",
    "        (neutral_X_train, neutral_y_train), (neutral_X_test, neutral_y_test) = split(copy.deepcopy(neutral), 2, train_test_split=train_test_split)\n",
    "else:\n",
    "    if proanti:\n",
    "        (pro_X_train, pro_y_train), (pro_X_test, pro_y_test) = split(copy.deepcopy(pro), 1, train_test_split=train_test_split)\n",
    "        (anti_X_train, anti_y_train), (anti_X_test, anti_y_test) = split(copy.deepcopy(anti), 0, train_test_split=train_test_split)\n",
    "    else:\n",
    "        (neutral_X_train, neutral_y_train), (neutral_X_test, neutral_y_test) = split(copy.deepcopy(neutral), 0, train_test_split=train_test_split)\n",
    "        (non_neutral_X_train, non_neutral_y_train), (non_neutral_X_test, non_neutral_y_test) = split(copy.deepcopy(non_neutral), 1, train_test_split=train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not two_step:\n",
    "    # pro v/s anti v/s neutral classification\n",
    "    # pro:1, anti:0, neutral:2\n",
    "    X_train = pro_X_train + anti_X_train + neutral_X_train\n",
    "    y_train = pro_y_train + anti_y_train + neutral_y_train\n",
    "    X_test = pro_X_test + anti_X_test + neutral_X_test\n",
    "    y_test = pro_y_test + anti_y_test + neutral_y_test\n",
    "else:\n",
    "    if proanti:\n",
    "        # pro v/s anti classification\n",
    "        # pro:1, anti:0\n",
    "        X_train = pro_X_train + anti_X_train\n",
    "        y_train = pro_y_train + anti_y_train\n",
    "        X_test = pro_X_test + anti_X_test\n",
    "        y_test = pro_y_test + anti_y_test\n",
    "    else:\n",
    "        # neutral v/s non_neutral classification\n",
    "        # non_neutral:1, neutral:0\n",
    "        X_train = neutral_X_train + non_neutral_X_train\n",
    "        y_train = neutral_y_train + non_neutral_y_train\n",
    "        X_test = neutral_X_test + non_neutral_X_test\n",
    "        y_test = neutral_y_test + non_neutral_y_test\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balanced:\n",
    "    if undersample:\n",
    "        X_train, y_train = balance_classes(X_train, y_train)\n",
    "    else:\n",
    "        X_train, y_train = upsample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'statement':X_train, 'target':y_train})\n",
    "df_test = pd.DataFrame({'statement':X_test, 'target':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        statement\n",
       " target           \n",
       " 0               2\n",
       " 1               2,         statement\n",
       " target           \n",
       " 1               1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('target').count(), df_test.groupby('target').count() # check counts of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tokens'] = [word_tokenize(re.sub(r'[^\\w\\s]|[\\d]+',' ',sent)) for sent in df_train['statement']]\n",
    "df_train = df_train[['tokens','target']]\n",
    "df_test['tokens'] = [word_tokenize(re.sub(r'[^\\w\\s]|[\\d]+',' ',sent)) for sent in df_test['statement']]\n",
    "df_test = df_test[['tokens','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_train,open(\"./trees/df_\"+file_trees,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not two_step:\n",
    "    pro_trees = create_trees_using_df(df_train[df_train.target == 1])\n",
    "    anti_trees = create_trees_using_df(df_train[df_train.target == 0])\n",
    "    neutral_trees = create_trees_using_df(df_train[df_train.target == 2])\n",
    "    pro_test_trees = create_trees_using_df(df_test[df_test.target == 1])\n",
    "    anti_test_trees = create_trees_using_df(df_test[df_test.target == 0])\n",
    "    neutral_test_trees = create_trees_using_df(df_test[df_test.target == 2])\n",
    "    fout = open(\"./trees/\"+file_trees,'wb')\n",
    "    pickle.dump([pro_trees, anti_trees, neutral_trees],fout)\n",
    "    fout.close()\n",
    "    fout = open(\"./trees/\"+file_trees+\"_test\",'wb')\n",
    "    pickle.dump([pro_test_trees, anti_test_trees, neutral_test_trees],fout)\n",
    "    fout.close()\n",
    "else:\n",
    "    if proanti:\n",
    "        pro_trees = create_trees_using_df(df_train[df_train.target == 1])\n",
    "        anti_trees = create_trees_using_df(df_train[df_train.target == 0])\n",
    "        pro_test_trees = create_trees_using_df(df_test[df_test.target == 1])\n",
    "        anti_test_trees = create_trees_using_df(df_test[df_test.target == 0])\n",
    "        fout = open(\"./trees/\"+file_trees,'wb')\n",
    "        pickle.dump([pro_trees, anti_trees],fout)\n",
    "        fout.close()\n",
    "        fout = open(\"./trees/\"+file_trees+\"_test\",'wb')\n",
    "        pickle.dump([pro_test_trees, anti_test_trees],fout)\n",
    "        fout.close()\n",
    "    else:\n",
    "        neutral = create_trees_using_df(df_train[df_train.target == 0])\n",
    "        non_neutral = create_trees_using_df(df_train[df_train.target == 1])\n",
    "        neutral_test = create_trees_using_df(df_test[df_test.target == 0])\n",
    "        non_neutral_test = create_trees_using_df(df_test[df_test.target == 1])\n",
    "        fout = open(\"./trees/\"+file_trees,'wb')\n",
    "        pickle.dump([neutral, non_neutral],fout)\n",
    "        fout.close()\n",
    "        fout = open(\"./trees/\"+file_trees+\"_test\",'wb')\n",
    "        pickle.dump([neutral_test, non_neutral_test],fout)\n",
    "        fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
